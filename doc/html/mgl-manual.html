<!DOCTYPE html>
<html xmlns='http://www.w3.org/1999/xhtml' xml:lang='en' lang='en'>
<head>
<title>MGL Manual</title>
<link type='text/css' href='style.css' rel='stylesheet'/>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
</head>
<body><p><a name='x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29'></a></p>

<h1><span class="navigation"> <a href="#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29" title="(\&quot;mgl\&quot; ASDF/SYSTEM:SYSTEM)">&#8594;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8634;</a></span>MGL Manual</h1>

<h2>Table of Contents</h2>

<ul>
<li><a href="#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29" title="(\&quot;mgl\&quot; ASDF/SYSTEM:SYSTEM)">1 mgl ASDF System Details</a></li>
<li><a href="#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-OVERVIEW MGL-PAX:SECTION)">2 Overview</a>

<ul>
<li><a href="#x-28MGL-3A-40MGL-DEPENDENCIES-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-DEPENDENCIES MGL-PAX:SECTION)">2.1 Dependencies</a></li>
<li><a href="#x-28MGL-3A-40MGL-CODE-ORGANIZATION-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-CODE-ORGANIZATION MGL-PAX:SECTION)">2.2 Code Organization</a></li>
<li><a href="#x-28MGL-3A-40MGL-GLOSSARY-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GLOSSARY MGL-PAX:SECTION)">2.3 Glossary</a></li>
</ul></li>
<li><a href="#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-DATASET MGL-PAX:SECTION)">3 Datasets</a>

<ul>
<li><a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER MGL-PAX:SECTION)">3.1 Samplers</a>

<ul>
<li><a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-FUNCTION-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER-FUNCTION-SAMPLER MGL-PAX:SECTION)">3.1.1 Function Sampler</a></li>
</ul></li>
</ul></li>
<li><a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">4 Resampling</a>

<ul>
<li><a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-PARTITIONS-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-PARTITIONS MGL-PAX:SECTION)">4.1 Partitions</a></li>
<li><a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CROSS-VALIDATION-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CROSS-VALIDATION MGL-PAX:SECTION)">4.2 Cross-validation</a></li>
<li><a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-BAGGING MGL-PAX:SECTION)">4.3 Bagging</a></li>
<li><a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CV-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CV-BAGGING MGL-PAX:SECTION)">4.4 CV Bagging</a></li>
<li><a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-MISC-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-MISC MGL-PAX:SECTION)">4.5 Miscellaneous Operations</a></li>
</ul></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL MGL-PAX:SECTION)">5 Models</a>

<ul>
<li><a href="#x-28MGL-CORE-3A-40MGL-MODEL-PERSISTENCE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-PERSISTENCE MGL-PAX:SECTION)">5.1 Model Persistence</a></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-MODEL-STRIPE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-STRIPE MGL-PAX:SECTION)">5.2 Batch Processing</a></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-EXECUTORS MGL-PAX:SECTION)">5.3 Executors</a>

<ul>
<li><a href="#x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-PARAMETERIZED-EXECUTOR-CACHE MGL-PAX:SECTION)">5.3.1 Parameterized Executor Cache</a></li>
</ul></li>
</ul></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">6 Monitoring</a>

<ul>
<li><a href="#x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITOR MGL-PAX:SECTION)">6.1 Monitors</a></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MEASURER MGL-PAX:SECTION)">6.2 Measurers</a></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">6.3 Counters</a>

<ul>
<li><a href="#x-28MGL-CORE-3A-40MGL-ATTRIBUTES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-ATTRIBUTES MGL-PAX:SECTION)">6.3.1 Attributes</a></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-COUNTER-CLASSES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER-CLASSES MGL-PAX:SECTION)">6.3.2 Counter classes</a></li>
</ul></li>
</ul></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION MGL-PAX:SECTION)">7 Classification</a>

<ul>
<li><a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MONITOR MGL-PAX:SECTION)">7.1 Classification Monitors</a></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MEASURER MGL-PAX:SECTION)">7.2 Classification Measurers</a></li>
<li><a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-COUNTER MGL-PAX:SECTION)">7.3 Classification Counters</a>

<ul>
<li><a href="#x-28MGL-CORE-3A-40MGL-CONFUSION-MATRIX-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CONFUSION-MATRIX MGL-PAX:SECTION)">7.3.1 Confusion Matrices</a></li>
</ul></li>
</ul></li>
<li><a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">8 Gradient Based Optimization</a>

<ul>
<li><a href="#x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-ITERATIVE-OPTIMIZER MGL-PAX:SECTION)">8.1 Iterative Optimizer</a></li>
<li><a href="#x-28MGL-OPT-3A-40MGL-OPT-COST-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-COST MGL-PAX:SECTION)">8.2 Cost Function</a></li>
<li><a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">8.3 Gradient Descent</a>

<ul>
<li><a href="#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-BATCH-GD-OPTIMIZER MGL-PAX:SECTION)">8.3.1 Batch GD Optimizer</a></li>
<li><a href="#x-28MGL-GD-3A-40MGL-GD-SEGMENTED-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-SEGMENTED-GD-OPTIMIZER MGL-PAX:SECTION)">8.3.2 Segmented GD Optimizer</a></li>
<li><a href="#x-28MGL-GD-3A-40MGL-GD-PER-WEIGHT-OPTIMIZATION-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-PER-WEIGHT-OPTIMIZATION MGL-PAX:SECTION)">8.3.3 Per-weight Optimization</a></li>
<li><a href="#x-28MGL-GD-3A-40MGL-GD-ADAM-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-ADAM-OPTIMIZER MGL-PAX:SECTION)">8.3.4 Adam Optimizer</a></li>
<li><a href="#x-28MGL-GD-3A-40MGL-GD-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-UTILITIES MGL-PAX:SECTION)">8.3.5 Utilities</a></li>
</ul></li>
<li><a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">8.4 Conjugate Gradient</a></li>
<li><a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">8.5 Extension API</a>

<ul>
<li><a href="#x-28MGL-OPT-3A-40MGL-OPT-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-OPTIMIZER MGL-PAX:SECTION)">8.5.1 Implementing Optimizers</a></li>
<li><a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SOURCE MGL-PAX:SECTION)">8.5.2 Implementing Gradient Sources</a></li>
<li><a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SINK-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SINK MGL-PAX:SECTION)">8.5.3 Implementing Gradient Sinks</a></li>
</ul></li>
</ul></li>
<li><a href="#x-28MGL-DIFFUN-3A-40MGL-DIFFUN-20MGL-PAX-3ASECTION-29" title="(MGL-DIFFUN:@MGL-DIFFUN MGL-PAX:SECTION)">9 Differentiable Functions</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">10 Backpropagation Neural Networks</a>

<ul>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-OVERVIEW MGL-PAX:SECTION)">10.1 Backprop Overview</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EXTENSION-API MGL-PAX:SECTION)">10.2 Clump API</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">10.3 BPNs</a>

<ul>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TRAINING MGL-PAX:SECTION)">10.3.1 Training</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MONITORING MGL-PAX:SECTION)">10.3.2 Monitoring</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN MGL-PAX:SECTION)">10.3.3 Feed-Forward Nets</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN MGL-PAX:SECTION)">10.3.4 Recurrent Neural Nets</a></li>
</ul></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">10.4 Lumps</a>

<ul>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMP MGL-PAX:SECTION)">10.4.1 Lump Base Class</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUTS MGL-PAX:SECTION)">10.4.2 Inputs</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-WEIGHT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-WEIGHT-LUMP MGL-PAX:SECTION)">10.4.3 Weight Lump</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-SUBNET-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-SUBNET MGL-PAX:SECTION)">10.4.4 Activation Subnet</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">10.4.5 Activation Functions</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSSES MGL-PAX:SECTION)">10.4.6 Losses</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-STOCHASTICITY MGL-PAX:SECTION)">10.4.7 Stochasticity</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">10.4.8 Arithmetic</a></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RNN-OPERATIONS MGL-PAX:SECTION)">10.4.9 Operations for RNNs</a></li>
</ul></li>
<li><a href="#x-28MGL-BP-3A-40MGL-BP-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-UTILITIES MGL-PAX:SECTION)">10.5 Utilities</a></li>
</ul></li>
<li><a href="#x-28MGL-3A-40MGL-BM-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-BM MGL-PAX:SECTION)">11 Boltzmann Machines</a></li>
<li><a href="#x-28MGL-3A-40MGL-GP-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GP MGL-PAX:SECTION)">12 Gaussian Processes</a></li>
<li><a href="#x-28MGL-NLP-3A-40MGL-NLP-20MGL-PAX-3ASECTION-29" title="(MGL-NLP:@MGL-NLP MGL-PAX:SECTION)">13 Natural Language Processing</a></li>
</ul>

<h6>[in package MGL]</h6>

<p><a name='x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-OVERVIEW MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29" title="(\&quot;mgl\&quot; ASDF/SYSTEM:SYSTEM)">&#8634;</a></span>1 mgl ASDF System Details</h2>

<ul>
<li>Version: 0.1.0</li>
<li>Description: MGL is a machine learning library for backpropagation
  neural networks, boltzmann machines, gaussian processes and more.</li>
<li>Licence: MIT, see COPYING.</li>
<li>Author: Gábor Melis</li>
<li>Mailto: <a href="mailto:mega@retes.hu" >mega@retes.hu</a></li>
<li>Homepage: <a href="http://quotenil.com" >http://quotenil.com</a></li>
</ul>

<p><a name='x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29" title="(\&quot;mgl\&quot; ASDF/SYSTEM:SYSTEM)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-3A-40MGL-DEPENDENCIES-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-DEPENDENCIES MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-OVERVIEW MGL-PAX:SECTION)">&#8634;</a></span>2 Overview</h2>

<p>MGL is a Common Lisp machine learning library by <a href="http://quotenil.com" >Gábor
Melis</a> with some parts originally contributed
by Ravenpack International. It mainly concentrates on various forms
of neural networks (boltzmann machines, feed-forward and recurrent
backprop nets). Most of MGL is built on top of <code>MGL-MAT</code> so it has
BLAS and CUDA support.</p>

<p>In general, the focus is on power and performance not on ease of
use. Perhaps one day there will be a cookie cutter interface with
restricted functionality if a reasonable compromise is found between
power and utility.</p>

<p>Here is the <a href="https://github.com/melisgl/mgl" >official repository</a>
and <a href="http://melisgl.github.io/mgl-pax-world/mgl-manual.html" >HTML
documentation</a>.</p>

<p><a name='x-28MGL-3A-40MGL-DEPENDENCIES-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-OVERVIEW MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-OVERVIEW MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-3A-40MGL-CODE-ORGANIZATION-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-CODE-ORGANIZATION MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-3A-40MGL-DEPENDENCIES-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-DEPENDENCIES MGL-PAX:SECTION)">&#8634;</a></span>2.1 Dependencies</h3>

<p>MGL used to rely on <a href="https://github.com/tpapp/lla" >LLA</a> to
interface to BLAS and LAPACK. That's mostly history by now, but
configuration of foreign libraries is still done via <code>LLA</code>. See the
README in <code>LLA</code> on how to set things up. Note that these days OpenBLAS
is easier to set up and just as fast as ATLAS.</p>

<p><a href="https://github.com/takagi/cl-cuda" >CL-CUDA</a> and
<a href="https://github.com/melisgl/mgl" >MGL-MAT</a> are the two main
dependencies and also the ones not yet in quicklisp, so just drop
them into <code>quicklisp/local-projects/</code>. If there is no suitable GPU
on the system or the CUDA SDK is not installed, MGL will simply
fall back on using BLAS and Lisp code. Wrapping code in
<code>MGL-MAT:WITH-CUDA*</code> is basically all that's needed to run on the GPU,
and with <code>MGL-MAT:CUDA-AVAILABLE-P</code> one can check whether the GPU is
really being used.</p>

<p>Prettier-than-markdown HTML documentation cross-linked with other
libraries is
<a href="http://melisgl.github.io/mgl-pax-world/mgl-manual.html" >available</a>
as part of <a href="http://melisgl.github.io/mgl-pax-world/" >PAX World</a>.</p>

<p><a name='x-28MGL-3A-40MGL-CODE-ORGANIZATION-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-3A-40MGL-DEPENDENCIES-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-DEPENDENCIES MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-OVERVIEW MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-3A-40MGL-GLOSSARY-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GLOSSARY MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-3A-40MGL-CODE-ORGANIZATION-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-CODE-ORGANIZATION MGL-PAX:SECTION)">&#8634;</a></span>2.2 Code Organization</h3>

<p>MGL consists of several packages dedicated to different tasks.
For example, package <code>MGL-RESAMPLE</code> is about <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">Resampling</a> and
<code>MGL-GD</code> is about <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">Gradient Descent</a> and so on. On one hand, having many
packages makes it easier to cleanly separate API and implementation
and also to explore into a specific task. At other times, they can
be a hassle, so the <a href="#x-28-22mgl-22-20ASDF-2FSYSTEM-3ASYSTEM-29" title="(\&quot;mgl\&quot; ASDF/SYSTEM:SYSTEM)"><code>MGL</code></a> package itself reexports every external
symbol found in all the other packages that make up MGL and
MGL-MAT (see <code>MGL-MAT:@MAT-MANUAL</code>) on which it heavily relies.</p>

<p>One exception to this rule is the bundled, but independent
<code>MGL-GNUPLOT</code> library.</p>

<p>The built in tests can be run with:</p>

<pre><code>(ASDF:OOS 'ASDF:TEST-OP '#:MGL)
</code></pre>

<p>Note, that most of the tests are rather stochastic and can fail once
in a while.</p>

<p><a name='x-28MGL-3A-40MGL-GLOSSARY-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-3A-40MGL-CODE-ORGANIZATION-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-CODE-ORGANIZATION MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-OVERVIEW MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-DATASET MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-3A-40MGL-GLOSSARY-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GLOSSARY MGL-PAX:SECTION)">&#8634;</a></span>2.3 Glossary</h3>

<p>Ultimately machine learning is about creating <strong>models</strong> of some
domain. The observations in the modelled domain are called
<strong>instances</strong> (also known as examples or samples). Sets of instances
are called <strong>datasets</strong>. Datasets are used when fitting a model or
when making <strong>predictions</strong>. Sometimes the word predictions is too
specific, and the results obtained from applying a model to some
instances are simply called <strong>results</strong>.</p>

<p><a name='x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-3A-40MGL-GLOSSARY-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GLOSSARY MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-DATASET MGL-PAX:SECTION)">&#8634;</a></span>3 Datasets</h2>

<h6>[in package MGL-DATASET]</h6>

<p>An instance can often be any kind of object of the user's choice.
It is typically represented by a set of numbers which is called a
feature vector or by a structure holding the feature vector, the
label, etc. A dataset is a <code>SEQUENCE</code> of such instances or a
<a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER MGL-PAX:SECTION)">Samplers</a> object that produces instances.</p>

<p><a name='x-28MGL-DATASET-3AMAP-DATASET-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAP-DATASET</strong> <em>FN DATASET</em></p>

<p>Call <code>FN</code> with each instance in <code>DATASET</code>. This is basically equivalent
to iterating over the elements of a sequence or a sampler (see
<a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER MGL-PAX:SECTION)">Samplers</a>).</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3AMAP-DATASETS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAP-DATASETS</strong> <em>FN DATASETS &amp;KEY (IMPUTE NIL IMPUTEP)</em></p>

<p>Call <code>FN</code> with a list of instances, one from each dataset in
<code>DATASETS</code>. Return nothing. If <code>IMPUTE</code> is specified then iterate until
the largest dataset is consumed imputing <code>IMPUTE</code> for missing values.
If <code>IMPUTE</code> is not specified then iterate until the smallest dataset
runs out.</p>

<pre><code>(map-datasets #'prin1 '((0 1 2) (:a :b)))
.. (0 :A)(1 :B)

(map-datasets #'prin1 '((0 1 2) (:a :b)) :impute nil)
.. (0 :A)(1 :B)(2 NIL)
</code></pre>

<p>It is of course allowed to mix sequences with samplers:</p>

<pre><code>(map-datasets #'prin1
              (list '(0 1 2)
                    (make-sequence-sampler '(:a :b) :max-n-samples 2)))
.. (0 :A)(1 :B)
</code></pre></li>
</ul>

<p><a name='x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-DATASET MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-DATASET MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-FUNCTION-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER-FUNCTION-SAMPLER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER MGL-PAX:SECTION)">&#8634;</a></span>3.1 Samplers</h3>

<p>Some algorithms do not need random access to the entire dataset and
can work with a stream observations. Samplers are simple generators
providing two functions: <a href="#x-28MGL-DATASET-3ASAMPLE-20GENERIC-FUNCTION-29" title="(MGL-DATASET:SAMPLE GENERIC-FUNCTION)"><code>SAMPLE</code></a> and <a href="#x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29" title="(MGL-DATASET:FINISHEDP GENERIC-FUNCTION)"><code>FINISHEDP</code></a>.</p>

<p><a name='x-28MGL-DATASET-3ASAMPLE-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SAMPLE</strong> <em>SAMPLER</em></p>

<p>If <code>SAMPLER</code> has not run out of data (see <a href="#x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29" title="(MGL-DATASET:FINISHEDP GENERIC-FUNCTION)"><code>FINISHEDP</code></a>)
<a href="#x-28MGL-DATASET-3ASAMPLE-20GENERIC-FUNCTION-29" title="(MGL-DATASET:SAMPLE GENERIC-FUNCTION)"><code>SAMPLE</code></a> returns an object that represents a sample from the world to
be experienced or, in other words, simply something the can be used
as input for training or prediction. It is not allowed to call
<a href="#x-28MGL-DATASET-3ASAMPLE-20GENERIC-FUNCTION-29" title="(MGL-DATASET:SAMPLE GENERIC-FUNCTION)"><code>SAMPLE</code></a> if <code>SAMPLER</code> is <a href="#x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29" title="(MGL-DATASET:FINISHEDP GENERIC-FUNCTION)"><code>FINISHEDP</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>FINISHEDP</strong> <em>SAMPLER</em></p>

<p>See if <code>SAMPLER</code> has run out of examples.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3ALIST-SAMPLES-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>LIST-SAMPLES</strong> <em>SAMPLER MAX-SIZE</em></p>

<p>Return a list of samples of length at most <code>MAX-SIZE</code> or less if
<code>SAMPLER</code> runs out.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3AMAKE-SEQUENCE-SAMPLER-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-SEQUENCE-SAMPLER</strong> <em>SEQ &amp;KEY MAX-N-SAMPLES</em></p>

<p>Create a sampler that returns elements of <code>SEQ</code> in their original
order. If <code>MAX-N-SAMPLES</code> is non-nil, then at most <code>MAX-N-SAMPLES</code> are
sampled.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3AMAKE-RANDOM-SAMPLER-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-RANDOM-SAMPLER</strong> <em>SEQ &amp;KEY MAX-N-SAMPLES (REORDER #'MGL-RESAMPLE:SHUFFLE)</em></p>

<p>Create a sampler that returns elements of <code>SEQ</code> in random order. If
<code>MAX-N-SAMPLES</code> is non-nil, then at most <code>MAX-N-SAMPLES</code> are sampled.
The first pass over a shuffled copy of <code>SEQ</code>, and this copy is
reshuffled whenever the sampler reaches the end of it. Shuffling is
performed by calling the <code>REORDER</code> function.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3A-2AINFINITELY-EMPTY-DATASET-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*INFINITELY-EMPTY-DATASET*</strong> <em>#&lt;FUNCTION-SAMPLER &quot;infinitely empty&quot; &gt;</em></p>

<p>This is the default dataset for <a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MGL-OPT:MINIMIZE</code></a>. It's an infinite
stream of NILs.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3A-40MGL-SAMPLER-FUNCTION-SAMPLER-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-FUNCTION-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER-FUNCTION-SAMPLER MGL-PAX:SECTION)">&#8634;</a></span>3.1.1 Function Sampler</h4>

<p><a name='x-28MGL-DATASET-3AFUNCTION-SAMPLER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>FUNCTION-SAMPLER</strong></p>

<p>A sampler with a function in its <a href="#x-28MGL-DATASET-3AGENERATOR-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29" title="(MGL-DATASET:GENERATOR (MGL-PAX:READER MGL-DATASET:FUNCTION-SAMPLER))"><code>GENERATOR</code></a> that
produces a stream of samples which may or may not be finite
depending on <a href="#x-28MGL-DATASET-3AMAX-N-SAMPLES-20-28MGL-PAX-3AACCESSOR-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29" title="(MGL-DATASET:MAX-N-SAMPLES (MGL-PAX:ACCESSOR MGL-DATASET:FUNCTION-SAMPLER))"><code>MAX-N-SAMPLES</code></a>. <a href="#x-28MGL-DATASET-3AFINISHEDP-20GENERIC-FUNCTION-29" title="(MGL-DATASET:FINISHEDP GENERIC-FUNCTION)"><code>FINISHEDP</code></a> returns <code>T</code> iff <a href="#x-28MGL-DATASET-3AMAX-N-SAMPLES-20-28MGL-PAX-3AACCESSOR-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29" title="(MGL-DATASET:MAX-N-SAMPLES (MGL-PAX:ACCESSOR MGL-DATASET:FUNCTION-SAMPLER))"><code>MAX-N-SAMPLES</code></a> is
non-nil, and it's not greater than the number of samples
generated (<a href="#x-28MGL-DATASET-3AN-SAMPLES-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29" title="(MGL-DATASET:N-SAMPLES (MGL-PAX:READER MGL-DATASET:FUNCTION-SAMPLER))"><code>N-SAMPLES</code></a>).</p>

<pre><code>(list-samples (make-instance 'function-sampler
                             :generator (lambda ()
                                          (random 10))
                             :max-n-samples 5)
              10)
=&gt; (3 5 2 3 3)
</code></pre></li>
</ul>

<p><a name='x-28MGL-DATASET-3AGENERATOR-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>GENERATOR</strong> <em>FUNCTION-SAMPLER</em> <em>(:GENERATOR)</em></p>

<p>A generator function of no arguments that returns
the next sample.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3AMAX-N-SAMPLES-20-28MGL-PAX-3AACCESSOR-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29'></a></p>

<ul>
<li>[accessor] <strong>MAX-N-SAMPLES</strong> <em>FUNCTION-SAMPLER</em> <em>(:MAX-N-SAMPLES = NIL)</em></li>
</ul>

<p><a name='x-28MGL-COMMON-3ANAME-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>NAME</strong> <em>FUNCTION-SAMPLER</em> <em>(:NAME = NIL)</em></p>

<p>An arbitrary object naming the sampler. Only used
for printing the sampler object.</p></li>
</ul>

<p><a name='x-28MGL-DATASET-3AN-SAMPLES-20-28MGL-PAX-3AREADER-20MGL-DATASET-3AFUNCTION-SAMPLER-29-29'></a></p>

<ul>
<li>[reader] <strong>N-SAMPLES</strong> <em>FUNCTION-SAMPLER</em> <em>(:N-SAMPLES = 0)</em></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-DATASET-3A-40MGL-SAMPLER-FUNCTION-SAMPLER-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-SAMPLER-FUNCTION-SAMPLER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-PARTITIONS-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-PARTITIONS MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8634;</a></span>4 Resampling</h2>

<h6>[in package MGL-RESAMPLE]</h6>

<p>The focus of this package is on resampling methods such as
cross-validation and bagging which can be used for model evaluation,
model selection, and also as a simple form of ensembling. Data
partitioning and sampling functions are also provided because they
tend to be used together with resampling.</p>

<p><a name='x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-PARTITIONS-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CROSS-VALIDATION-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CROSS-VALIDATION MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-PARTITIONS-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-PARTITIONS MGL-PAX:SECTION)">&#8634;</a></span>4.1 Partitions</h3>

<p>The following functions partition a dataset (currently only
SEQUENCEs are supported) into a number of partitions. For each
element in the original dataset there is exactly one partition that
contains it.</p>

<p><a name='x-28MGL-RESAMPLE-3AFRACTURE-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>FRACTURE</strong> <em>FRACTIONS SEQ &amp;KEY WEIGHT</em></p>

<p>Partition <code>SEQ</code> into a number of subsequences. <code>FRACTIONS</code> is either a
positive integer or a list of non-negative real numbers. <code>WEIGHT</code> is
<code>NIL</code> or a function that returns a non-negative real number when
called with an element from <code>SEQ</code>. If <code>FRACTIONS</code> is a positive integer
then return a list of that many subsequences with equal sum of
weights bar rounding errors, else partition <code>SEQ</code> into subsequences,
where the sum of weights of subsequence I is proportional to element
I of <code>FRACTIONS</code>. If <code>WEIGHT</code> is <code>NIL</code>, then it's element is assumed to
have the same weight.</p>

<p>To split into 5 sequences:</p>

<pre><code>(fracture 5 '(0 1 2 3 4 5 6 7 8 9))
=> ((0 1) (2 3) (4 5) (6 7) (8 9))
</code></pre>

<p>To split into two sequences whose lengths are proportional to 2 and
3:</p>

<pre><code>(fracture '(2 3) '(0 1 2 3 4 5 6 7 8 9))
=> ((0 1 2 3) (4 5 6 7 8 9))
</code></pre></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>STRATIFY</strong> <em>SEQ &amp;KEY (KEY #'IDENTITY) (TEST #'EQL)</em></p>

<p>Return the list of strata of <code>SEQ</code>. <code>SEQ</code> is a sequence of elements for
which the function <code>KEY</code> returns the class they belong to. Such
classes are opaque objects compared for equality with <code>TEST</code>. A
stratum is a sequence of elements with the same (under <code>TEST</code>) <code>KEY</code>.</p>

<pre><code>(stratify '(0 1 2 3 4 5 6 7 8 9) :key #'evenp)
=> ((0 2 4 6 8) (1 3 5 7 9))
</code></pre></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3AFRACTURE-STRATIFIED-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>FRACTURE-STRATIFIED</strong> <em>FRACTIONS SEQ &amp;KEY (KEY #'IDENTITY) (TEST #'EQL) WEIGHT</em></p>

<p>Similar to <a href="#x-28MGL-RESAMPLE-3AFRACTURE-20FUNCTION-29" title="(MGL-RESAMPLE:FRACTURE FUNCTION)"><code>FRACTURE</code></a>, but also makes sure that keys are evenly
distributed among the partitions (see <a href="#x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29" title="(MGL-RESAMPLE:STRATIFY FUNCTION)"><code>STRATIFY</code></a>). It can be useful
for classification tasks to partition the data set while keeping the
distribution of classes the same.</p>

<p>Note that the sets returned are not in random order. In fact, they
are sorted internally by <code>KEY</code>.</p>

<p>For example, to make two splits with approximately the same number
of even and odd numbers:</p>

<pre><code>(fracture-stratified 2 '(0 1 2 3 4 5 6 7 8 9) :key #'evenp)
=> ((0 2 1 3) (4 6 8 5 7 9))
</code></pre></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CROSS-VALIDATION-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-PARTITIONS-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-PARTITIONS MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-BAGGING MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CROSS-VALIDATION-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CROSS-VALIDATION MGL-PAX:SECTION)">&#8634;</a></span>4.2 Cross-validation</h3>

<p><a name='x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>CROSS-VALIDATE</strong> <em>DATA FN &amp;KEY (N-FOLDS 5) (FOLDS (ALEXANDRIA.0.DEV:IOTA N-FOLDS)) (SPLIT-FN #'SPLIT-FOLD/MOD) PASS-FOLD</em></p>

<p>Map <code>FN</code> over the <code>FOLDS</code> of <code>DATA</code> split with <code>SPLIT-FN</code> and collect the
results in a list. The simplest demonstration is:</p>

<pre><code>(cross-validate '(0 1 2 3 4)
                (lambda (test training)
                 (list test training))
                :n-folds 5)
=> (((0) (1 2 3 4))
    ((1) (0 2 3 4))
    ((2) (0 1 3 4))
    ((3) (0 1 2 4))
    ((4) (0 1 2 3)))
</code></pre>

<p>Of course, in practice one would typically train a model and return
the trained model and/or its score on <code>TEST</code>. Also, sometimes one may
want to do only some of the folds and remember which ones they were:</p>

<pre><code>(cross-validate '(0 1 2 3 4)
                (lambda (fold test training)
                 (list :fold fold test training))
                :folds '(2 3)
                :pass-fold t)
=> ((:fold 2 (2) (0 1 3 4))
    (:fold 3 (3) (0 1 2 4)))
</code></pre>

<p>Finally, the way the data is split can be customized. By default
<a href="#x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FMOD-20FUNCTION-29" title="(MGL-RESAMPLE:SPLIT-FOLD/MOD FUNCTION)"><code>SPLIT-FOLD/MOD</code></a> is called with the arguments <code>DATA</code>, the fold (from
among <code>FOLDS</code>) and <code>N-FOLDS</code>. <a href="#x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FMOD-20FUNCTION-29" title="(MGL-RESAMPLE:SPLIT-FOLD/MOD FUNCTION)"><code>SPLIT-FOLD/MOD</code></a> returns two values which
are then passed on to <code>FN</code>. One can use <a href="#x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FCONT-20FUNCTION-29" title="(MGL-RESAMPLE:SPLIT-FOLD/CONT FUNCTION)"><code>SPLIT-FOLD/CONT</code></a> or
<a href="#x-28MGL-RESAMPLE-3ASPLIT-STRATIFIED-20FUNCTION-29" title="(MGL-RESAMPLE:SPLIT-STRATIFIED FUNCTION)"><code>SPLIT-STRATIFIED</code></a> or any other function that works with these
arguments. The only real constraint is that <code>FN</code> has to take as many
arguments (plus the fold argument if <code>PASS-FOLD</code>) as <code>SPLIT-FN</code>
returns.</p></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FMOD-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SPLIT-FOLD/MOD</strong> <em>SEQ FOLD N-FOLDS</em></p>

<p>Partition <code>SEQ</code> into two sequences: one with elements of <code>SEQ</code> with
indices whose remainder is <code>FOLD</code> when divided with <code>N-FOLDS</code>, and a
second one with the rest. The second one is the larger set. The
order of elements remains stable. This function is suitable as the
<code>SPLIT-FN</code> argument of <a href="#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29" title="(MGL-RESAMPLE:CROSS-VALIDATE FUNCTION)"><code>CROSS-VALIDATE</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3ASPLIT-FOLD-2FCONT-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SPLIT-FOLD/CONT</strong> <em>SEQ FOLD N-FOLDS</em></p>

<p>Imagine dividing <code>SEQ</code> into <code>N-FOLDS</code> subsequences of the same
size (bar rounding). Return the subsequence of index <code>FOLD</code> as the
first value and the all the other subsequences concatenated into one
as the second value. The order of elements remains stable. This
function is suitable as the <code>SPLIT-FN</code> argument of <a href="#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29" title="(MGL-RESAMPLE:CROSS-VALIDATE FUNCTION)"><code>CROSS-VALIDATE</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3ASPLIT-STRATIFIED-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SPLIT-STRATIFIED</strong> <em>SEQ FOLD N-FOLDS &amp;KEY (KEY #'IDENTITY) (TEST #'EQL) WEIGHT</em></p>

<p>Split <code>SEQ</code> into <code>N-FOLDS</code> partitions (as in <a href="#x-28MGL-RESAMPLE-3AFRACTURE-STRATIFIED-20FUNCTION-29" title="(MGL-RESAMPLE:FRACTURE-STRATIFIED FUNCTION)"><code>FRACTURE-STRATIFIED</code></a>).
Return the partition of index <code>FOLD</code> as the first value, and the
concatenation of the rest as the second value. This function is
suitable as the <code>SPLIT-FN</code> argument of <a href="#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29" title="(MGL-RESAMPLE:CROSS-VALIDATE FUNCTION)"><code>CROSS-VALIDATE</code></a> (mostly likely
as a closure with <code>KEY</code>, <code>TEST</code>, <code>WEIGHT</code> bound).</p></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-BAGGING-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CROSS-VALIDATION-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CROSS-VALIDATION MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CV-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CV-BAGGING MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-BAGGING MGL-PAX:SECTION)">&#8634;</a></span>4.3 Bagging</h3>

<p><a name='x-28MGL-RESAMPLE-3ABAG-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>BAG</strong> <em>SEQ FN &amp;KEY (RATIO 1) N WEIGHT (REPLACEMENT T) KEY (TEST #'EQL) (RANDOM-STATE *RANDOM-STATE*)</em></p>

<p>Sample from <code>SEQ</code> with <a href="#x-28MGL-RESAMPLE-3ASAMPLE-FROM-20FUNCTION-29" title="(MGL-RESAMPLE:SAMPLE-FROM FUNCTION)"><code>SAMPLE-FROM</code></a> (passing <code>RATIO</code>, <code>WEIGHT</code>,
<code>REPLACEMENT</code>), or <a href="#x-28MGL-RESAMPLE-3ASAMPLE-STRATIFIED-20FUNCTION-29" title="(MGL-RESAMPLE:SAMPLE-STRATIFIED FUNCTION)"><code>SAMPLE-STRATIFIED</code></a> if <code>KEY</code> is not <code>NIL</code>. Call <code>FN</code> with
the sample. If <code>N</code> is <code>NIL</code> then keep repeating this until <code>FN</code> performs a
non-local exit. Else <code>N</code> must be a non-negative integer, <code>N</code> iterations
will be performed, the primary values returned by <code>FN</code> collected into
a list and returned. See <a href="#x-28MGL-RESAMPLE-3ASAMPLE-FROM-20FUNCTION-29" title="(MGL-RESAMPLE:SAMPLE-FROM FUNCTION)"><code>SAMPLE-FROM</code></a> and <a href="#x-28MGL-RESAMPLE-3ASAMPLE-STRATIFIED-20FUNCTION-29" title="(MGL-RESAMPLE:SAMPLE-STRATIFIED FUNCTION)"><code>SAMPLE-STRATIFIED</code></a> for
examples.</p></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3ASAMPLE-FROM-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SAMPLE-FROM</strong> <em>RATIO SEQ &amp;KEY WEIGHT REPLACEMENT (RANDOM-STATE *RANDOM-STATE*)</em></p>

<p>Return a sequence constructed by sampling with or without
<code>REPLACEMENT</code> from <code>SEQ</code>. The sum of weights in the result sequence will
approximately be the sum of weights of <code>SEQ</code> times <code>RATIO</code>. If <code>WEIGHT</code> is
<code>NIL</code> then elements are assumed to have equal weights, else <code>WEIGHT</code>
should return a non-negative real number when called with an element
of <code>SEQ</code>.</p>

<p>To randomly select half of the elements:</p>

<pre><code><span class="code"><span class="paren1">(<span class="code">sample-from 1/2 '<span class="paren2">(<span class="code">0 1 2 3 4 5</span>)</span></span>)</span>
=&gt; <span class="paren1">(<span class="code">5 3 2</span>)</span></span></code></pre>

<p>To randomly select some elements such that the sum of their weights
constitute about half of the sum of weights across the whole
sequence:</p>

<pre><code><span class="code"><span class="paren1">(<span class="code">sample-from 1/2 '<span class="paren2">(<span class="code">0 1 2 3 4 5 6 7 8 9</span>)</span> <span class="keyword">:weight</span> #'identity</span>)</span>
=&gt; <span class="comment">;; sums to 28 that's near 45/2
</span>   <span class="paren1">(<span class="code">9 4 1 6 8</span>)</span></span></code></pre>

<p>To sample with replacement (that is, allowing the element to be
sampled multiple times):</p>

<pre><code><span class="code"><span class="paren1">(<span class="code">sample-from 1 '<span class="paren2">(<span class="code">0 1 2 3 4 5</span>)</span> <span class="keyword">:replacement</span> t</span>)</span>
=&gt; <span class="paren1">(<span class="code">1 1 5 1 4 4</span>)</span></span></code></pre></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3ASAMPLE-STRATIFIED-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SAMPLE-STRATIFIED</strong> <em>RATIO SEQ &amp;KEY WEIGHT REPLACEMENT (KEY #'IDENTITY) (TEST #'EQL) (RANDOM-STATE *RANDOM-STATE*)</em></p>

<p>Like <a href="#x-28MGL-RESAMPLE-3ASAMPLE-FROM-20FUNCTION-29" title="(MGL-RESAMPLE:SAMPLE-FROM FUNCTION)"><code>SAMPLE-FROM</code></a> but makes sure that the weighted proportion of
classes in the result is approximately the same as the proportion in
<code>SEQ</code>. See <a href="#x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29" title="(MGL-RESAMPLE:STRATIFY FUNCTION)"><code>STRATIFY</code></a> for the description of <code>KEY</code> and <code>TEST</code>.</p></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CV-BAGGING-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-BAGGING MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-MISC-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-MISC MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CV-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CV-BAGGING MGL-PAX:SECTION)">&#8634;</a></span>4.4 CV Bagging</h3>

<p><a name='x-28MGL-RESAMPLE-3ABAG-CV-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>BAG-CV</strong> <em>DATA FN &amp;KEY N (N-FOLDS 5) (FOLDS (ALEXANDRIA.0.DEV:IOTA N-FOLDS)) (SPLIT-FN #'SPLIT-FOLD/MOD) PASS-FOLD (RANDOM-STATE *RANDOM-STATE*)</em></p>

<p>Perform cross-validation on different shuffles of <code>DATA</code> <code>N</code> times and
collect the results. Since <a href="#x-28MGL-RESAMPLE-3ACROSS-VALIDATE-20FUNCTION-29" title="(MGL-RESAMPLE:CROSS-VALIDATE FUNCTION)"><code>CROSS-VALIDATE</code></a> collects the return values
of <code>FN</code>, the return value of this function is a list of lists of <code>FN</code>
results. If <code>N</code> is <code>NIL</code>, don't collect anything just keep doing
repeated CVs until <code>FN</code> performs an non-local exit.</p>

<p>The following example simply collects the test and training sets for
2-fold CV repeated 3 times with shuffled data:</p>

<pre><code><span class="code"><span class="comment">;;; This is non-deterministic.
</span><span class="paren1">(<span class="code">bag-cv '<span class="paren2">(<span class="code">0 1 2 3 4</span>)</span> #'list <span class="keyword">:n</span> 3 <span class="keyword">:n-folds</span> 2</span>)</span>
=&gt; <span class="paren1">(<span class="code"><span class="paren2">(<span class="code"><span class="paren3">(<span class="code"><span class="paren4">(<span class="code">2 3 4</span>)</span> <span class="paren4">(<span class="code">1 0</span>)</span></span>)</span>
     <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">1 0</span>)</span> <span class="paren4">(<span class="code">2 3 4</span>)</span></span>)</span></span>)</span>
    <span class="paren2">(<span class="code"><span class="paren3">(<span class="code"><span class="paren4">(<span class="code">2 1 0</span>)</span> <span class="paren4">(<span class="code">4 3</span>)</span></span>)</span>
     <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">4 3</span>)</span> <span class="paren4">(<span class="code">2 1 0</span>)</span></span>)</span></span>)</span>
    <span class="paren2">(<span class="code"><span class="paren3">(<span class="code"><span class="paren4">(<span class="code">1 0 3</span>)</span> <span class="paren4">(<span class="code">2 4</span>)</span></span>)</span>
     <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">2 4</span>)</span> <span class="paren4">(<span class="code">1 0 3</span>)</span></span>)</span></span>)</span></span>)</span></span></code></pre>

<p>CV bagging is useful when a single CV is not producing stable
results. As an ensemble method, CV bagging has the advantage over
bagging that each example will occur the same number of times and
after the first CV is complete there is a complete but less reliable
estimate for each example which gets refined by further CVs.</p></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-MISC-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-CV-BAGGING-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-CV-BAGGING MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-MISC-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-MISC MGL-PAX:SECTION)">&#8634;</a></span>4.5 Miscellaneous Operations</h3>

<p><a name='x-28MGL-RESAMPLE-3ASPREAD-STRATA-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SPREAD-STRATA</strong> <em>SEQ &amp;KEY (KEY #'IDENTITY) (TEST #'EQL)</em></p>

<p>Return a sequence that's a reordering of <code>SEQ</code> such that elements
belonging to different strata (under <code>KEY</code> and <code>TEST</code>, see <a href="#x-28MGL-RESAMPLE-3ASTRATIFY-20FUNCTION-29" title="(MGL-RESAMPLE:STRATIFY FUNCTION)"><code>STRATIFY</code></a>) are
distributed evenly. The order of elements belonging to the same
stratum is unchanged.</p>

<p>For example, to make sure that even and odd numbers are distributed
evenly:</p>

<pre><code>(spread-strata '(0 2 4 6 8 1 3 5 7 9) :key #'evenp)
=> (0 1 2 3 4 5 6 7 8 9)
</code></pre>

<p>Same thing with unbalanced classes:</p>

<pre><code>(spread-strata (vector 0 2 3 5 6 1 4)
               :key (lambda (x)
                      (if (member x '(1 4))
                          t
                          nil)))
=> #(0 1 2 3 4 5 6)
</code></pre></li>
</ul>

<p><a name='x-28MGL-RESAMPLE-3AZIP-EVENLY-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>ZIP-EVENLY</strong> <em>SEQS &amp;KEY RESULT-TYPE</em></p>

<p>Make a single sequence out of the sequences in <code>SEQS</code> so that in the
returned sequence indices of elements belonging to the same source
sequence are spread evenly across the whole range. The result is a
list is <code>RESULT-TYPE</code> is <code>LIST</code>, it's a vector if <code>RESULT-TYPE</code> is <code>VECTOR</code>.
If <code>RESULT-TYPE</code> is <code>NIL</code>, then it's determined by the type of the first
sequence in <code>SEQS</code>.</p>

<pre><code>(zip-evenly '((0 2 4) (1 3)))
=> (0 1 2 3 4)
</code></pre></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-RESAMPLE-3A-40MGL-RESAMPLE-MISC-20MGL-PAX-3ASECTION-29" title="(MGL-RESAMPLE:@MGL-RESAMPLE-MISC MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-PERSISTENCE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-PERSISTENCE MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL MGL-PAX:SECTION)">&#8634;</a></span>5 Models</h2>

<h6>[in package MGL-CORE]</h6>

<p><a name='x-28MGL-CORE-3A-40MGL-MODEL-PERSISTENCE-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-STRIPE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-STRIPE MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-PERSISTENCE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-PERSISTENCE MGL-PAX:SECTION)">&#8634;</a></span>5.1 Model Persistence</h3>

<p><a name='x-28MGL-CORE-3AREAD-WEIGHTS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>READ-WEIGHTS</strong> <em>MODEL STREAM</em></p>

<p>Read the weights of <code>MODEL</code> from the bivalent <code>STREAM</code>
where weights mean the learnt parameters. There is currently no
sanity checking of data which will most certainly change in the
future together with the serialization format.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AWRITE-WEIGHTS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>WRITE-WEIGHTS</strong> <em>MODEL STREAM</em></p>

<p>Write weight of <code>MODEL</code> to the bivalent <code>STREAM</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ALOAD-WEIGHTS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>LOAD-WEIGHTS</strong> <em>FILENAME MODEL</em></p>

<p>Load weights of <code>MODEL</code> from <code>FILENAME</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ASAVE-WEIGHTS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SAVE-WEIGHTS</strong> <em>FILENAME MODEL &amp;KEY (IF-EXISTS :ERROR) (ENSURE T)</em></p>

<p>Save weights of <code>MODEL</code> to <code>FILENAME</code>. If <code>ENSURE</code>, then
<code>ENSURE-DIRECTORIES-EXIST</code> is called on <code>FILENAME</code>. <code>IF-EXISTS</code> is passed
on to <code>OPEN</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-MODEL-STRIPE-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-PERSISTENCE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-PERSISTENCE MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-EXECUTORS MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-STRIPE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-STRIPE MGL-PAX:SECTION)">&#8634;</a></span>5.2 Batch Processing</h3>

<p>Processing instances one by one during training or prediction can
be slow. The models that support batch processing for greater
efficiency are said to be <em>striped</em>.</p>

<p>Typically, during or after creating a model, one sets <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a>
on it a positive integer. When a batch of instances is to be fed to
the model it is first broken into subbatches of length that's at
most <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a>. For each subbatch, <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a> (FIXDOC) is called
and a before method takes care of setting <a href="#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:N-STRIPES GENERIC-FUNCTION)"><code>N-STRIPES</code></a> to the actual
number of instances in the subbatch. When <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a> is set
internal data structures may be resized which is an expensive
operation. Setting <a href="#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:N-STRIPES GENERIC-FUNCTION)"><code>N-STRIPES</code></a> is a comparatively cheap operation,
often implemented as matrix reshaping.</p>

<p>Note that for models made of different parts (for example,
<a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>MGL-BP:BPN</code></a> consists of <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>MGL-BP:LUMP</code></a>s) , setting these
values affects the constituent parts, but one should never change
the number stripes of the parts directly because that would lead to
an internal inconsistency in the model.</p>

<p><a name='x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAX-N-STRIPES</strong> <em>OBJECT</em></p>

<p>The number of stripes with which the <code>OBJECT</code> is
capable of dealing simultaneously. </p></li>
</ul>

<p><a name='x-28MGL-CORE-3ASET-MAX-N-STRIPES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SET-MAX-N-STRIPES</strong> <em>MAX-N-STRIPES OBJECT</em></p>

<p>Allocate the necessary stuff to allow for
<code>MAX-N-STRIPES</code> number of stripes to be worked with simultaneously in
<code>OBJECT</code>. This is called when <code>MAX-N-STRIPES</code> is <code>SETF</code>'ed.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>N-STRIPES</strong> <em>OBJECT</em></p>

<p>The number of stripes currently present in <code>OBJECT</code>.
This is at most <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ASET-N-STRIPES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SET-N-STRIPES</strong> <em>N-STRIPES OBJECT</em></p>

<p>Set the number of stripes (out of <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a>)
that are in use in <code>OBJECT</code>. This is called when <code>N-STRIPES</code> is
<code>SETF</code>'ed.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AWITH-STRIPES-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>WITH-STRIPES</strong> <em>SPECS &amp;BODY BODY</em></p>

<p>Bind start and optionally end indices belonging to stripes in
striped objects.</p>

<pre><code>(WITH-STRIPES ((STRIPE1 OBJECT1 START1 END1)
               (STRIPE2 OBJECT2 START2)
               ...)
 ...)
</code></pre>

<p>This is how one's supposed to find the index range corresponding to
the Nth input in an input lump of a bpn:</p>

<pre><code> (with-stripes ((n input-lump start end))
   (loop for i upfrom start below end
         do (setf (mref (nodes input-lump) i) 0d0)))
</code></pre>

<p>Note how the input lump is striped, but the matrix into which we are
indexing (<a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a>) is not known to <a href="#x-28MGL-CORE-3AWITH-STRIPES-20MGL-PAX-3AMACRO-29" title="(MGL-CORE:WITH-STRIPES MGL-PAX:MACRO)"><code>WITH-STRIPES</code></a>. In fact, for lumps
the same stripe indices work with <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> and <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>MGL-BP:DERIVATIVES</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ASTRIPE-START-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>STRIPE-START</strong> <em>STRIPE OBJECT</em></p>

<p>Return the start index of <code>STRIPE</code> in some array or
matrix of <code>OBJECT</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ASTRIPE-END-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>STRIPE-END</strong> <em>STRIPE OBJECT</em></p>

<p>Return the end index (exclusive) of <code>STRIPE</code> in some
array or matrix of <code>OBJECT</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SET-INPUT</strong> <em>INSTANCES MODEL</em></p>

<p>Set <code>INSTANCES</code> as inputs in <code>MODEL</code>. SAMPLES is always
a <code>SEQUENCE</code> of instances even for models not capable of batch
operation. It sets <a href="#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:N-STRIPES GENERIC-FUNCTION)"><code>N-STRIPES</code></a> to (<code>LENGTH</code> <code>INSTANCES</code>) in a <code>:BEFORE</code>
method.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAP-BATCHES-FOR-MODEL-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAP-BATCHES-FOR-MODEL</strong> <em>FN DATASET MODEL</em></p>

<p>Call <code>FN</code> with batches of instances from <code>DATASET</code> suitable for <code>MODEL</code>.
The number of instances in a batch is <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a> of <code>MODEL</code> or less
if there are no more instances left.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ADO-BATCHES-FOR-MODEL-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>DO-BATCHES-FOR-MODEL</strong> <em>(BATCH (DATASET MODEL)) &amp;BODY BODY</em></p>

<p>Convenience macro over <a href="#x-28MGL-CORE-3AMAP-BATCHES-FOR-MODEL-20FUNCTION-29" title="(MGL-CORE:MAP-BATCHES-FOR-MODEL FUNCTION)"><code>MAP-BATCHES-FOR-MODEL</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-STRIPE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL-STRIPE MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-MODEL-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MODEL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-PARAMETERIZED-EXECUTOR-CACHE MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-EXECUTORS MGL-PAX:SECTION)">&#8634;</a></span>5.3 Executors</h3>

<p><a name='x-28MGL-CORE-3AMAP-OVER-EXECUTORS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAP-OVER-EXECUTORS</strong> <em>FN INSTANCES PROTOTYPE-EXECUTOR</em></p>

<p>Divide <code>INSTANCES</code> between executors that perform the
same function as <code>PROTOTYPE-EXECUTOR</code> and call <code>FN</code> with the instances
and the executor for which the instances are.</p>

<p>Some objects conflate function and call: the forward pass of a
<a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>MGL-BP:BPN</code></a> computes output from inputs so it is like a
function but it also doubles as a function call in the sense that
the bpn (function) object changes state during the computation of
the output. Hence not even the forward pass of a bpn is thread safe.
There is also the restriction that all inputs must be of the same
size.</p>

<p>For example, if we have a function that builds bpn a for an input of
a certain size, then we can create a factory that creates bpns for a
particular call. The factory probably wants keep the weights the
same though. In <a href="#x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-PARAMETERIZED-EXECUTOR-CACHE MGL-PAX:SECTION)">Parameterized Executor Cache</a>,
<a href="#x-28MGL-CORE-3AMAKE-EXECUTOR-WITH-PARAMETERS-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAKE-EXECUTOR-WITH-PARAMETERS GENERIC-FUNCTION)"><code>MAKE-EXECUTOR-WITH-PARAMETERS</code></a> is this factory.</p>

<p>Parallelization of execution is another possibility
<a href="#x-28MGL-CORE-3AMAP-OVER-EXECUTORS-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAP-OVER-EXECUTORS GENERIC-FUNCTION)"><code>MAP-OVER-EXECUTORS</code></a> allows, but there is no prebuilt solution for it,
yet.</p>

<p>The default implementation simply calls <code>FN</code> with <code>INSTANCES</code> and
<code>PROTOTYPE-EXECUTOR</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ADO-EXECUTORS-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>DO-EXECUTORS</strong> <em>(INSTANCES OBJECT) &amp;BODY BODY</em></p>

<p>Convenience macro on top of <a href="#x-28MGL-CORE-3AMAP-OVER-EXECUTORS-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAP-OVER-EXECUTORS GENERIC-FUNCTION)"><code>MAP-OVER-EXECUTORS</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-EXECUTORS MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-EXECUTORS-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-EXECUTORS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-PARAMETERIZED-EXECUTOR-CACHE MGL-PAX:SECTION)">&#8634;</a></span>5.3.1 Parameterized Executor Cache</h4>

<p><a name='x-28MGL-CORE-3APARAMETERIZED-EXECUTOR-CACHE-MIXIN-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>PARAMETERIZED-EXECUTOR-CACHE-MIXIN</strong></p>

<p>Mix this into a model, implement
<a href="#x-28MGL-CORE-3AINSTANCE-TO-EXECUTOR-PARAMETERS-20GENERIC-FUNCTION-29" title="(MGL-CORE:INSTANCE-TO-EXECUTOR-PARAMETERS GENERIC-FUNCTION)"><code>INSTANCE-TO-EXECUTOR-PARAMETERS</code></a> and <a href="#x-28MGL-CORE-3AMAKE-EXECUTOR-WITH-PARAMETERS-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAKE-EXECUTOR-WITH-PARAMETERS GENERIC-FUNCTION)"><code>MAKE-EXECUTOR-WITH-PARAMETERS</code></a>
and <a href="#x-28MGL-CORE-3ADO-EXECUTORS-20MGL-PAX-3AMACRO-29" title="(MGL-CORE:DO-EXECUTORS MGL-PAX:MACRO)"><code>DO-EXECUTORS</code></a> will be to able build executors suitable for
different instances. The canonical example is using a BPN to compute
the means and convariances of a gaussian process. Since each
instance is made of a variable number of observations, the size of
the input is not constant, thus we have a bpn (an executor) for each
input dimension (the parameters).</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAKE-EXECUTOR-WITH-PARAMETERS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAKE-EXECUTOR-WITH-PARAMETERS</strong> <em>PARAMETERS CACHE</em></p>

<p>Create a new executor for <code>PARAMETERS</code>. <code>CACHE</code> is a
<a href="#x-28MGL-CORE-3APARAMETERIZED-EXECUTOR-CACHE-MIXIN-20CLASS-29" title="(MGL-CORE:PARAMETERIZED-EXECUTOR-CACHE-MIXIN CLASS)"><code>PARAMETERIZED-EXECUTOR-CACHE-MIXIN</code></a>. In the BPN gaussian process
example, <code>PARAMETERS</code> would be a list of input dimensions.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AINSTANCE-TO-EXECUTOR-PARAMETERS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>INSTANCE-TO-EXECUTOR-PARAMETERS</strong> <em>INSTANCE CACHE</em></p>

<p>Return the parameters for an executor able to
handle <code>INSTANCE</code>. Called by <a href="#x-28MGL-CORE-3AMAP-OVER-EXECUTORS-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAP-OVER-EXECUTORS GENERIC-FUNCTION)"><code>MAP-OVER-EXECUTORS</code></a> on <code>CACHE</code> (that's a
<a href="#x-28MGL-CORE-3APARAMETERIZED-EXECUTOR-CACHE-MIXIN-20CLASS-29" title="(MGL-CORE:PARAMETERIZED-EXECUTOR-CACHE-MIXIN CLASS)"><code>PARAMETERIZED-EXECUTOR-CACHE-MIXIN</code></a>). The returned parameters are
keys in an <code>EQUAL</code> parameters-&gt;executor hash table.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-PARAMETERIZED-EXECUTOR-CACHE-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-PARAMETERIZED-EXECUTOR-CACHE MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITOR MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">&#8634;</a></span>6 Monitoring</h2>

<h6>[in package MGL-CORE]</h6>

<p>When training or applying a model, one often wants to track various
statistics. For example, in the case of training a neural network
with cross-entropy loss, these statistics could be the average
cross-entropy loss itself, classification accuracy, or even the
entire confusion matrix and sparsity levels in hidden layers. Also,
there is the question of what to do with the measured values (log
and forget, add to some counter or a list).</p>

<p>So there may be several phases of operation when we want to keep an
eye on. Let's call these <strong>events</strong>. There can also be many fairly
independent things to do in response to an event. Let's call these
<strong>monitors</strong>. Some monitors are a composition of two operations: one
that extracts some measurements and another that aggregates those
measurements. Let's call these two <strong>measurers</strong> and <strong>counters</strong>,
respectively.</p>

<p>For example, consider training a backpropagation neural network. We
want to look at the state of of network just after the backward
pass. <a href="#x-28MGL-BP-3ABP-LEARNER-20CLASS-29" title="(MGL-BP:BP-LEARNER CLASS)"><code>MGL-BP:BP-LEARNER</code></a> has a [MONITORS]
event hook corresponding to the moment after backpropagating the
gradients. Suppose we are interested in how the training cost
evolves:</p>

<pre><code>(push (make-instance 'monitor
                     :measurer (lambda (instances bpn)
                                 (declare (ignore instances))
                                 (mgl-bp:cost bpn))
                     :counter (make-instance 'basic-counter))
      (monitors learner))
</code></pre>

<p>During training, this monitor will track the cost of training
examples behind the scenes. If we want to print and reset this
monitor periodically we can put another monitor on
<a href="#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29" title="(MGL-OPT:ITERATIVE-OPTIMIZER CLASS)"><code>MGL-OPT:ITERATIVE-OPTIMIZER</code></a>'s <a href="#x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:ON-N-INSTANCES-CHANGED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER))"><code>MGL-OPT:ON-N-INSTANCES-CHANGED</code></a>
accessor:</p>

<pre><code>(push (lambda (optimizer gradient-source n-instances)
        (declare (ignore optimizer))
        (when (zerop (mod n-instances 1000))
          (format t &quot;n-instances: ~S~%&quot; n-instances)
          (dolist (monitor (monitors gradient-source))
            (when (counter monitor)
              (format t &quot;~A~%&quot; (counter monitor))
              (reset-counter (counter monitor)))))
      (mgl-opt:on-n-instances-changed optimizer))
</code></pre>

<p>Note that the monitor we push can be anything as long as
<a href="#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29" title="(MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION)"><code>APPLY-MONITOR</code></a> is implemented on it with the appropriate signature.
Also note that the <code>ZEROP</code> + <code>MOD</code> logic is fragile, so you will likely
want to use <a href="#x-28MGL-OPT-3AMONITOR-OPTIMIZATION-PERIODICALLY-20FUNCTION-29" title="(MGL-OPT:MONITOR-OPTIMIZATION-PERIODICALLY FUNCTION)"><code>MGL-OPT:MONITOR-OPTIMIZATION-PERIODICALLY</code></a> instead of
doing the above.</p>

<p>So that's the general idea. Concrete events are documented where
they are signalled. Often there are task specific utilities that
create a reasonable set of default monitors (see
<a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MONITOR MGL-PAX:SECTION)">Classification Monitors</a>).</p>

<p><a name='x-28MGL-CORE-3AAPPLY-MONITORS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>APPLY-MONITORS</strong> <em>MONITORS &amp;REST ARGUMENTS</em></p>

<p>Call <a href="#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29" title="(MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION)"><code>APPLY-MONITOR</code></a> on each monitor in <code>MONITORS</code> and <code>ARGUMENTS</code>. This
qqqqis how an event is fired.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>APPLY-MONITOR</strong> <em>MONITOR &amp;REST ARGUMENTS</em></p>

<p>Apply <code>MONITOR</code> to <code>ARGUMENTS</code>. This sound fairly
generic, because it is. <code>MONITOR</code> can be anything, even a simple
function or symbol, in which case this is just <code>CL:APPLY</code>. See
<a href="#x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITOR MGL-PAX:SECTION)">Monitors</a> for more.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACOUNTER-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>COUNTER</strong> <em>MONITOR</em></p>

<p>Return an object representing the state of <code>MONITOR</code>
or <code>NIL</code>, if it doesn't have any (say because it's a simple logging
function). Most monitors have counters into which they accumulate
results until they are printed and reset. See <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">Counters</a> for
more.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMONITOR-MODEL-RESULTS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MONITOR-MODEL-RESULTS</strong> <em>FN DATASET MODEL MONITORS</em></p>

<p>Call <code>FN</code> with batches of instances from <code>DATASET</code> until it runs
out (as in <a href="#x-28MGL-CORE-3ADO-BATCHES-FOR-MODEL-20MGL-PAX-3AMACRO-29" title="(MGL-CORE:DO-BATCHES-FOR-MODEL MGL-PAX:MACRO)"><code>DO-BATCHES-FOR-MODEL</code></a>). <code>FN</code> is supposed to apply <code>MODEL</code> to
the batch and return some kind of result (for neural networks, the
result is the model state itself). Apply <code>MONITORS</code> to each batch and
the result returned by <code>FN</code> for that batch. Finally, return the list
of counters of <code>MONITORS</code>.</p>

<p>The purpose of this function is to collect various results and
statistics (such as error measures) efficiently by applying the
model only once, leaving extraction of quantities of interest from
the model's results to <code>MONITORS</code>.</p>

<p>See the model specific versions of this functions such as
MONITOR-BPN-RESULTS.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMONITORS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MONITORS</strong> <em>OBJECT</em></p>

<p>Return monitors associated with <code>OBJECT</code>. See various
methods such as [MONITORS] for more
documentation.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MEASURER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITOR MGL-PAX:SECTION)">&#8634;</a></span>6.1 Monitors</h3>

<p><a name='x-28MGL-CORE-3AMONITOR-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>MONITOR</strong></p>

<p>A monitor that has another monitor called <a href="#x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29" title="(MGL-CORE:MEASURER (MGL-PAX:READER MGL-CORE:MONITOR))"><code>MEASURER</code></a>
embedded in it. When this monitor is applied, it applies the
measurer and passes the returned values to <a href="#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION)"><code>ADD-TO-COUNTER</code></a> called on
its <a href="#x-28MGL-CORE-3ACOUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:COUNTER GENERIC-FUNCTION)"><code>COUNTER</code></a> slot. One may further specialize <a href="#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29" title="(MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION)"><code>APPLY-MONITOR</code></a> to change
that.</p>

<p>This class is useful when the same event monitor is applied
repeatedly over a period and its results must be aggregated such as
when training statistics are being tracked or when predictions are
begin made. Note that the monitor must be compatible with the event
it handles. That is, the embedded <a href="#x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29" title="(MGL-CORE:MEASURER (MGL-PAX:READER MGL-CORE:MONITOR))"><code>MEASURER</code></a> must be prepared to take
the arguments that are documented to come with the event.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29'></a></p>

<ul>
<li><p>[reader] <strong>MEASURER</strong> <em>MONITOR</em> <em>(:MEASURER)</em></p>

<p>This must be a monitor itself which only means
that <a href="#x-28MGL-CORE-3AAPPLY-MONITOR-20GENERIC-FUNCTION-29" title="(MGL-CORE:APPLY-MONITOR GENERIC-FUNCTION)"><code>APPLY-MONITOR</code></a> is defined on it (but see <a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">Monitoring</a>). The
returned values are aggregated by <a href="#x-28MGL-CORE-3ACOUNTER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29" title="(MGL-CORE:COUNTER (MGL-PAX:READER MGL-CORE:MONITOR))"><code>COUNTER</code></a>. See
<a href="#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MEASURER MGL-PAX:SECTION)">Measurers</a> for a library of measurers.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACOUNTER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29'></a></p>

<ul>
<li><p>[reader] <strong>COUNTER</strong> <em>MONITOR</em> <em>(:COUNTER)</em></p>

<p>The <code>COUNTER</code> of a monitor carries out the
aggregation of results returned by <a href="#x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29" title="(MGL-CORE:MEASURER (MGL-PAX:READER MGL-CORE:MONITOR))"><code>MEASURER</code></a>. The See <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">Counters</a>
for a library of counters.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITOR MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MEASURER MGL-PAX:SECTION)">&#8634;</a></span>6.2 Measurers</h3>

<p><a href="#x-28MGL-CORE-3AMEASURER-20-28MGL-PAX-3AREADER-20MGL-CORE-3AMONITOR-29-29" title="(MGL-CORE:MEASURER (MGL-PAX:READER MGL-CORE:MONITOR))"><code>MEASURER</code></a> is a part of <a href="#x-28MGL-CORE-3AMONITOR-20CLASS-29" title="(MGL-CORE:MONITOR CLASS)"><code>MONITOR</code></a> objects, an embedded monitor that
computes a specific quantity (e.g. classification accuracy) from the
arguments of event it is applied to (e.g. the model results).
Measurers are often implemented by combining some kind of model
specific extractor with a generic measurer function.</p>

<p>All generic measurer functions return their results as multiple
values matching the arguments of <a href="#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION)"><code>ADD-TO-COUNTER</code></a> for a counter of a
certain type (see <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">Counters</a>) so as to make them easily used in a
<a href="#x-28MGL-CORE-3AMONITOR-20CLASS-29" title="(MGL-CORE:MONITOR CLASS)"><code>MONITOR</code></a>:</p>

<pre><code>(multiple-value-call #'add-to-counter &lt;some-counter&gt;
                     &lt;call-to-some-measurer&gt;)
</code></pre>

<p>The counter class compatible with the measurer this way is noted for
each function.</p>

<p>For a list of measurer functions see <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MEASURER MGL-PAX:SECTION)">Classification Measurers</a>.</p>

<p><a name='x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MEASURER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MONITORING MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-ATTRIBUTES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-ATTRIBUTES MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">&#8634;</a></span>6.3 Counters</h3>

<p><a name='x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>ADD-TO-COUNTER</strong> <em>COUNTER &amp;REST ARGS</em></p>

<p>Add <code>ARGS</code> to <code>COUNTER</code> in some way. See specialized
methods for type specific documentation. The kind of arguments to be
supported is the what the measurer functions (see <a href="#x-28MGL-CORE-3A-40MGL-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-MEASURER MGL-PAX:SECTION)">Measurers</a>)
intended to be paired with the counter return as multiple values.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACOUNTER-VALUES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>COUNTER-VALUES</strong> <em>COUNTER</em></p>

<p>Return any number of values representing the state
of <code>COUNTER</code>. See specialized methods for type specific
documentation.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACOUNTER-RAW-VALUES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>COUNTER-RAW-VALUES</strong> <em>COUNTER</em></p>

<p>Return any number of values representing the state
of <code>COUNTER</code> in such a way that passing the returned values as
arguments <a href="#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION)"><code>ADD-TO-COUNTER</code></a> on a fresh instance of the same type
recreates the original state.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ARESET-COUNTER-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>RESET-COUNTER</strong> <em>COUNTER</em></p>

<p>Restore state of <code>COUNTER</code> to what it was just after
creation.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-ATTRIBUTES-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-CLASSES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER-CLASSES MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-ATTRIBUTES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-ATTRIBUTES MGL-PAX:SECTION)">&#8634;</a></span>6.3.1 Attributes</h4>

<p><a name='x-28MGL-CORE-3AATTRIBUTED-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>ATTRIBUTED</strong></p>

<p>This is a utility class that all counters subclass.
The <a href="#x-28MGL-CORE-3AATTRIBUTES-20-28MGL-PAX-3AACCESSOR-20MGL-CORE-3AATTRIBUTED-29-29" title="(MGL-CORE:ATTRIBUTES (MGL-PAX:ACCESSOR MGL-CORE:ATTRIBUTED))"><code>ATTRIBUTES</code></a> plist can hold basically anything. Currently the
attributes are only used when printing and they can be specified by
the user. The monitor maker functions such as those in
<a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MONITOR MGL-PAX:SECTION)">Classification Monitors</a> also add attributes of their own to the
counters they create.</p>

<p>With the <code>:PREPEND-ATTRIBUTES</code> initarg when can easily add new
attributes without clobbering the those in the <code>:INITFORM</code>, (<code>:TYPE</code>
&quot;rmse&quot;) in this case.</p>

<pre><code>(princ (make-instance 'rmse-counter
                      :prepend-attributes '(:event &quot;pred.&quot;
                                            :dataset &quot;test&quot;)))
;; pred. test rmse: 0.000e+0 (0)
=&gt; #&lt;RMSE-COUNTER pred. test rmse: 0.000e+0 (0)&gt;
</code></pre></li>
</ul>

<p><a name='x-28MGL-CORE-3AATTRIBUTES-20-28MGL-PAX-3AACCESSOR-20MGL-CORE-3AATTRIBUTED-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>ATTRIBUTES</strong> <em>ATTRIBUTED</em> <em>(:ATTRIBUTES = NIL)</em></p>

<p>A plist of attribute keys and values.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ANAME-20-28METHOD-20NIL-20-28MGL-CORE-3AATTRIBUTED-29-29-29'></a></p>

<ul>
<li><p>[method] <strong>NAME</strong> <em>(ATTRIBUTED ATTRIBUTED)</em></p>

<p>Return a string assembled from the values of the <a href="#x-28MGL-CORE-3AATTRIBUTES-20-28MGL-PAX-3AACCESSOR-20MGL-CORE-3AATTRIBUTED-29-29" title="(MGL-CORE:ATTRIBUTES (MGL-PAX:ACCESSOR MGL-CORE:ATTRIBUTED))"><code>ATTRIBUTES</code></a> of
<code>ATTRIBUTED</code>. If there are multiple entries with the same key, then
they are printed near together.</p>

<p>Values may be padded according to an enclosing
<a href="#x-28MGL-CORE-3AWITH-PADDED-ATTRIBUTE-PRINTING-20MGL-PAX-3AMACRO-29" title="(MGL-CORE:WITH-PADDED-ATTRIBUTE-PRINTING MGL-PAX:MACRO)"><code>WITH-PADDED-ATTRIBUTE-PRINTING</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AWITH-PADDED-ATTRIBUTE-PRINTING-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>WITH-PADDED-ATTRIBUTE-PRINTING</strong> <em>(ATTRIBUTEDS) &amp;BODY BODY</em></p>

<p>Note the width of values for each attribute key which is the number
of characters in the value's <code>PRINC-TO-STRING</code>'ed representation. In
<code>BODY</code>, if attributes with they same key are printed they are forced
to be at least this wide. This allows for nice, table-like output:</p>

<pre><code>(let ((attributeds
        (list (make-instance 'basic-counter
                             :attributes '(:a 1 :b 23 :c 456))
              (make-instance 'basic-counter
                             :attributes '(:a 123 :b 45 :c 6)))))
  (with-padded-attribute-printing (attributeds)
    (map nil (lambda (attributed)
               (format t &quot;~A~%&quot; attributed))
         attributeds)))
;; 1   23 456: 0.000e+0 (0)
;; 123 45 6  : 0.000e+0 (0)
</code></pre></li>
</ul>

<p><a name='x-28MGL-CORE-3ALOG-PADDED-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>LOG-PADDED</strong> <em>ATTRIBUTEDS</em></p>

<p>Log (see <code>LOG-MSG</code>) <code>ATTRIBUTEDS</code> non-escaped (as in <code>PRINC</code> or ~A) with
the output being as table-like as possible.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-COUNTER-CLASSES-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-ATTRIBUTES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-ATTRIBUTES MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-CLASSES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER-CLASSES MGL-PAX:SECTION)">&#8634;</a></span>6.3.2 Counter classes</h4>

<p>In addition to the really basic ones here, also see
<a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-COUNTER MGL-PAX:SECTION)">Classification Counters</a>.</p>

<p><a name='x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>BASIC-COUNTER</strong> <em>ATTRIBUTED</em></p>

<p>A simple counter whose <a href="#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION)"><code>ADD-TO-COUNTER</code></a> takes two
additional parameters: an increment to the internal sums of called
the <code>NUMERATOR</code> and <code>DENOMINATOR</code>. <a href="#x-28MGL-CORE-3ACOUNTER-VALUES-20GENERIC-FUNCTION-29" title="(MGL-CORE:COUNTER-VALUES GENERIC-FUNCTION)"><code>COUNTER-VALUES</code></a> returns two
values:</p>

<ul>
<li><p><code>NUMERATOR</code> divided by <code>DENOMINATOR</code> (or 0 if <code>DENOMINATOR</code> is 0) and</p></li>
<li><p><code>DENOMINATOR</code></p></li>
</ul>

<p>Here is an example the compute the mean of 5 things received in two
batches:</p>

<pre><code> (let ((counter (make-instance 'basic-counter)))
   (add-to-counter counter 6.5 3)
   (add-to-counter counter 3.5 2)
   counter)
 =&gt; #&lt;BASIC-COUNTER 2.00000e+0 (5)&gt;
</code></pre></li>
</ul>

<p><a name='x-28MGL-CORE-3ARMSE-COUNTER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>RMSE-COUNTER</strong> <em>BASIC-COUNTER</em></p>

<p>A <a href="#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29" title="(MGL-CORE:BASIC-COUNTER CLASS)"><code>BASIC-COUNTER</code></a> with whose nominator accumulates
the square of some statistics. It has the attribute <code>:TYPE</code> &quot;rmse&quot;.
<a href="#x-28MGL-CORE-3ACOUNTER-VALUES-20GENERIC-FUNCTION-29" title="(MGL-CORE:COUNTER-VALUES GENERIC-FUNCTION)"><code>COUNTER-VALUES</code></a> returns the square root of what <a href="#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29" title="(MGL-CORE:BASIC-COUNTER CLASS)"><code>BASIC-COUNTER</code></a>'s
<a href="#x-28MGL-CORE-3ACOUNTER-VALUES-20GENERIC-FUNCTION-29" title="(MGL-CORE:COUNTER-VALUES GENERIC-FUNCTION)"><code>COUNTER-VALUES</code></a> would return.</p>

<pre><code>(let ((counter (make-instance 'rmse-counter)))
  (add-to-counter counter (+ (* 3 3) (* 4 4)) 2)
  counter)
=&gt; #&lt;RMSE-COUNTER rmse: 3.53553e+0 (2)&gt;
</code></pre></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONCAT-COUNTER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>CONCAT-COUNTER</strong> <em>ATTRIBUTED</em></p>

<p>A counter that simply concatenates
sequences.</p>

<p>```cl-transcript
(let ((counter (make-instance 'concat-counter)))
  (add-to-counter counter '(1 2 3) #(4 5))
  (add-to-counter counter '(6 7))
  (counter-values counter))
=&gt; (1 2 3 4 5 6 7)
````</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONCATENATION-TYPE-20-28MGL-PAX-3AREADER-20MGL-CORE-3ACONCAT-COUNTER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>CONCATENATION-TYPE</strong> <em>CONCAT-COUNTER</em> <em>(:CONCATENATION-TYPE = 'LIST)</em></p>

<p>A type designator suitable as the RESULT-TYPE
argument to <code>CONCATENATE</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-COUNTER-CLASSES-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-COUNTER-CLASSES MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MONITOR MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION MGL-PAX:SECTION)">&#8634;</a></span>7 Classification</h2>

<h6>[in package MGL-CORE]</h6>

<p>To be able to measure classification related quantities, we need to
define what the label of an instance is. Customization is possible
by implementing a method for a specific type of instance, but these
functions only ever appear as defaults that can be overridden.</p>

<p><a name='x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>LABEL-INDEX</strong> <em>INSTANCE</em></p>

<p>Return the label of <code>INSTANCE</code> as a non-negative
integer.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTION-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>LABEL-INDEX-DISTRIBUTION</strong> <em>INSTANCE</em></p>

<p>Return a one dimensional array of probabilities
representing the distribution of labels. The probability of the
label with <a href="#x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29" title="(MGL-CORE:LABEL-INDEX GENERIC-FUNCTION)"><code>LABEL-INDEX</code></a> <code>I</code> is element at index <code>I</code> of the returned
arrray.</p></li>
</ul>

<p>The following two functions are basically the same as the previous
two, but in batch mode: they return a sequence of label indices or
distributions. These are called on results produced by models.
Implement these for a model and the monitor maker functions below
will automatically work. See FIXDOC: for bpn and boltzmann.</p>

<p><a name='x-28MGL-CORE-3ALABEL-INDICES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>LABEL-INDICES</strong> <em>RESULTS</em></p>

<p>Return a sequence of label indices for <code>RESULTS</code>
produced by some model for a batch of instances. This is akin to
<a href="#x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29" title="(MGL-CORE:LABEL-INDEX GENERIC-FUNCTION)"><code>LABEL-INDEX</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTIONS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>LABEL-INDEX-DISTRIBUTIONS</strong> <em>RESULT</em></p>

<p>Return a sequence of label index distributions for
<code>RESULTS</code> produced by some model for a batch of instances. This is
akin to <a href="#x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTION-20GENERIC-FUNCTION-29" title="(MGL-CORE:LABEL-INDEX-DISTRIBUTION GENERIC-FUNCTION)"><code>LABEL-INDEX-DISTRIBUTION</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MEASURER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MONITOR MGL-PAX:SECTION)">&#8634;</a></span>7.1 Classification Monitors</h3>

<p>The following functions return a list monitors. The monitors are
for events of signature (<code>INSTANCES</code> <code>MODEL</code>) such as those produced by
<a href="#x-28MGL-CORE-3AMONITOR-MODEL-RESULTS-20FUNCTION-29" title="(MGL-CORE:MONITOR-MODEL-RESULTS FUNCTION)"><code>MONITOR-MODEL-RESULTS</code></a> and its various model specific variations.
They are model-agnostic functions, extensible to new classifier
types. </p>

<p><a name='x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-CLASSIFICATION-ACCURACY-MONITORS</strong> <em>MODEL &amp;KEY OPERATION-MODE ATTRIBUTES (LABEL-INDEX-FN #'LABEL-INDEX)</em></p>

<p>Return a list of <a href="#x-28MGL-CORE-3AMONITOR-20CLASS-29" title="(MGL-CORE:MONITOR CLASS)"><code>MONITOR</code></a> objects associated with
<a href="#x-28MGL-CORE-3ACLASSIFICATION-ACCURACY-COUNTER-20CLASS-29" title="(MGL-CORE:CLASSIFICATION-ACCURACY-COUNTER CLASS)"><code>CLASSIFICATION-ACCURACY-COUNTER</code></a>s. <code>LABEL-INDEX-FN</code> is a function
like <a href="#x-28MGL-CORE-3ALABEL-INDEX-20GENERIC-FUNCTION-29" title="(MGL-CORE:LABEL-INDEX GENERIC-FUNCTION)"><code>LABEL-INDEX</code></a>. See that function for more.</p>

<p>Implemented in terms of <a href="#x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-2A-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAKE-CLASSIFICATION-ACCURACY-MONITORS* GENERIC-FUNCTION)"><code>MAKE-CLASSIFICATION-ACCURACY-MONITORS*</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-CROSS-ENTROPY-MONITORS</strong> <em>MODEL &amp;KEY OPERATION-MODE ATTRIBUTES (LABEL-INDEX-DISTRIBUTION-FN #'LABEL-INDEX-DISTRIBUTION)</em></p>

<p>Return a list of <a href="#x-28MGL-CORE-3AMONITOR-20CLASS-29" title="(MGL-CORE:MONITOR CLASS)"><code>MONITOR</code></a> objects associated with
<a href="#x-28MGL-CORE-3ACROSS-ENTROPY-COUNTER-20CLASS-29" title="(MGL-CORE:CROSS-ENTROPY-COUNTER CLASS)"><code>CROSS-ENTROPY-COUNTER</code></a>s. <code>LABEL-INDEX-DISTRIBUTION-FN</code> is a
function like <a href="#x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTION-20GENERIC-FUNCTION-29" title="(MGL-CORE:LABEL-INDEX-DISTRIBUTION GENERIC-FUNCTION)"><code>LABEL-INDEX-DISTRIBUTION</code></a>. See that function for more.</p>

<p>Implemented in terms of <a href="#x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-2A-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAKE-CROSS-ENTROPY-MONITORS* GENERIC-FUNCTION)"><code>MAKE-CROSS-ENTROPY-MONITORS*</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAKE-LABEL-MONITORS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-LABEL-MONITORS</strong> <em>MODEL &amp;KEY OPERATION-MODE ATTRIBUTES (LABEL-INDEX-FN #'LABEL-INDEX) (LABEL-INDEX-DISTRIBUTION-FN #'LABEL-INDEX-DISTRIBUTION)</em></p>

<p>Return classification accuracy and cross-entropy monitors. See
<a href="#x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-20FUNCTION-29" title="(MGL-CORE:MAKE-CLASSIFICATION-ACCURACY-MONITORS FUNCTION)"><code>MAKE-CLASSIFICATION-ACCURACY-MONITORS</code></a> and
<a href="#x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-20FUNCTION-29" title="(MGL-CORE:MAKE-CROSS-ENTROPY-MONITORS FUNCTION)"><code>MAKE-CROSS-ENTROPY-MONITORS</code></a> for a description of paramters.</p></li>
</ul>

<p>The monitor makers above can be extended to support new classifier
types via the following generic functions.</p>

<p><a name='x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-2A-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAKE-CLASSIFICATION-ACCURACY-MONITORS*</strong> <em>MODEL OPERATION-MODE LABEL-INDEX-FN ATTRIBUTES</em></p>

<p>Identical to <a href="#x-28MGL-CORE-3AMAKE-CLASSIFICATION-ACCURACY-MONITORS-20FUNCTION-29" title="(MGL-CORE:MAKE-CLASSIFICATION-ACCURACY-MONITORS FUNCTION)"><code>MAKE-CLASSIFICATION-ACCURACY-MONITORS</code></a>
bar the keywords arguments. Specialize this to add to support for
new model types. The default implementation also allows for some
extensibility: if <a href="#x-28MGL-CORE-3ALABEL-INDICES-20GENERIC-FUNCTION-29" title="(MGL-CORE:LABEL-INDICES GENERIC-FUNCTION)"><code>LABEL-INDICES</code></a> is defined on <code>MODEL</code>, then it will be
used to extract label indices from model results.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-2A-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAKE-CROSS-ENTROPY-MONITORS*</strong> <em>MODEL OPERATION-MODE LABEL-INDEX-DISTRIBUTION-FN ATTRIBUTES</em></p>

<p>Identical to <a href="#x-28MGL-CORE-3AMAKE-CROSS-ENTROPY-MONITORS-20FUNCTION-29" title="(MGL-CORE:MAKE-CROSS-ENTROPY-MONITORS FUNCTION)"><code>MAKE-CROSS-ENTROPY-MONITORS</code></a> bar the
keywords arguments. Specialize this to add to support for new model
types. The default implementation also allows for some
extensibility: if <a href="#x-28MGL-CORE-3ALABEL-INDEX-DISTRIBUTIONS-20GENERIC-FUNCTION-29" title="(MGL-CORE:LABEL-INDEX-DISTRIBUTIONS GENERIC-FUNCTION)"><code>LABEL-INDEX-DISTRIBUTIONS</code></a> is defined on <code>MODEL</code>,
then it will be used to extract label distributions from model
results.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MONITOR MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-COUNTER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MEASURER MGL-PAX:SECTION)">&#8634;</a></span>7.2 Classification Measurers</h3>

<p>The functions here compare some known good solution (also known as
<em>ground truth</em> or <em>target</em>) to a prediction or approximation and
return some measure of their [dis][]similarity. They are model
independent, hence one has to extract the ground truths and
predictions first. Rarely used directly, they are mostly hidden
behind <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MONITOR-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MONITOR MGL-PAX:SECTION)">Classification Monitors</a>.</p>

<p><a name='x-28MGL-CORE-3AMEASURE-CLASSIFICATION-ACCURACY-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MEASURE-CLASSIFICATION-ACCURACY</strong> <em>TRUTHS PREDICTIONS &amp;KEY (TEST #'EQL) TRUTH-KEY PREDICTION-KEY WEIGHT</em></p>

<p>Return the number of correct classifications and as the second
value the number of instances (equal to length of <code>TRUTHS</code> in the
non-weighted case). <code>TRUTHS</code> (keyed by <code>TRUTH-KEY</code>) is a sequence of
opaque class labels compared with <code>TEST</code> to another sequence of
classes labels in <code>PREDICTIONS</code> (keyed by <code>PREDICTION-KEY</code>). If <code>WEIGHT</code>
is non-nil, then it is a function that returns the weight of an
element of <code>TRUTHS</code>. Weighted cases add their weight to both
counts (returned as the first and second values) instead of 1 as in
the non-weighted case.</p>

<p>Note how the returned values are suitable for <code>MULTIPLE-VALUE-CALL</code>
with #'<a href="#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION)"><code>ADD-TO-COUNTER</code></a> and a <a href="#x-28MGL-CORE-3ACLASSIFICATION-ACCURACY-COUNTER-20CLASS-29" title="(MGL-CORE:CLASSIFICATION-ACCURACY-COUNTER CLASS)"><code>CLASSIFICATION-ACCURACY-COUNTER</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMEASURE-CROSS-ENTROPY-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MEASURE-CROSS-ENTROPY</strong> <em>TRUTHS PREDICTIONS &amp;KEY TRUTH-KEY PREDICTION-KEY (MIN-PREDICTION-PR 1.d-15)</em></p>

<p>Return the sum of the cross-entropy between pairs of elements with
the same index of <code>TRUTHS</code> and <code>PREDICTIONS</code>. <code>TRUTH-KEY</code> is a function
that's when applied to an element of <code>TRUTHS</code> returns a sequence
representing some kind of discrete target distribution (P in the
definition below). <code>TRUTH-KEY</code> may be <code>NIL</code> which is equivalent to the
<code>IDENTITY</code> function. <code>PREDICTION-KEY</code> is the same kind of key for
<code>PREDICTIONS</code>, but the sequence it returns represents a distribution
that approximates (Q below) the true one.</p>

<p>Cross-entropy of the true and approximating distributions is defined
as:</p>

<pre><code>cross-entropy(p,q) = - sum_i p(i) * log(q(i))
</code></pre>

<p>of which this function returns the sum over the pairs of elements of
<code>TRUTHS</code> and <code>PREDICTIONS</code> keyed by <code>TRUTH-KEY</code> and <code>PREDICTION-KEY</code>.</p>

<p>Due to the logarithm, if q(i) is close to zero, we run into
numerical problems. To prevent this, all q(i) that are less than
<code>MIN-PREDICTION-PR</code> are treated as if they were <code>MIN-PREDICTION-PR</code>.</p>

<p>The second value returned is the sum of p(i) over all <code>TRUTHS</code> and all
<code>I</code>. This is normally equal to <code>(LENGTH TRUTHS)</code>, since elements of
<code>TRUTHS</code> represent a probability distribution, but this is not
enforced which allows relative importance of elements to be
controlled.</p>

<p>The third value returned is a plist that maps each index occurring
in the distribution sequences to a list of two elements:</p>

<pre><code> sum_j p_j(i) * log(q_j(i))
</code></pre>

<p>and</p>

<pre><code>sum_j p_j(i)
</code></pre>

<p>where <code>J</code> indexes into <code>TRUTHS</code> and <code>PREDICTIONS</code>.</p>

<pre><code>(measure-cross-entropy '((0 1 0)) '((0.1 0.7 0.2)))
=&gt; 0.35667497
   1
   (2 (0.0 0)
    1 (0.35667497 1)
    0 (0.0 0))
</code></pre>

<p>Note how the returned values are suitable for <code>MULTIPLE-VALUE-CALL</code>
with #'<a href="#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION)"><code>ADD-TO-COUNTER</code></a> and a <a href="#x-28MGL-CORE-3ACROSS-ENTROPY-COUNTER-20CLASS-29" title="(MGL-CORE:CROSS-ENTROPY-COUNTER CLASS)"><code>CROSS-ENTROPY-COUNTER</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMEASURE-ROC-AUC-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MEASURE-ROC-AUC</strong> <em>PREDICTIONS PRED &amp;KEY (KEY #'IDENTITY) WEIGHT</em></p>

<p>Return the area under the ROC curve for <code>PREDICTIONS</code> representing
predictions for a binary classification problem. <code>PRED</code> is a predicate
function for deciding whether a prediction belongs to the so called
positive class. <code>KEY</code> returns a number for each element which is the
predictor's idea of how much that element is likely to belong to the
class, although it's not necessarily a probability.</p>

<p>If <code>WEIGHT</code> is <code>NIL</code>, then all elements of <code>PREDICTIONS</code> count as 1
towards the unnormalized sum within AUC. Else <code>WEIGHT</code> must be a
function like <code>KEY</code>, but it should return the importance (a positive
real number) of elements. If the weight of an prediction is 2 then
it's as if there were another identical copy of that prediction in
<code>PREDICTIONS</code>.</p>

<p>The algorithm is based on algorithm 2 in the paper 'An introduction
to ROC analysis' by Tom Fawcett.</p>

<p>ROC AUC is equal to the probability of a randomly chosen positive
having higher <code>KEY</code> (score) than a randomly chosen negative element.
With equal scores in mind, a more precise version is: AUC is the
expectation of the above probability over all possible sequences
sorted by scores.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMEASURE-CONFUSION-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MEASURE-CONFUSION</strong> <em>TRUTHS PREDICTIONS &amp;KEY (TEST #'EQL) TRUTH-KEY PREDICTION-KEY WEIGHT</em></p>

<p>Create a <a href="#x-28MGL-CORE-3ACONFUSION-MATRIX-20CLASS-29" title="(MGL-CORE:CONFUSION-MATRIX CLASS)"><code>CONFUSION-MATRIX</code></a> from <code>TRUTHS</code> and <code>PREDICTIONS</code>.
<code>TRUTHS</code> (keyed by <code>TRUTH-KEY</code>) is a sequence of class labels compared
with <code>TEST</code> to another sequence of class labels in <code>PREDICTIONS</code> (keyed
by <code>PREDICTION-KEY</code>). If <code>WEIGHT</code> is non-nil, then it is a function that
returns the weight of an element of <code>TRUTHS</code>. Weighted cases add their
weight to both counts (returned as the first and second values).</p>

<p>Note how the returned confusion matrix can be added to another with
<a href="#x-28MGL-CORE-3AADD-TO-COUNTER-20GENERIC-FUNCTION-29" title="(MGL-CORE:ADD-TO-COUNTER GENERIC-FUNCTION)"><code>ADD-TO-COUNTER</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-MEASURER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-MEASURER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CORE-3A-40MGL-CONFUSION-MATRIX-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CONFUSION-MATRIX MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-COUNTER MGL-PAX:SECTION)">&#8634;</a></span>7.3 Classification Counters</h3>

<p><a name='x-28MGL-CORE-3ACLASSIFICATION-ACCURACY-COUNTER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>CLASSIFICATION-ACCURACY-COUNTER</strong> <em>BASIC-COUNTER</em></p>

<p>A <a href="#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29" title="(MGL-CORE:BASIC-COUNTER CLASS)"><code>BASIC-COUNTER</code></a> with &quot;acc.&quot; as its <code>:TYPE</code>
attribute and a <code>PRINT-OBJECT</code> method that prints percentages.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACROSS-ENTROPY-COUNTER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>CROSS-ENTROPY-COUNTER</strong> <em>BASIC-COUNTER</em></p>

<p>A <a href="#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29" title="(MGL-CORE:BASIC-COUNTER CLASS)"><code>BASIC-COUNTER</code></a> with &quot;xent&quot; as its <code>:TYPE</code>
attribute.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3A-40MGL-CONFUSION-MATRIX-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-COUNTER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-CORE-3A-40MGL-CLASSIFICATION-COUNTER-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CLASSIFICATION-COUNTER MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CORE-3A-40MGL-CONFUSION-MATRIX-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CONFUSION-MATRIX MGL-PAX:SECTION)">&#8634;</a></span>7.3.1 Confusion Matrices</h4>

<p><a name='x-28MGL-CORE-3ACONFUSION-MATRIX-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>CONFUSION-MATRIX</strong></p>

<p>A confusion matrix keeps count of classification
results. The correct class is called <code>target' and the output of the
classifier is called</code>prediction'. Classes are compared with
<code>EQUAL</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAKE-CONFUSION-MATRIX-20FUNCTION-29'></a></p>

<ul>
<li>[function] <strong>MAKE-CONFUSION-MATRIX</strong> <em>&amp;KEY (TEST #'EQL)</em></li>
</ul>

<p><a name='x-28MGL-CORE-3ASORT-CONFUSION-CLASSES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SORT-CONFUSION-CLASSES</strong> <em>MATRIX CLASSES</em></p>

<p>Return a list of <code>CLASSES</code> sorted for presentation
purposes.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONFUSION-CLASS-NAME-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>CONFUSION-CLASS-NAME</strong> <em>MATRIX CLASS</em></p>

<p>Name of <code>CLASS</code> for presentation purposes.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONFUSION-COUNT-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li>[generic-function] <strong>CONFUSION-COUNT</strong> <em>MATRIX TARGET PREDICTION</em></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAP-CONFUSION-MATRIX-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAP-CONFUSION-MATRIX</strong> <em>FN MATRIX</em></p>

<p>Call <code>FN</code> with <code>TARGET</code>, <code>PREDICTION</code>,
<code>COUNT</code> paramaters for each cell in the confusion matrix. Cells with a
zero count may be ommitted.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONFUSION-MATRIX-CLASSES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>CONFUSION-MATRIX-CLASSES</strong> <em>MATRIX</em></p>

<p>A list of all classes. The default is to collect
classes from the counts. This can be overridden if, for instance,
some classes are not present in the results.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONFUSION-MATRIX-ACCURACY-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>CONFUSION-MATRIX-ACCURACY</strong> <em>MATRIX &amp;KEY FILTER</em></p>

<p>Return the overall accuracy of the results in <code>MATRIX</code>. It's computed
as the number of correctly classified cases (hits) divided by the
name of cases. Return the number of hits and the number of cases as
the second and third value. If <code>FILTER</code> function is given, then call
it with the target and the prediction of the cell. Disregard cell
for which <code>FILTER</code> returns <code>NIL</code>.</p>

<p>Precision and recall can be easily computed by giving the right
filter, although those are provided in separate convenience
functions.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONFUSION-MATRIX-PRECISION-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>CONFUSION-MATRIX-PRECISION</strong> <em>MATRIX PREDICTION</em></p>

<p>Return the accuracy over the cases when the classifier said
<code>PREDICTION</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ACONFUSION-MATRIX-RECALL-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>CONFUSION-MATRIX-RECALL</strong> <em>MATRIX TARGET</em></p>

<p>Return the accuracy over the cases when the correct class is
<code>TARGET</code>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AADD-CONFUSION-MATRIX-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>ADD-CONFUSION-MATRIX</strong> <em>MATRIX RESULT-MATRIX</em></p>

<p>Add <code>MATRIX</code> into <code>RESULT-MATRIX</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-CORE-3A-40MGL-CONFUSION-MATRIX-20MGL-PAX-3ASECTION-29" title="(MGL-CORE:@MGL-CONFUSION-MATRIX MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-ITERATIVE-OPTIMIZER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8634;</a></span>8 Gradient Based Optimization</h2>

<h6>[in package MGL-OPT]</h6>

<p>We have a real valued, differentiable function F and the task is to
find the parameters that minimize its value. Optimization starts
from a single point in the parameter space of F, and this single
point is updated iteratively based on the gradient and value of F at
or around the current point.</p>

<p>Note that while the stated problem is that of global optimization,
for non-convex functions, most algorithms will tend to converge to a
local optimum.</p>

<p>Currently, there are two optimization algorithms:
<a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">Gradient Descent</a> (with several variants) and <a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">Conjugate Gradient</a> both of
which are first order methods (they do not need second order
gradients) but more can be added with the <a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">Extension API</a>.</p>

<p><a name='x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MINIMIZE</strong> <em>OPTIMIZER GRADIENT-SOURCE &amp;KEY (WEIGHTS (LIST-SEGMENTS GRADIENT-SOURCE)) (DATASET *INFINITELY-EMPTY-DATASET*)</em></p>

<p>Minimize the value of the real valued function represented by
<code>GRADIENT-SOURCE</code> by updating some of its parameters in <code>WEIGHTS</code> (a <code>MAT</code>
or a sequence of MATs). Return <code>WEIGHTS</code>. <code>DATASET</code> (see
<a href="#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-DATASET MGL-PAX:SECTION)">Datasets</a>) is a set of unoptimized parameters of the same
function. For example, <code>WEIGHTS</code> may be the weights of a neural
network while <code>DATASET</code> is the training set consisting of inputs
suitable for <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>. The default
<code>DATASET</code>, (<a href="#x-28MGL-DATASET-3A-2AINFINITELY-EMPTY-DATASET-2A-20VARIABLE-29" title="(MGL-DATASET:*INFINITELY-EMPTY-DATASET* VARIABLE)"><code>*INFINITELY-EMPTY-DATASET*</code></a>) is suitable for when all
parameters are optimized, so there is nothing left to come from the
environment.</p>

<p>Optimization terminates if <code>DATASET</code> is a sampler and it runs out or
when some other condition met (see <a href="#x-28MGL-OPT-3ATERMINATION-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:TERMINATION (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER))"><code>TERMINATION</code></a>, for example). If
<code>DATASET</code> is a <code>SEQUENCE</code>, then it is reused over and over again.</p>

<p>Examples for various optimizers are provided in <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">Gradient Descent</a> and
<a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">Conjugate Gradient</a>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-COST-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-COST MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-ITERATIVE-OPTIMIZER MGL-PAX:SECTION)">&#8634;</a></span>8.1 Iterative Optimizer</h3>

<p><a name='x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>ITERATIVE-OPTIMIZER</strong></p>

<p>An abstract base class of <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">Gradient Descent</a> and
<a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">Conjugate Gradient</a> based optimizers that iterate over instances until a
termination condition is met.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>N-INSTANCES</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:N-INSTANCES = 0)</em></p>

<p>The number of instances this optimizer has seen so
far. Incremented automatically during optimization.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ATERMINATION-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>TERMINATION</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:TERMINATION = NIL)</em></p>

<p>If a number, it's the number of instances to train
on in the sense of <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a>. If <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a> is equal or greater
than this value optimization stops. If <code>TERMINATION</code> is <code>NIL</code>, then
optimization will continue. If it is <code>T</code>, then optimization will
stop. If it is a function of no arguments, then its return value
is processed as if it was returned by <code>TERMINATION</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AON-OPTIMIZATION-STARTED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>ON-OPTIMIZATION-STARTED</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:ON-OPTIMIZATION-STARTED = NIL)</em></p>

<p>An event hook with parameters <code>(OPTIMIZER
GRADIENT-SOURCE N-INSTANCES)</code>. Called after initializations are
performed (INITIALIZE-OPTIMIZER<em>, INITIALIZE-GRADIENT-SOURCE</em>) but
before optimization is started.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AON-OPTIMIZATION-FINISHED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>ON-OPTIMIZATION-FINISHED</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:ON-OPTIMIZATION-FINISHED = NIL)</em></p>

<p>An event hook with parameters <code>(OPTIMIZER
GRADIENT-SOURCE N-INSTANCES)</code>. Called when optimization has
finished.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>ON-N-INSTANCES-CHANGED</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:ON-N-INSTANCES-CHANGED = NIL)</em></p>

<p>An event hook with parameters <code>(OPTIMIZER
GRADIENT-SOURCE N-INSTANCES)</code>. Called when optimization of a batch
of instances is done and <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a> is incremented.</p></li>
</ul>

<p>Now let's discuss a few handy utilities.</p>

<p><a name='x-28MGL-OPT-3AMONITOR-OPTIMIZATION-PERIODICALLY-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MONITOR-OPTIMIZATION-PERIODICALLY</strong> <em>OPTIMIZER PERIODIC-FNS</em></p>

<p>For each periodic function in the list of <code>PERIODIC-FNS</code>, add a
monitor to <code>OPTIMIZER</code>'s <a href="#x-28MGL-OPT-3AON-OPTIMIZATION-STARTED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:ON-OPTIMIZATION-STARTED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER))"><code>ON-OPTIMIZATION-STARTED</code></a>,
<a href="#x-28MGL-OPT-3AON-OPTIMIZATION-FINISHED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:ON-OPTIMIZATION-FINISHED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER))"><code>ON-OPTIMIZATION-FINISHED</code></a> and <a href="#x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:ON-N-INSTANCES-CHANGED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER))"><code>ON-N-INSTANCES-CHANGED</code></a> hooks. The
monitors are simple functions that just call each periodic function
with the event parameters (<code>OPTIMIZER</code> <code>GRADIENT-SOURCE</code> <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a>).
Return <code>OPTIMIZER</code>.</p>

<p>To log and reset the monitors of the gradient source after every
1000 instances seen by <code>OPTIMIZER</code>:</p>

<pre><code>(monitor-optimization-periodically optimizer
                                   '((:fn log-my-test-error
                                      :period 2000)
                                     (:fn reset-optimization-monitors
                                      :period 1000
                                      :last-eval 0)))
</code></pre>

<p>Note how we don't pass it's allowed to just pass the initargs for a
<code>PERIODIC-FN</code> instead of <code>PERIODIC-FN</code> itself. The <code>:LAST-EVAL</code> 0 bit
prevents <a href="#x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20GENERIC-FUNCTION-29" title="(MGL-OPT:RESET-OPTIMIZATION-MONITORS GENERIC-FUNCTION)"><code>RESET-OPTIMIZATION-MONITORS</code></a> from being called at the start
of the optimization when the monitors are empty anyway.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>RESET-OPTIMIZATION-MONITORS</strong> <em>OPTIMIZER GRADIENT-SOURCE</em></p>

<p>Report the state of <a href="#x-28MGL-CORE-3AMONITORS-20GENERIC-FUNCTION-29" title="(MGL-CORE:MONITORS GENERIC-FUNCTION)"><code>MONITORS</code></a> of
<code>OPTIMIZER</code> and <code>GRADIENT-SOURCE</code> and reset their counters. See
<a href="#x-28MGL-OPT-3AMONITOR-OPTIMIZATION-PERIODICALLY-20FUNCTION-29" title="(MGL-OPT:MONITOR-OPTIMIZATION-PERIODICALLY FUNCTION)"><code>MONITOR-OPTIMIZATION-PERIODICALLY</code></a> for an example of how this is
used.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20-28METHOD-20NIL-20-28MGL-OPT-3AITERATIVE-OPTIMIZER-20T-29-29-29'></a></p>

<ul>
<li><p>[method] <strong>RESET-OPTIMIZATION-MONITORS</strong> <em>(OPTIMIZER ITERATIVE-OPTIMIZER) GRADIENT-SOURCE</em></p>

<p>Log the counters of the monitors of <code>OPTIMIZER</code> and <code>GRADIENT-SOURCE</code>
and reset them.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AREPORT-OPTIMIZATION-PARAMETERS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>REPORT-OPTIMIZATION-PARAMETERS</strong> <em>OPTIMIZER GRADIENT-SOURCE</em></p>

<p>A utility that's often called at the start of
optimization (from <a href="#x-28MGL-OPT-3AON-OPTIMIZATION-STARTED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:ON-OPTIMIZATION-STARTED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER))"><code>ON-OPTIMIZATION-STARTED</code></a>). The default
implementation logs the description of <code>GRADIENT-SOURCE</code> (as in
<code>DESCRIBE</code>) and <code>OPTIMIZER</code> and calls <code>LOG-MAT-ROOM</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3A-40MGL-OPT-COST-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-OPT-3A-40MGL-OPT-ITERATIVE-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-ITERATIVE-OPTIMIZER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-COST-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-COST MGL-PAX:SECTION)">&#8634;</a></span>8.2 Cost Function</h3>

<p>The function being minimized is often called the <em>cost</em> or the
<em>loss</em> function.</p>

<p><a name='x-28MGL-COMMON-3ACOST-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>COST</strong> <em>MODEL</em></p>

<p>Return the value of the cost function being
minimized. Calling this only makes sense in the context of an
ongoing optimization (see <a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MINIMIZE</code></a>). The cost is that of a batch of
instances.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AMAKE-COST-MONITORS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-COST-MONITORS</strong> <em>MODEL &amp;KEY OPERATION-MODE ATTRIBUTES</em></p>

<p>Return a list of <a href="#x-28MGL-CORE-3AMONITOR-20CLASS-29" title="(MGL-CORE:MONITOR CLASS)"><code>MONITOR</code></a> objects, each associated with one
<a href="#x-28MGL-CORE-3ABASIC-COUNTER-20CLASS-29" title="(MGL-CORE:BASIC-COUNTER CLASS)"><code>BASIC-COUNTER</code></a> with attribute <code>:TYPE</code> &quot;cost&quot;. Implemented in terms of
<a href="#x-28MGL-OPT-3AMAKE-COST-MONITORS-2A-20GENERIC-FUNCTION-29" title="(MGL-OPT:MAKE-COST-MONITORS* GENERIC-FUNCTION)"><code>MAKE-COST-MONITORS*</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AMAKE-COST-MONITORS-2A-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAKE-COST-MONITORS*</strong> <em>MODEL OPERATION-MODE ATTRIBUTES</em></p>

<p>Identical to <a href="#x-28MGL-OPT-3AMAKE-COST-MONITORS-20FUNCTION-29" title="(MGL-OPT:MAKE-COST-MONITORS FUNCTION)"><code>MAKE-COST-MONITORS</code></a> bar the keywords
arguments. Specialize this to add to support for new model types.</p></li>
</ul>

<p><a name='x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-OPT-3A-40MGL-OPT-COST-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-COST MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-BATCH-GD-OPTIMIZER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8634;</a></span>8.3 Gradient Descent</h3>

<h6>[in package MGL-GD]</h6>

<p>Gradient descent is a first-order optimization algorithm. Relying
completely on first derivatives, it does not even evaluate the
function to be minimized. Let's see how to minimize a numerical lisp
function with respect to some of its parameters.</p>

<p><a name='x-28MGL-GD-3A-3ASGD-2ELISP-20-28MGL-PAX-3AINCLUDE-20-23P-22-2Fhome-2Fmega-2Fown-2Fmgl-2Fexample-2Fsgd-2Elisp-22-20-3AHEADER-NL-20-22-60-60-60commonlisp-22-20-3AFOOTER-NL-20-22-60-60-60-22-29-29'></a></p>

<pre><code><span class="code"><span class="paren1">(<span class="code"><i><span class="symbol">cl:defpackage</span></i> <span class="keyword">:mgl-example-sgd</span>
  <span class="paren2">(<span class="code"><span class="keyword">:use</span> <span class="keyword">#:common-lisp</span> <span class="keyword">#:mgl</span></span>)</span></span>)</span>

<span class="paren1">(<span class="code">in-package <span class="keyword">:mgl-example-sgd</span></span>)</span>

<span class="comment">;;; Create an object representing the sine function.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*diff-fn-1*</span>
  <span class="paren2">(<span class="code">make-instance 'mgl-diffun:diffun
                 <span class="keyword">:fn</span> #'sin
                 <span class="comment">;; We are going to optimize its only parameter.
</span>                 <span class="keyword">:weight-indices</span> '<span class="paren3">(<span class="code">0</span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Minimize SIN. Note that there is no dataset involved because all
</span><span class="comment">;;; parameters are being optimized.
</span><span class="paren1">(<span class="code">minimize <span class="paren2">(<span class="code">make-instance 'batch-gd-optimizer <span class="keyword">:termination</span> 1000</span>)</span>
          <span class="special">*diff-fn-1*</span>
          <span class="keyword">:weights</span> <span class="paren2">(<span class="code">make-mat 1</span>)</span></span>)</span>
<span class="comment">;;; =&gt; A MAT with a single value of about -pi/2.
</span>
<span class="comment">;;; Create a differentiable function for f(x,y)=(x-y)^2. X is a
</span><span class="comment">;;; parameter whose values come from the DATASET argument passed to
</span><span class="comment">;;; MINIMIZE. Y is a parameter to be optimized (a 'weight').
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*diff-fn-2*</span>
  <span class="paren2">(<span class="code">make-instance 'mgl-diffun:diffun
                 <span class="keyword">:fn</span> <span class="paren3">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren4">(<span class="code">x y</span>)</span>
                       <span class="paren4">(<span class="code">expt <span class="paren5">(<span class="code">- x y</span>)</span> 2</span>)</span></span>)</span>
                 <span class="keyword">:parameter-indices</span> '<span class="paren3">(<span class="code">0</span>)</span>
                 <span class="keyword">:weight-indices</span> '<span class="paren3">(<span class="code">1</span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Find the Y that minimizes the distance from the instances
</span><span class="comment">;;; generated by the sampler.
</span><span class="paren1">(<span class="code">minimize <span class="paren2">(<span class="code">make-instance 'batch-gd-optimizer <span class="keyword">:batch-size</span> 10</span>)</span>
          <span class="special">*diff-fn-2*</span>
          <span class="keyword">:weights</span> <span class="paren2">(<span class="code">make-mat 1</span>)</span>
          <span class="keyword">:dataset</span> <span class="paren2">(<span class="code">make-instance 'function-sampler
                                  <span class="keyword">:generator</span> <span class="paren3">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren4">(<span class="code"></span>)</span>
                                               <span class="paren4">(<span class="code">list <span class="paren5">(<span class="code">+ 10
                                                        <span class="paren6">(<span class="code">gaussian-random-1</span>)</span></span>)</span></span>)</span></span>)</span>
                                  <span class="keyword">:max-n-samples</span> 1000</span>)</span></span>)</span>
<span class="comment">;;; =&gt; A MAT with a single value of about 10, the expected value of
</span><span class="comment">;;; the instances in the dataset.
</span>
<span class="comment">;;; The dataset can be a SEQUENCE in which case we'd better set
</span><span class="comment">;;; TERMINATION else optimization would never finish.
</span><span class="paren1">(<span class="code">minimize <span class="paren2">(<span class="code">make-instance 'batch-gd-optimizer
                         <span class="keyword">:termination</span> 1000</span>)</span>
          <span class="special">*diff-fn-2*</span>
          <span class="keyword">:weights</span> <span class="paren2">(<span class="code">make-mat 1</span>)</span>
          <span class="keyword">:dataset</span> '<span class="paren2">(<span class="code"><span class="paren3">(<span class="code">0</span>)</span> <span class="paren3">(<span class="code">1</span>)</span> <span class="paren3">(<span class="code">2</span>)</span> <span class="paren3">(<span class="code">3</span>)</span> <span class="paren3">(<span class="code">4</span>)</span> <span class="paren3">(<span class="code">5</span>)</span></span>)</span></span>)</span>
<span class="comment">;;; =&gt; A MAT with a single value of about 2.5.</span></span></code></pre>

<p>We are going to see a number of accessors for optimizer paramaters.
In general, it's allowed to <code>SETF</code> real slot accessors (as opposed to
readers and writers) at any time during optimization and so is
defining a method on an optimizer subclass that computes the value
in any way. For example, to decay the learning rate on a per
mini-batch basis:</p>

<pre><code>(defmethod learning-rate ((optimizer my-batch-gd-optimizer))
  (* (slot-value optimizer 'learning-rate)
     (expt 0.998
           (/ (n-instances optimizer) 60000))))
</code></pre>

<p><a name='x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-SEGMENTED-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-SEGMENTED-GD-OPTIMIZER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-BATCH-GD-OPTIMIZER MGL-PAX:SECTION)">&#8634;</a></span>8.3.1 Batch GD Optimizer</h4>

<p><a name='x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>BATCH-GD-OPTIMIZER</strong> <em>GD-OPTIMIZER</em></p>

<p>Updates all weights simultaneously after chewing
through <code>BATCH-SIZE</code>(<a href="#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29" title="(MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER))"><code>1</code></a>) inputs. <a href="#x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29" title="(MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER CLASS)"><code>PER-WEIGHT-BATCH-GD-OPTIMIZER</code></a> may be a
better choice when some weights can go unused for instance due to
missing input values.</p>

<p>Assuming that <code>ACCUMULATOR</code> has the sum of gradients for a mini-batch,
the weight update looks like this:</p>

<pre><code>delta_w' += momentum * delta_w +
            accumulator / batch_size + l2 * w + l1 * sign(w)

w' -= learning_rate * delta_w'
</code></pre>

<p>which is the same as the more traditional formulation:</p>

<pre><code>delta_w' += momentum * delta_w +
            learning_rate * (df/dw / batch_size + l2 * w + l1 * sign(w))

w' -= delta_w'
</code></pre>

<p>but the former works better when batch size, momentum or learning
rate change during the course of optimization. The above is with
normal momentum, Nesterov's momentum (see <a href="#x-28MGL-GD-3AMOMENTUM-TYPE-20-28MGL-PAX-3AREADER-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-GD:MOMENTUM-TYPE (MGL-PAX:READER MGL-GD::GD-OPTIMIZER))"><code>MOMENTUM-TYPE</code></a>) momentum is
also available.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>N-INSTANCES</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:N-INSTANCES = 0)</em></p>

<p>The number of instances this optimizer has seen so
far. Incremented automatically during optimization.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ATERMINATION-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>TERMINATION</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:TERMINATION = NIL)</em></p>

<p>If a number, it's the number of instances to train
on in the sense of <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a>. If <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a> is equal or greater
than this value optimization stops. If <code>TERMINATION</code> is <code>NIL</code>, then
optimization will continue. If it is <code>T</code>, then optimization will
stop. If it is a function of no arguments, then its return value
is processed as if it was returned by <code>TERMINATION</code>.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>BATCH-SIZE</strong> <em>GD-OPTIMIZER</em> <em>(:BATCH-SIZE = 1)</em></p>

<p>After having gone through <code>BATCH-SIZE</code> number of
inputs, weights are updated. With <code>BATCH-SIZE</code> 1, one gets
Stochastics Gradient Descent. With <code>BATCH-SIZE</code> equal to the number
of instances in the dataset, one gets standard, 'batch' gradient
descent. With <code>BATCH-SIZE</code> between these two extremes, one gets the
most practical 'mini-batch' compromise.</p></li>
</ul>

<p><a name='x-28MGL-GD-3ALEARNING-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>LEARNING-RATE</strong> <em>GD-OPTIMIZER</em> <em>(:LEARNING-RATE = 0.1)</em></p>

<p>This is the step size along the gradient. Decrease
it if optimization diverges, increase it if it doesn't make
progress.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AMOMENTUM-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>MOMENTUM</strong> <em>GD-OPTIMIZER</em> <em>(:MOMENTUM = 0)</em></p>

<p>A value in the [0, 1) interval. <code>MOMENTUM</code> times the
previous weight change is added to the gradient. 0 means no
momentum.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AMOMENTUM-TYPE-20-28MGL-PAX-3AREADER-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>MOMENTUM-TYPE</strong> <em>GD-OPTIMIZER</em> <em>(:MOMENTUM-TYPE = :NORMAL)</em></p>

<p>One of <code>:NORMAL</code>, <code>:NESTEROV</code> or <code>:NONE</code>. For pure
optimization Nesterov's momentum may be better, but it may also
increases chances of overfitting. Using <code>:NONE</code> is equivalent to 0
momentum, but it also uses less memory. Note that with <code>:NONE</code>,
<a href="#x-28MGL-GD-3AMOMENTUM-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-GD:MOMENTUM (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER))"><code>MOMENTUM</code></a> is ignored even it it is non-zero.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AWEIGHT-DECAY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>WEIGHT-DECAY</strong> <em>GD-OPTIMIZER</em> <em>(:WEIGHT-DECAY = 0)</em></p>

<p>An L2 penalty. It discourages large weights, much
like a zero mean gaussian prior. <code>WEIGHT-DECAY</code> * WEIGHT is added to
the gradient to penalize large weights. It's as if the function
whose minimum is sought had WEIGHT-DECAY*sum_i{0.5 * WEIGHT_i^2}
added to it.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AWEIGHT-PENALTY-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>WEIGHT-PENALTY</strong> <em>GD-OPTIMIZER</em> <em>(:WEIGHT-PENALTY = 0)</em></p>

<p>An L1 penalty. It encourages sparsity.
<code>SIGN</code>(WEIGHT) * <code>WEIGHT-PENALTY</code> is added to the gradient pushing the
weight towards negative infinity. It's as if the function whose
minima is sought had WEIGHT-PENALTY*sum_i{abs(WEIGHT_i)} added to
it. Putting it on feature biases consitutes a sparsity constraint
on the features.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AUSE-SEGMENT-DERIVATIVES-P-20-28MGL-PAX-3AREADER-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>USE-SEGMENT-DERIVATIVES-P</strong> <em>GD-OPTIMIZER</em> <em>(:USE-SEGMENT-DERIVATIVES-P = NIL)</em></p>

<p>Save memory if both the gradient source (the model
being optimized) and the optimizer support this feature. It works
like this: the accumulator into which the gradient source is asked
to place the derivatives of a segment will be <a href="#x-28MGL-OPT-3ASEGMENT-DERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-OPT:SEGMENT-DERIVATIVES GENERIC-FUNCTION)"><code>SEGMENT-DERIVATIVES</code></a>
of the segment. This allows the optimizer not to allocate an
accumulator matrix into which the derivatives are summed.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AAFTER-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>AFTER-UPDATE-HOOK</strong> <em>GD-OPTIMIZER</em> <em>(:AFTER-UPDATE-HOOK = NIL)</em></p>

<p>A list of functions with no arguments called after
each weight update.</p></li>
</ul>

<p><a name='x-28MGL-GD-3ABEFORE-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3ABATCH-GD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>BEFORE-UPDATE-HOOK</strong> <em>BATCH-GD-OPTIMIZER</em> <em>(:BEFORE-UPDATE-HOOK = NIL)</em></p>

<p>A list of functions of no parameters. Each
function is called just before a weight update takes place (after
accumulated gradients have been divided the length of the batch).
Convenient to hang some additional gradient accumulating code
on.</p></li>
</ul>

<p><a name='x-28MGL-GD-3A-40MGL-GD-SEGMENTED-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-GD-3A-40MGL-GD-BATCH-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-BATCH-GD-OPTIMIZER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-PER-WEIGHT-OPTIMIZATION-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-PER-WEIGHT-OPTIMIZATION MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-SEGMENTED-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-SEGMENTED-GD-OPTIMIZER MGL-PAX:SECTION)">&#8634;</a></span>8.3.2 Segmented GD Optimizer</h4>

<p><a name='x-28MGL-GD-3ASEGMENTED-GD-OPTIMIZER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>SEGMENTED-GD-OPTIMIZER</strong> <em>BASE-GD-OPTIMIZER</em></p>

<p>An optimizer that delegates training of segments to
other optimizers. Useful to delegate training of different segments
to different optimizers (capable of working with segmentables) or
simply to not train all segments.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>N-INSTANCES</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:N-INSTANCES = 0)</em></p>

<p>The number of instances this optimizer has seen so
far. Incremented automatically during optimization.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ATERMINATION-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>TERMINATION</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:TERMINATION = NIL)</em></p>

<p>If a number, it's the number of instances to train
on in the sense of <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a>. If <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a> is equal or greater
than this value optimization stops. If <code>TERMINATION</code> is <code>NIL</code>, then
optimization will continue. If it is <code>T</code>, then optimization will
stop. If it is a function of no arguments, then its return value
is processed as if it was returned by <code>TERMINATION</code>.</p></li>
</ul>

<p><a name='x-28MGL-GD-3ASEGMENTER-20-28MGL-PAX-3AREADER-20MGL-GD-3ASEGMENTED-GD-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>SEGMENTER</strong> <em>SEGMENTED-GD-OPTIMIZER</em> <em>(:SEGMENTER)</em></p>

<p>When this optimizer is initialized it loops over
the segment of the learner with <a href="#x-28MGL-OPT-3AMAP-SEGMENTS-20GENERIC-FUNCTION-29" title="(MGL-OPT:MAP-SEGMENTS GENERIC-FUNCTION)"><code>MAP-SEGMENTS</code></a>. <code>SEGMENTER</code> is a
function that is called with each segment and returns an optimizer
or <code>NIL</code>. Several segments may be mapped to the same optimizer.
After the segment-&gt;optimizer mappings are collected, each
optimizer is initialized by INITIALIZE-OPTIMIZER with the list of
segments mapped to it.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENTS-20-28MGL-PAX-3AREADER-20MGL-GD-3ASEGMENTED-GD-OPTIMIZER-29-29'></a></p>

<ul>
<li>[reader] <strong>SEGMENTS</strong> <em>SEGMENTED-GD-OPTIMIZER</em></li>
</ul>

<p><a name='x-28MGL-GD-3A-40MGL-GD-PER-WEIGHT-OPTIMIZATION-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-GD-3A-40MGL-GD-SEGMENTED-GD-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-SEGMENTED-GD-OPTIMIZER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-ADAM-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-ADAM-OPTIMIZER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-PER-WEIGHT-OPTIMIZATION-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-PER-WEIGHT-OPTIMIZATION MGL-PAX:SECTION)">&#8634;</a></span>8.3.3 Per-weight Optimization</h4>

<p><a name='x-28MGL-GD-3ANORMALIZED-BATCH-GD-OPTIMIZER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>NORMALIZED-BATCH-GD-OPTIMIZER</strong> <em>BATCH-GD-OPTIMIZER</em></p>

<p>Like <a href="#x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29" title="(MGL-GD:BATCH-GD-OPTIMIZER CLASS)"><code>BATCH-GD-OPTIMIZER</code></a> but keeps count of how many
times each weight was used in the batch and divides the accumulated
gradient by this count instead of dividing by <code>N-INSTANCES-IN-BATCH</code>.
This only makes a difference if there are missing values in the
learner that's being trained. The main feature that distuinguishes
this class from <a href="#x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29" title="(MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER CLASS)"><code>PER-WEIGHT-BATCH-GD-OPTIMIZER</code></a> is that batches end at
same time for all weights.</p></li>
</ul>

<p><a name='x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>PER-WEIGHT-BATCH-GD-OPTIMIZER</strong> <em>GD-OPTIMIZER</em></p>

<p>This is much like <a href="#x-28MGL-GD-3ABATCH-GD-OPTIMIZER-20CLASS-29" title="(MGL-GD:BATCH-GD-OPTIMIZER CLASS)"><code>BATCH-GD-OPTIMIZER</code></a> but it is more
clever about when to update weights. Basically every weight has its
own batch independent from the batches of others. It has desirable
properties. One can for example put two neural networks together
without adding any connections between them and the learning will
produce results equivalent to the separated case. Also, adding
inputs with only missing values does not change anything.</p></li>
</ul>

<p><a name='x-28MGL-GD-3A-40MGL-GD-ADAM-OPTIMIZER-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-GD-3A-40MGL-GD-PER-WEIGHT-OPTIMIZATION-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-PER-WEIGHT-OPTIMIZATION MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-UTILITIES MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-ADAM-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-ADAM-OPTIMIZER MGL-PAX:SECTION)">&#8634;</a></span>8.3.4 Adam Optimizer</h4>

<p><a name='x-28MGL-GD-3AADAM-OPTIMIZER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>ADAM-OPTIMIZER</strong> <em>BATCH-GD-OPTIMIZER</em></p>

<p>Adam is a first-order stochasistic gradient descent
optimizer. It maintains an internal estimation for the mean and raw
variance of each derivative as exponential moving averages. The step
is takes is basically <code>M/(sqrt(V)+E)</code> where <code>M</code> is the estimated
mean, <code>V</code> is the estimated variance, and <code>E</code> is a small adjustment
factor to prevent the gradient from blowing up. See the
<a href="http://arxiv.org/abs/1412.6980" >paper</a> for more.</p></li>
</ul>

<p><a name='x-28MGL-GD-3ALEARNING-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>LEARNING-RATE</strong> <em>ADAM-OPTIMIZER</em> <em>(= 2.e-4)</em></p>

<p>Same thing as <a href="#x-28MGL-GD-3ALEARNING-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-GD:LEARNING-RATE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER))"><code>LEARNING-RATE</code></a> but with the default suggested by the Adam paper.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AMEAN-UPDATE-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>MEAN-UPDATE-RATE</strong> <em>ADAM-OPTIMIZER</em> <em>(:MEAN-UPDATE-RATE = 0.1)</em></p>

<p>A number between 0 and 1 that determines how fast
the estimated mean of derivatives is updated. 1 basically gives
you RMSPROP (if <a href="#x-28MGL-GD-3AVARIANCE-UPDATE-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29" title="(MGL-GD:VARIANCE-UPDATE-RATE (MGL-PAX:ACCESSOR MGL-GD:ADAM-OPTIMIZER))"><code>VARIANCE-UPDATE-RATE</code></a> is not too small) or
AdaGrad (if <a href="#x-28MGL-GD-3AVARIANCE-UPDATE-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29" title="(MGL-GD:VARIANCE-UPDATE-RATE (MGL-PAX:ACCESSOR MGL-GD:ADAM-OPTIMIZER))"><code>VARIANCE-UPDATE-RATE</code></a> is infinitesimal and the learning
rate is annealed.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AVARIANCE-UPDATE-RATE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>VARIANCE-UPDATE-RATE</strong> <em>ADAM-OPTIMIZER</em> <em>(:VARIANCE-UPDATE-RATE = 0.001)</em></p>

<p>A number between 0 and 1 that determines how fast
the estimated variance of derivatives is updated.</p></li>
</ul>

<p><a name='x-28MGL-GD-3AVARIANCE-ADJUSTMENT-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3AADAM-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>VARIANCE-ADJUSTMENT</strong> <em>ADAM-OPTIMIZER</em> <em>(:VARIANCE-ADJUSTMENT = 1.e-8)</em></p>

<p>Within the bowels of adam, the estimated mean is
divided by the square root of the estimated variance (per weight)
which can lead to numerical problems if the denominator is near
zero. To avoid this, <code>VARIANCE-ADJUSTMENT</code> which should be a small
positive number is added to the denominator.</p></li>
</ul>

<p><a name='x-28MGL-GD-3A-40MGL-GD-UTILITIES-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-GD-3A-40MGL-GD-ADAM-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-ADAM-OPTIMIZER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-GD-3A-40MGL-GD-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-UTILITIES MGL-PAX:SECTION)">&#8634;</a></span>8.3.5 Utilities</h4>

<p><a name='x-28MGL-GD-3ACLIP-GRADIENTS-20FUNCTION-29'></a></p>

<ul>
<li>[function] <strong>CLIP-GRADIENTS</strong> <em>MATS L2-UPPER-BOUND &amp;KEY CALLBACK</em></li>
</ul>

<p><a name='x-28MGL-GD-3AARRANGE-FOR-CLIPPING-GRADIENTS-20FUNCTION-29'></a></p>

<ul>
<li>[function] <strong>ARRANGE-FOR-CLIPPING-GRADIENTS</strong> <em>BATCH-GD-OPTIMIZER L2-UPPER-BOUND &amp;KEY CALLBACK</em></li>
</ul>

<p><a name='x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-GD-3A-40MGL-GD-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD-UTILITIES MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">&#8634;</a></span>8.4 Conjugate Gradient</h3>

<h6>[in package MGL-CG]</h6>

<p>Conjugate gradient is a first-order optimization algorithm. It's
more advanced than gradient descent as it does line searches which
unfortunately also makes it unsuitable for non-deterministic
functions. Let's see how to minimize a numerical lisp function with
respect to some of its parameters.</p>

<pre><code><span class="code"><span class="comment">;;; Create an object representing the sine function.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*diff-fn-1*</span>
  <span class="paren2">(<span class="code">make-instance 'mgl-diffun:diffun
                 <span class="keyword">:fn</span> #'sin
                 <span class="comment">;; We are going to optimize its only parameter.
</span>                 <span class="keyword">:weight-indices</span> '<span class="paren3">(<span class="code">0</span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Minimize SIN. Note that there is no dataset involved because all
</span><span class="comment">;;; parameters are being optimized.
</span><span class="paren1">(<span class="code">minimize <span class="paren2">(<span class="code">make-instance 'cg-optimizer
                         <span class="keyword">:batch-size</span> 1
                         <span class="keyword">:termination</span> 1</span>)</span>
          <span class="special">*diff-fn-1*</span>
          <span class="keyword">:weights</span> <span class="paren2">(<span class="code">make-mat 1</span>)</span></span>)</span>
<span class="comment">;;; =&gt; A MAT with a single value of about -pi/2.
</span>
<span class="comment">;;; Create a differentiable function for f(x,y)=(x-y)^2. X is a
</span><span class="comment">;;; parameter whose values come from the DATASET argument passed to
</span><span class="comment">;;; MINIMIZE. Y is a parameter to be optimized (a 'weight').
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*diff-fn-2*</span>
  <span class="paren2">(<span class="code">make-instance 'mgl-diffun:diffun
                 <span class="keyword">:fn</span> <span class="paren3">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren4">(<span class="code">x y</span>)</span>
                       <span class="paren4">(<span class="code">expt <span class="paren5">(<span class="code">- x y</span>)</span> 2</span>)</span></span>)</span>
                 <span class="keyword">:parameter-indices</span> '<span class="paren3">(<span class="code">0</span>)</span>
                 <span class="keyword">:weight-indices</span> '<span class="paren3">(<span class="code">1</span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Find the Y that minimizes the distance from the instances
</span><span class="comment">;;; generated by the sampler.
</span><span class="paren1">(<span class="code">minimize <span class="paren2">(<span class="code">make-instance 'cg-optimizer <span class="keyword">:batch-size</span> 10</span>)</span>
          <span class="special">*diff-fn-2*</span>
          <span class="keyword">:weights</span> <span class="paren2">(<span class="code">make-mat 1</span>)</span>
          <span class="keyword">:dataset</span> <span class="paren2">(<span class="code">make-instance 'function-sampler
                                  <span class="keyword">:generator</span> <span class="paren3">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren4">(<span class="code"></span>)</span>
                                               <span class="paren4">(<span class="code">list <span class="paren5">(<span class="code">+ 10
                                                        <span class="paren6">(<span class="code">gaussian-random-1</span>)</span></span>)</span></span>)</span></span>)</span>
                                  <span class="keyword">:max-n-samples</span> 1000</span>)</span></span>)</span>
<span class="comment">;;; =&gt; A MAT with a single value of about 10, the expected value of
</span><span class="comment">;;; the instances in the dataset.
</span>
<span class="comment">;;; The dataset can be a SEQUENCE in which case we'd better set
</span><span class="comment">;;; TERMINATION else optimization would never finish. Note how a
</span><span class="comment">;;; single epoch suffices.
</span><span class="paren1">(<span class="code">minimize <span class="paren2">(<span class="code">make-instance 'cg-optimizer <span class="keyword">:termination</span> 6</span>)</span>
          <span class="special">*diff-fn-2*</span>
          <span class="keyword">:weights</span> <span class="paren2">(<span class="code">make-mat 1</span>)</span>
          <span class="keyword">:dataset</span> '<span class="paren2">(<span class="code"><span class="paren3">(<span class="code">0</span>)</span> <span class="paren3">(<span class="code">1</span>)</span> <span class="paren3">(<span class="code">2</span>)</span> <span class="paren3">(<span class="code">3</span>)</span> <span class="paren3">(<span class="code">4</span>)</span> <span class="paren3">(<span class="code">5</span>)</span></span>)</span></span>)</span>
<span class="comment">;;; =&gt; A MAT with a single value of about 2.5.</span></span></code></pre>

<p><a name='x-28MGL-CG-3ACG-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>CG</strong> <em>FN W &amp;KEY (MAX-N-LINE-SEARCHES *DEFAULT-MAX-N-LINE-SEARCHES*) (MAX-N-EVALUATIONS-PER-LINE-SEARCH *DEFAULT-MAX-N-EVALUATIONS-PER-LINE-SEARCH*) (MAX-N-EVALUATIONS *DEFAULT-MAX-N-EVALUATIONS*) (SIG *DEFAULT-SIG*) (RHO *DEFAULT-RHO*) (INT *DEFAULT-INT*) (EXT *DEFAULT-EXT*) (RATIO *DEFAULT-RATIO*) SPARE-VECTORS</em></p>

<p><a href="#x-28MGL-CG-3ACG-OPTIMIZER-20CLASS-29" title="(MGL-CG:CG-OPTIMIZER CLASS)"><code>CG-OPTIMIZER</code></a> passes each batch of data to this function with its
<a href="#x-28MGL-CG-3ACG-ARGS-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29" title="(MGL-CG:CG-ARGS (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER))"><code>CG-ARGS</code></a> passed on.</p>

<p>Minimize a differentiable multivariate function with conjugate
gradient. The Polak-Ribiere flavour of conjugate gradients is used
to compute search directions, and a line search using quadratic and
cubic polynomial approximations and the Wolfe-Powell stopping
criteria is used together with the slope ratio method for guessing
initial step sizes. Additionally a bunch of checks are made to make
sure that exploration is taking place and that extrapolation will
not be unboundedly large.</p>

<p><code>FN</code> is a function of two parameters: <code>WEIGHTS</code>(<a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>0</code></a> <a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>1</code></a>) and <code>DERIVATIVES</code>. <code>WEIGHTS</code>(<a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>0</code></a> <a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>1</code></a>)
is a <code>MAT</code> of the same size as <code>W</code> that is where the search start from.
<code>DERIVATIVES</code> is also a <code>MAT</code> of that size and it is where <code>FN</code> shall
place the partial derivatives. <code>FN</code> returns the value of the function
that is being minimized.</p>

<p><a href="#x-28MGL-CG-3ACG-20FUNCTION-29" title="(MGL-CG:CG FUNCTION)"><code>CG</code></a> performs a number of line searches and invokes <code>FN</code> at each step. A
line search invokes <code>FN</code> at most <code>MAX-N-EVALUATIONS-PER-LINE-SEARCH</code>
number of times and can succeed in improving the minimum by the
sufficient margin or it can fail. Note, the even a failed line
search may improve further and hence change the weights it's just
that the improvement was deemed too small. <a href="#x-28MGL-CG-3ACG-20FUNCTION-29" title="(MGL-CG:CG FUNCTION)"><code>CG</code></a> stops when either:</p>

<ul>
<li><p>two line searches fail in a row</p></li>
<li><p><code>MAX-N-LINE-SEARCHES</code> is reached</p></li>
<li><p><code>MAX-N-EVALUATIONS</code> is reached</p></li>
</ul>

<p><a href="#x-28MGL-CG-3ACG-20FUNCTION-29" title="(MGL-CG:CG FUNCTION)"><code>CG</code></a> returns a <code>MAT</code> that contains the best weights, the minimum, the
number of line searches performed, the number of succesful line
searches and the number of evaluations.</p>

<p>When using <code>MAX-N-EVALUATIONS</code> remember that there is an extra
evaluation of <code>FN</code> before the first line search.</p>

<p><code>SPARE-VECTORS</code> is a list of preallocated MATs of the same size as <code>W</code>.
Passing 6 of them covers the current need of the algorithm and it
will not cons up vectors of size <code>W</code> at all.</p>

<p>NOTE: If the function terminates within a few iterations, it could
be an indication that the function values and derivatives are not
consistent (ie, there may be a bug in the implementation of <code>FN</code>
function).</p>

<p><code>SIG</code> and <code>RHO</code> are the constants controlling the Wolfe-Powell
conditions. <code>SIG</code> is the maximum allowed absolute ratio between
previous and new slopes (derivatives in the search direction), thus
setting <code>SIG</code> to low (positive) values forces higher precision in the
line-searches. <code>RHO</code> is the minimum allowed fraction of the
expected (from the slope at the initial point in the linesearch).
Constants must satisfy 0 &lt; <code>RHO</code> &lt; <code>SIG</code> &lt; 1. Tuning of <code>SIG</code> (depending
on the nature of the function to be optimized) may speed up the
minimization; it is probably not worth playing much with <code>RHO</code>.</p></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-INT-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*DEFAULT-INT*</strong> <em>0.1</em></p>

<p>Don't reevaluate within <code>INT</code> of the limit of the current bracket.</p></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-EXT-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*DEFAULT-EXT*</strong> <em>3</em></p>

<p>Extrapolate maximum <code>EXT</code> times the current step-size.</p></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-SIG-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*DEFAULT-SIG*</strong> <em>0.1</em></p>

<p><code>SIG</code> and <code>RHO</code> are the constants controlling the Wolfe-Powell
conditions. <code>SIG</code> is the maximum allowed absolute ratio between
previous and new slopes (derivatives in the search direction), thus
setting <code>SIG</code> to low (positive) values forces higher precision in the
line-searches.</p></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-RHO-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*DEFAULT-RHO*</strong> <em>0.05</em></p>

<p><code>RHO</code> is the minimum allowed fraction of the expected (from the slope
at the initial point in the linesearch). Constants must satisfy 0 &lt;
<code>RHO</code> &lt; <code>SIG</code> &lt; 1.</p></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-RATIO-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*DEFAULT-RATIO*</strong> <em>10</em></p>

<p>Maximum allowed slope ratio.</p></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-MAX-N-LINE-SEARCHES-2A-20VARIABLE-29'></a></p>

<ul>
<li>[variable] <strong>*DEFAULT-MAX-N-LINE-SEARCHES*</strong> <em>NIL</em></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-MAX-N-EVALUATIONS-PER-LINE-SEARCH-2A-20VARIABLE-29'></a></p>

<ul>
<li>[variable] <strong>*DEFAULT-MAX-N-EVALUATIONS-PER-LINE-SEARCH*</strong> <em>20</em></li>
</ul>

<p><a name='x-28MGL-CG-3A-2ADEFAULT-MAX-N-EVALUATIONS-2A-20VARIABLE-29'></a></p>

<ul>
<li>[variable] <strong>*DEFAULT-MAX-N-EVALUATIONS*</strong> <em>NIL</em></li>
</ul>

<p><a name='x-28MGL-CG-3ACG-OPTIMIZER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>CG-OPTIMIZER</strong> <em>ITERATIVE-OPTIMIZER</em></p>

<p>Updates all weights simultaneously after chewing
through <code>BATCH-SIZE</code>(<a href="#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29" title="(MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER))"><code>1</code></a>) inputs.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>N-INSTANCES</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:N-INSTANCES = 0)</em></p>

<p>The number of instances this optimizer has seen so
far. Incremented automatically during optimization.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ATERMINATION-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>TERMINATION</strong> <em>ITERATIVE-OPTIMIZER</em> <em>(:TERMINATION = NIL)</em></p>

<p>If a number, it's the number of instances to train
on in the sense of <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a>. If <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a> is equal or greater
than this value optimization stops. If <code>TERMINATION</code> is <code>NIL</code>, then
optimization will continue. If it is <code>T</code>, then optimization will
stop. If it is a function of no arguments, then its return value
is processed as if it was returned by <code>TERMINATION</code>.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>BATCH-SIZE</strong> <em>CG-OPTIMIZER</em> <em>(:BATCH-SIZE)</em></p>

<p>After having gone through <code>BATCH-SIZE</code> number of
instances, weights are updated. Normally, <a href="#x-28MGL-CG-3ACG-20FUNCTION-29" title="(MGL-CG:CG FUNCTION)"><code>CG</code></a> operates on all
available data, but it may be useful to introduce some noise into
the optimization to reduce overfitting by using smaller batch
sizes. If <code>BATCH-SIZE</code> is not set, it is initialized to the size of
the dataset at the start of optimization.</p></li>
</ul>

<p><a name='x-28MGL-CG-3ACG-ARGS-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29'></a></p>

<ul>
<li>[accessor] <strong>CG-ARGS</strong> <em>CG-OPTIMIZER</em> <em>(:CG-ARGS = 'NIL)</em></li>
</ul>

<p><a name='x-28MGL-CG-3AON-CG-BATCH-DONE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>ON-CG-BATCH-DONE</strong> <em>CG-OPTIMIZER</em> <em>(:ON-CG-BATCH-DONE = NIL)</em></p>

<p>An event hook called when processing a conjugate
gradient batch is done. The handlers on the hook are called with 8
arguments:</p>

<pre><code>(optimizer gradient-source instances
 best-w best-f n-line-searches
 n-succesful-line-searches n-evaluations)
</code></pre>

<p>The latter 5 of which are the return values of the <a href="#x-28MGL-CG-3ACG-20FUNCTION-29" title="(MGL-CG:CG FUNCTION)"><code>CG</code></a> function.</p></li>
</ul>

<p><a name='x-28MGL-CG-3ALOG-CG-BATCH-DONE-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>LOG-CG-BATCH-DONE</strong> <em>OPTIMIZER GRADIENT-SOURCE INSTANCES BEST-W BEST-F N-LINE-SEARCHES N-SUCCESFUL-LINE-SEARCHES N-EVALUATIONS</em></p>

<p>This is a function can be added to
<a href="#x-28MGL-CG-3AON-CG-BATCH-DONE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29" title="(MGL-CG:ON-CG-BATCH-DONE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER))"><code>ON-CG-BATCH-DONE</code></a>. The default implementation simply logs the event
arguments.</p></li>
</ul>

<p><a name='x-28MGL-CG-3ASEGMENT-FILTER-20-28MGL-PAX-3AREADER-20MGL-CG-3ACG-OPTIMIZER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>SEGMENT-FILTER</strong> <em>CG-OPTIMIZER</em> <em>(:SEGMENT-FILTER = (CONSTANTLY T))</em></p>

<p>A predicate function on segments that filters out
uninteresting segments. Called from <a href="#x-28MGL-OPT-3AINITIALIZE-OPTIMIZER-2A-20GENERIC-FUNCTION-29" title="(MGL-OPT:INITIALIZE-OPTIMIZER* GENERIC-FUNCTION)"><code>INITIALIZE-OPTIMIZER*</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-OPTIMIZER MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">&#8634;</a></span>8.5 Extension API</h3>

<p><a name='x-28MGL-OPT-3A-40MGL-OPT-OPTIMIZER-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SOURCE MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-OPTIMIZER MGL-PAX:SECTION)">&#8634;</a></span>8.5.1 Implementing Optimizers</h4>

<p>The following generic functions must be specialized for new
optimizer types.</p>

<p><a name='x-28MGL-OPT-3AMINIMIZE-2A-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MINIMIZE*</strong> <em>OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET</em></p>

<p>Called by <a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MINIMIZE</code></a> after <a href="#x-28MGL-OPT-3AINITIALIZE-OPTIMIZER-2A-20GENERIC-FUNCTION-29" title="(MGL-OPT:INITIALIZE-OPTIMIZER* GENERIC-FUNCTION)"><code>INITIALIZE-OPTIMIZER*</code></a> and
<a href="#x-28MGL-OPT-3AINITIALIZE-GRADIENT-SOURCE-2A-20GENERIC-FUNCTION-29" title="(MGL-OPT:INITIALIZE-GRADIENT-SOURCE* GENERIC-FUNCTION)"><code>INITIALIZE-GRADIENT-SOURCE*</code></a>, this generic function is the main
extension point for writing optimizers.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AINITIALIZE-OPTIMIZER-2A-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>INITIALIZE-OPTIMIZER*</strong> <em>OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET</em></p>

<p>Called automatically before training starts, this
function sets up <code>OPTIMIZER</code> to be suitable for optimizing
<code>GRADIENT-SOURCE</code>. It typically creates appropriately sized
accumulators for the gradients.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SEGMENTS</strong> <em>OPTIMIZER</em></p>

<p>Several weight matrices known as <em>segments</em> can be
optimized by a single optimizer. This function returns them as a
list.</p></li>
</ul>

<p>The rest are just useful for utilities for implementing
optimizers.</p>

<p><a name='x-28MGL-OPT-3ATERMINATE-OPTIMIZATION-P-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>TERMINATE-OPTIMIZATION-P</strong> <em>N-INSTANCES TERMINATION</em></p>

<p>Utility function for subclasses of <a href="#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29" title="(MGL-OPT:ITERATIVE-OPTIMIZER CLASS)"><code>ITERATIVE-OPTIMIZER</code></a>. It returns
whether optimization is to be terminated based on <code>N-INSTANCES</code> and
<code>TERMINATION</code> that are values of the respective accessors of
<a href="#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29" title="(MGL-OPT:ITERATIVE-OPTIMIZER CLASS)"><code>ITERATIVE-OPTIMIZER</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASET-N-INSTANCES-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SET-N-INSTANCES</strong> <em>OPTIMIZER GRADIENT-SOURCE N-INSTANCES</em></p>

<p>Set <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a> of <code>OPTIMIZER</code> and
fire <a href="#x-28MGL-OPT-3AON-N-INSTANCES-CHANGED-20-28MGL-PAX-3AACCESSOR-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:ON-N-INSTANCES-CHANGED (MGL-PAX:ACCESSOR MGL-OPT:ITERATIVE-OPTIMIZER))"><code>ON-N-INSTANCES-CHANGED</code></a>. <a href="#x-28MGL-OPT-3AITERATIVE-OPTIMIZER-20CLASS-29" title="(MGL-OPT:ITERATIVE-OPTIMIZER CLASS)"><code>ITERATIVE-OPTIMIZER</code></a> subclasses must
call this to increment <a href="#x-28MGL-OPT-3AN-INSTANCES-20-28MGL-PAX-3AREADER-20MGL-OPT-3AITERATIVE-OPTIMIZER-29-29" title="(MGL-OPT:N-INSTANCES (MGL-PAX:READER MGL-OPT:ITERATIVE-OPTIMIZER))"><code>N-INSTANCES</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENT-SET-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>SEGMENT-SET</strong></p>

<p>This is a utility class for optimizers that have a
list of <a href="#x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29" title="(MGL-OPT:SEGMENTS GENERIC-FUNCTION)"><code>SEGMENTS</code></a> and (the weights being optimized) is able to copy
back and forth between those segments and a single <code>MAT</code> (the
accumulator).</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENTS-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29'></a></p>

<ul>
<li><p>[reader] <strong>SEGMENTS</strong> <em>SEGMENT-SET</em> <em>(:SEGMENTS)</em></p>

<p>A list of weight matrices.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29'></a></p>

<ul>
<li><p>[reader] <strong>SIZE</strong> <em>SEGMENT-SET</em></p>

<p>The sum of the sizes of the weight matrices of
<a href="#x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29" title="(MGL-OPT:SEGMENTS GENERIC-FUNCTION)"><code>SEGMENTS</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ADO-SEGMENT-SET-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>DO-SEGMENT-SET</strong> <em>(SEGMENT &amp;OPTIONAL START) SEGMENT-SET &amp;BODY BODY</em></p>

<p>Iterate over <a href="#x-28MGL-OPT-3ASEGMENTS-20GENERIC-FUNCTION-29" title="(MGL-OPT:SEGMENTS GENERIC-FUNCTION)"><code>SEGMENTS</code></a> in <code>SEGMENT-SET</code>. If <code>START</code> is specified, the it
is bound to the start index of <code>SEGMENT</code> within <code>SEGMENT-SET</code>. The start
index is the sum of the sizes of previous segments.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENT-SET-3C-MAT-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SEGMENT-SET&lt;-MAT</strong> <em>SEGMENT-SET MAT</em></p>

<p>Copy the values of <code>MAT</code> to the weight matrices of <code>SEGMENT-SET</code> as if
they were concatenated into a single <code>MAT</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENT-SET--3EMAT-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>SEGMENT-SET-&gt;MAT</strong> <em>SEGMENT-SET MAT</em></p>

<p>Copy the values of <code>SEGMENT-SET</code> to <code>MAT</code> as if they were concatenated
into a single <code>MAT</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-OPT-3A-40MGL-OPT-OPTIMIZER-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-OPTIMIZER MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SINK-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SINK MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SOURCE MGL-PAX:SECTION)">&#8634;</a></span>8.5.2 Implementing Gradient Sources</h4>

<p>Weights can be stored in a multitude of ways. Optimizers need to
update weights, so it is assumed that weights are stored in any
number of <code>MAT</code> objects called segments.</p>

<p>The generic functions in this section must all be specialized for
new gradient sources except where noted.</p>

<p><a name='x-28MGL-OPT-3AMAP-SEGMENTS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAP-SEGMENTS</strong> <em>FN GRADIENT-SOURCE</em></p>

<p>Apply <code>FN</code> to each segment of <code>GRADIENT-SOURCE</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AMAP-SEGMENT-RUNS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAP-SEGMENT-RUNS</strong> <em>FN SEGMENT</em></p>

<p>Call <code>FN</code> with start and end of intervals of
consecutive indices that are not missing in <code>SEGMENT</code>. Called by
optimizers that support partial updates. The default implementation
assumes that all weights are present. This only needs to be
specialized if one plans to use an optimizer that knows how to deal
unused/missing weights such as <a href="#x-28MGL-GD-3ANORMALIZED-BATCH-GD-OPTIMIZER-20CLASS-29" title="(MGL-GD:NORMALIZED-BATCH-GD-OPTIMIZER CLASS)"><code>MGL-GD:NORMALIZED-BATCH-GD-OPTIMIZER</code></a>
and <code>OPTIMIZER</code> <a href="#x-28MGL-GD-3APER-WEIGHT-BATCH-GD-OPTIMIZER-20CLASS-29" title="(MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER CLASS)"><code>MGL-GD:PER-WEIGHT-BATCH-GD-OPTIMIZER</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENT-WEIGHTS-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SEGMENT-WEIGHTS</strong> <em>SEGMENT</em></p>

<p>Return the weight matrix of <code>SEGMENT</code>. A segment
doesn't need to be a <code>MAT</code> object itself. For example, it may be a
<code>MGL-BM:CHUNK</code> of a [MGL-BM:BM] or a <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>MGL-BP:LUMP</code></a> of a
<a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>MGL-BP:BPN</code></a> whose <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> slot holds the weights.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENT-WEIGHTS-20-28METHOD-20NIL-20-28MGL-MAT-3AMAT-29-29-29'></a></p>

<ul>
<li><p>[method] <strong>SEGMENT-WEIGHTS</strong> <em>(MAT MAT)</em></p>

<p>When the segment is really a <code>MAT</code>, then just return it.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ASEGMENT-DERIVATIVES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>SEGMENT-DERIVATIVES</strong> <em>SEGMENT</em></p>

<p>Return the derivatives matrix of <code>SEGMENT</code>. A segment
doesn't need to be a <code>MAT</code> object itself. For example, it may be a
<code>MGL-BM:CHUNK</code> of a [MGL-BM:BM] or a <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>MGL-BP:LUMP</code></a> of a
<a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>MGL-BP:BPN</code></a> whose DERIVATIVES slot holds the gradient.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ALIST-SEGMENTS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>LIST-SEGMENTS</strong> <em>GRADIENT-SOURCE</em></p>

<p>A utility function that returns the list of segments from
<a href="#x-28MGL-OPT-3AMAP-SEGMENTS-20GENERIC-FUNCTION-29" title="(MGL-OPT:MAP-SEGMENTS GENERIC-FUNCTION)"><code>MAP-SEGMENTS</code></a> on <code>GRADIENT-SOURCE</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AINITIALIZE-GRADIENT-SOURCE-2A-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>INITIALIZE-GRADIENT-SOURCE*</strong> <em>OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET</em></p>

<p>Called automatically before <a href="#x-28MGL-OPT-3AMINIMIZE-2A-20GENERIC-FUNCTION-29" title="(MGL-OPT:MINIMIZE* GENERIC-FUNCTION)"><code>MINIMIZE*</code></a> is called,
this function may be specialized if <code>GRADIENT-SOURCE</code> needs some kind
of setup.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AINITIALIZE-GRADIENT-SOURCE-2A-20-28METHOD-20NIL-20-28T-20T-20T-20T-29-29-29'></a></p>

<ul>
<li><p>[method] <strong>INITIALIZE-GRADIENT-SOURCE*</strong> <em>OPTIMIZER GRADIENT-SOURCE WEIGHTS DATASET</em></p>

<p>The default method does nothing.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3AACCUMULATE-GRADIENTS-2A-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>ACCUMULATE-GRADIENTS*</strong> <em>GRADIENT-SOURCE SINK BATCH MULTIPLIER VALUEP</em></p>

<p>Add <code>MULTIPLIER</code> times the sum of first-order
gradients to accumulators of <code>SINK</code> (normally accessed with
<a href="#x-28MGL-OPT-3ADO-GRADIENT-SINK-20MGL-PAX-3AMACRO-29" title="(MGL-OPT:DO-GRADIENT-SINK MGL-PAX:MACRO)"><code>DO-GRADIENT-SINK</code></a>) and if <code>VALUEP</code>, return the sum of values of the
function being optimized for a <code>BATCH</code> of instances. <code>GRADIENT-SOURCE</code>
is the object representing the function being optimized, <code>SINK</code> is
gradient sink.</p>

<p>Note the number of instances in <code>BATCH</code> may be larger than what
<code>GRADIENT-SOURCE</code> process in one go (in the sense of say,
<a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a>), so <a href="#x-28MGL-CORE-3ADO-BATCHES-FOR-MODEL-20MGL-PAX-3AMACRO-29" title="(MGL-CORE:DO-BATCHES-FOR-MODEL MGL-PAX:MACRO)"><code>DO-BATCHES-FOR-MODEL</code></a> or something like (<code>GROUP</code>
<code>BATCH</code> <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a>) can be handy.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SINK-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SOURCE MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-EXTENSION-API MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-DIFFUN-3A-40MGL-DIFFUN-20MGL-PAX-3ASECTION-29" title="(MGL-DIFFUN:@MGL-DIFFUN MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SINK-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SINK MGL-PAX:SECTION)">&#8634;</a></span>8.5.3 Implementing Gradient Sinks</h4>

<p>Optimizers call <a href="#x-28MGL-OPT-3AACCUMULATE-GRADIENTS-2A-20GENERIC-FUNCTION-29" title="(MGL-OPT:ACCUMULATE-GRADIENTS* GENERIC-FUNCTION)"><code>ACCUMULATE-GRADIENTS*</code></a> on gradient sources. One
parameter of <a href="#x-28MGL-OPT-3AACCUMULATE-GRADIENTS-2A-20GENERIC-FUNCTION-29" title="(MGL-OPT:ACCUMULATE-GRADIENTS* GENERIC-FUNCTION)"><code>ACCUMULATE-GRADIENTS*</code></a> is the <code>SINK</code>. A gradient sink
knows what accumulator matrix (if any) belongs to a segment. Sinks
are defined entirely by <a href="#x-28MGL-OPT-3AMAP-GRADIENT-SINK-20GENERIC-FUNCTION-29" title="(MGL-OPT:MAP-GRADIENT-SINK GENERIC-FUNCTION)"><code>MAP-GRADIENT-SINK</code></a>.</p>

<p><a name='x-28MGL-OPT-3AMAP-GRADIENT-SINK-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAP-GRADIENT-SINK</strong> <em>FN SINK</em></p>

<p>Call <code>FN</code> of lambda list (<code>SEGMENT</code> <code>ACCUMULATOR</code>) on
each segment and their corresponding accumulator <code>MAT</code> in <code>SINK</code>.</p></li>
</ul>

<p><a name='x-28MGL-OPT-3ADO-GRADIENT-SINK-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>DO-GRADIENT-SINK</strong> <em>((SEGMENT ACCUMULATOR) SINK) &amp;BODY BODY</em></p>

<p>A convenience macro on top of <a href="#x-28MGL-OPT-3AMAP-GRADIENT-SINK-20GENERIC-FUNCTION-29" title="(MGL-OPT:MAP-GRADIENT-SINK GENERIC-FUNCTION)"><code>MAP-GRADIENT-SINK</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-DIFFUN-3A-40MGL-DIFFUN-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SINK-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SINK MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-DIFFUN-3A-40MGL-DIFFUN-20MGL-PAX-3ASECTION-29" title="(MGL-DIFFUN:@MGL-DIFFUN MGL-PAX:SECTION)">&#8634;</a></span>9 Differentiable Functions</h2>

<h6>[in package MGL-DIFFUN]</h6>

<p><a name='x-28MGL-DIFFUN-3ADIFFUN-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>DIFFUN</strong></p>

<p><code>DIFFUN</code> dresses a lisp function (in its <a href="#x-28MGL-COMMON-3AFN-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29" title="(MGL-COMMON:FN (MGL-PAX:READER MGL-DIFFUN:DIFFUN))"><code>FN</code></a> slot) as
a gradient source (see <a href="#x-28MGL-OPT-3A-40MGL-OPT-GRADIENT-SOURCE-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT-GRADIENT-SOURCE MGL-PAX:SECTION)">Implementing Gradient Sources</a>) which allows it to
be used in <a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MINIMIZE</code></a>. See the examples in <a href="#x-28MGL-GD-3A-40MGL-GD-20MGL-PAX-3ASECTION-29" title="(MGL-GD:@MGL-GD MGL-PAX:SECTION)">Gradient Descent</a> and
<a href="#x-28MGL-CG-3A-40MGL-CG-20MGL-PAX-3ASECTION-29" title="(MGL-CG:@MGL-CG MGL-PAX:SECTION)">Conjugate Gradient</a>.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3AFN-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>FN</strong> <em>DIFFUN</em> <em>(:FN)</em></p>

<p>A real valued lisp function. It may have any
number of parameters.</p></li>
</ul>

<p><a name='x-28MGL-DIFFUN-3APARAMETER-INDICES-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>PARAMETER-INDICES</strong> <em>DIFFUN</em> <em>(:PARAMETER-INDICES = NIL)</em></p>

<p>The list of indices of parameters that we don't
optimize. Values for these will come from the DATASET argument of
<a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MINIMIZE</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-DIFFUN-3AWEIGHT-INDICES-20-28MGL-PAX-3AREADER-20MGL-DIFFUN-3ADIFFUN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>WEIGHT-INDICES</strong> <em>DIFFUN</em> <em>(:WEIGHT-INDICES = NIL)</em></p>

<p>The list of indices of parameters to be optimized,
the values of which will come from the [WEIGHTS]
argument of <a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MINIMIZE</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-DIFFUN-3A-40MGL-DIFFUN-20MGL-PAX-3ASECTION-29" title="(MGL-DIFFUN:@MGL-DIFFUN MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-OVERVIEW MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8634;</a></span>10 Backpropagation Neural Networks</h2>

<h6>[in package MGL-BP]</h6>

<p><a name='x-28MGL-BP-3A-40MGL-BP-OVERVIEW-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EXTENSION-API MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-OVERVIEW MGL-PAX:SECTION)">&#8634;</a></span>10.1 Backprop Overview</h3>

<p>Backpropagation Neural Networks are just functions with lots of
parameters called <em>weights</em> and a layered structure when presented
as a <a href="http://en.wikipedia.org/wiki/Automatic_differentiation" >computational
graph</a>. The
network is trained to <a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MINIMIZE</code></a> some kind of <em>loss function</em> whose
value the network computes.</p>

<p>In this implementation, a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> is assembled from several
<a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>LUMP</code></a>s (roughly corresponding to layers). Both feed-forward and
recurrent neural nets are supported (<a href="#x-28MGL-BP-3AFNN-20CLASS-29" title="(MGL-BP:FNN CLASS)"><code>FNN</code></a> and <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>, respectively).
<a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>s can contain not only <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>LUMP</code></a>s but other <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>s, too. As we
see, networks are composite objects and the abstract base class for
composite and simple parts is called <a href="#x-28MGL-BP-3ACLUMP-20CLASS-29" title="(MGL-BP:CLUMP CLASS)"><code>CLUMP</code></a>.</p>

<p><a name='x-28MGL-BP-3ACLUMP-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>CLUMP</strong></p>

<p>A <code>CLUMP</code> is a <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>LUMP</code></a> or a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>. It represents
a differentiable function. Arguments of clumps are given during
instantiation. Some arguments are clumps themselves so they get
permenantly wired together like this:</p>

<pre><code><span class="code"><span class="paren1">(<span class="code">-&gt;v*m <span class="paren2">(<span class="code">-&gt;input <span class="keyword">:size</span> 10 <span class="keyword">:name</span> 'input</span>)</span>
       <span class="paren2">(<span class="code">-&gt;weight <span class="keyword">:dimensions</span> '<span class="paren3">(<span class="code">10 20</span>)</span> <span class="keyword">:name</span> 'weight</span>)</span>
       <span class="keyword">:name</span> 'activation</span>)</span></span></code></pre>

<p>The above creates three clumps: the vector-matrix multiplication
clumps called <code>ACTIVATION</code> which has a reference to its operands:
<code>INPUT</code> and <code>WEIGHT</code>. Note that the example just defines a function, no
actual computation has taken place, yet.</p>

<p>This wiring of <code>CLUMP</code>s is how one builds feed-forward nets (<a href="#x-28MGL-BP-3AFNN-20CLASS-29" title="(MGL-BP:FNN CLASS)"><code>FNN</code></a>) or
recurrent neural networks (<a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>) that are <code>CLUMP</code>s themselves so one
can build nets in a hiearchical style if desired. Non-composite
<code>CLUMP</code>s are called <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>LUMP</code></a> (note the loss of <code>C</code> that stands for
composite). The various <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>LUMP</code></a> subtypes correspond to different layer
types (<a href="#x-28MGL-BP-3A--3ESIGMOID-20CLASS-29" title="(MGL-BP:-&gt;SIGMOID CLASS)"><code>-&gt;SIGMOID</code></a>, <a href="#x-28MGL-BP-3A--3EDROPOUT-20CLASS-29" title="(MGL-BP:-&gt;DROPOUT CLASS)"><code>-&gt;DROPOUT</code></a>, <a href="#x-28MGL-BP-3A--3ERELU-20CLASS-29" title="(MGL-BP:-&gt;RELU CLASS)"><code>-&gt;RELU</code></a>, <a href="#x-28MGL-BP-3A--3ETANH-20CLASS-29" title="(MGL-BP:-&gt;TANH CLASS)"><code>-&gt;TANH</code></a>, etc).</p></li>
</ul>

<p>At this point, you may want to jump ahead to get a feel for how
things work by reading the <a href="#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN-TUTORIAL MGL-PAX:SECTION)">FNN Tutorial</a>.</p>

<p><a name='x-28MGL-BP-3A-40MGL-BP-EXTENSION-API-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-OVERVIEW-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-OVERVIEW MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EXTENSION-API MGL-PAX:SECTION)">&#8634;</a></span>10.2 Clump API</h3>

<p>These are mostly for extension purposes. About the only thing
needed from here for normal operation is <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> when clamping inputs
or extracting predictions.</p>

<p><a name='x-28MGL-BP-3ASTRIPEDP-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>STRIPEDP</strong> <em>CLUMP</em></p>

<p>For efficiency, forward and backprop phases do
their stuff in batch mode: passing a number of instances through the
network in batches. Thus clumps must be able to store values of and
gradients for each of these instances. However, some clumps produce
the same result for each instance in a batch. These clumps are the
weights, the parameters of the network. <a href="#x-28MGL-BP-3ASTRIPEDP-20GENERIC-FUNCTION-29" title="(MGL-BP:STRIPEDP GENERIC-FUNCTION)"><code>STRIPEDP</code></a> returns true iff
<code>CLUMP</code> does not represent weights (i.e. it's not a <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a>).</p>

<p>For striped clumps, their <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> and <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> are <code>MAT</code> objects with
a leading dimension (number of rows in the 2d case) equal to the
number of instances in the batch. Non-striped clumps have no
restriction on their shape apart from what their usage dictates.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>NODES</strong> <em>OBJECT</em></p>

<p>Returns a <code>MAT</code> object representing the state or
result of <code>OBJECT</code>. The first dimension of the returned matrix is
equal to the number of stripes.</p></li>
</ul>

<p><a href="#x-28MGL-BP-3ACLUMP-20CLASS-29" title="(MGL-BP:CLUMP CLASS)"><code>CLUMP</code></a>s' <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> holds the result computed by the most recent
<a href="#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:FORWARD GENERIC-FUNCTION)"><code>FORWARD</code></a>. For <a href="#x-28MGL-BP-3A--3EINPUT-20CLASS-29" title="(MGL-BP:-&gt;INPUT CLASS)"><code>-&gt;INPUT</code></a> lumps, this is where input values shall be
placed (see <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>). Currently, the matrix is always two
dimensional but this restriction may go away in the future.</p>

<p><a name='x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>DERIVATIVES</strong> <em>CLUMP</em></p>

<p>Return the <code>MAT</code> object representing the partial
derivatives of the function <code>CLUMP</code> computes. The returned partial
derivatives were accumulated by previous <a href="#x-28MGL-BP-3ABACKWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:BACKWARD GENERIC-FUNCTION)"><code>BACKWARD</code></a> calls.</p>

<p>This matrix is shaped like the matrix returned by <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>FORWARD</strong> <em>CLUMP</em></p>

<p>Compute the values of the function represented by
<code>CLUMP</code> for all stripes and place the results into <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> of <code>CLUMP</code>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ABACKWARD-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>BACKWARD</strong> <em>CLUMP</em></p>

<p>Compute the partial derivatives of the function
represented by <code>CLUMP</code> and add them to <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> of the
corresponding argument clumps. The <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> of <code>CLUMP</code> contains the
sum of partial derivatives of all clumps by the corresponding
output. This function is intended to be called after a <a href="#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:FORWARD GENERIC-FUNCTION)"><code>FORWARD</code></a> pass.</p>

<p>Take the <a href="#x-28MGL-BP-3A--3ESIGMOID-20CLASS-29" title="(MGL-BP:-&gt;SIGMOID CLASS)"><code>-&gt;SIGMOID</code></a> clump for example when the network is being
applied to a batch of two instances <code>x1</code> and <code>x2</code>. <code>x1</code> and <code>x2</code> are
set in the <a href="#x-28MGL-BP-3A--3EINPUT-20CLASS-29" title="(MGL-BP:-&gt;INPUT CLASS)"><code>-&gt;INPUT</code></a> lump X. The sigmoid computes <code>1/(1+exp(-x))</code>
where <code>X</code> is its only argument clump.</p>

<pre><code>f(x) = 1/(1+exp(-x))
</code></pre>

<p>When <a href="#x-28MGL-BP-3ABACKWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:BACKWARD GENERIC-FUNCTION)"><code>BACKWARD</code></a> is called on the sigmoid lump, its <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> is a
2x1 <code>MAT</code> object that contains the partial derivatives of the loss
function:</p>

<pre><code>dL(x1)/df
dL(x2)/df
</code></pre>

<p>Now the <a href="#x-28MGL-BP-3ABACKWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:BACKWARD GENERIC-FUNCTION)"><code>BACKWARD</code></a> method of the sigmoid needs to add <code>dL(x1)/dx1</code> and
<code>dL(x2)/dx2</code> to <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> of <code>X</code>. Now, <code>dL(x1)/dx1 = dL(x1)/df *
df(x1)/dx1</code> and the first term is what we have in <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> of the
sigmoid so it only needs to calculate the second term.</p></li>
</ul>

<p>In addition to the above, clumps also have to support <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>),
<a href="#x-28MGL-CORE-3AN-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:N-STRIPES GENERIC-FUNCTION)"><code>N-STRIPES</code></a>, <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a> (and the <code>SETF</code> methods of the latter two)
which can be accomplished just by inheriting from <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>, <a href="#x-28MGL-BP-3AFNN-20CLASS-29" title="(MGL-BP:FNN CLASS)"><code>FNN</code></a>, <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>, or
a <a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>LUMP</code></a>.</p>

<p><a name='x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-EXTENSION-API-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EXTENSION-API MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TRAINING MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">&#8634;</a></span>10.3 BPNs</h3>

<p><a name='x-28MGL-BP-3ABPN-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>BPN</strong> <em>CLUMP</em></p>

<p>Abstract base class for <a href="#x-28MGL-BP-3AFNN-20CLASS-29" title="(MGL-BP:FNN CLASS)"><code>FNN</code></a> and <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AN-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>N-STRIPES</strong> <em>BPN</em> <em>(:N-STRIPES = 1)</em></p>

<p>The current number of instances the network has.
This is automatically set to the number of instances passed to
<a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>, so it rarely has to be manipulated directly although it
can be set. When set <code>N-STRIPES</code> of all <a href="#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN))"><code>CLUMPS</code></a> get set to the same
value.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMAX-N-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>MAX-N-STRIPES</strong> <em>BPN</em> <em>(:MAX-N-STRIPES = NIL)</em></p>

<p>The maximum number of instances the network can
operate on in parallel. Within <a href="#x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-FNN MGL-PAX:MACRO)"><code>BUILD-FNN</code></a> or <a href="#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-RNN MGL-PAX:MACRO)"><code>BUILD-RNN</code></a>, it defaults
to <code>MAX-N-STRIPES</code> of that parent network, else it defaults to 1.
When set <code>MAX-N-STRIPES</code> of all <a href="#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN))"><code>CLUMPS</code></a> get set to the same value.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>CLUMPS</strong> <em>BPN</em> <em>(:CLUMPS = (MAKE-ARRAY 0 :ELEMENT-TYPE 'CLUMP :ADJUSTABLE T :FILL-POINTER T))</em></p>

<p>A topological sorted adjustable array with a fill
pointer that holds the clumps that make up the network. Clumps are
added to it by <a href="#x-28MGL-BP-3AADD-CLUMP-20FUNCTION-29" title="(MGL-BP:ADD-CLUMP FUNCTION)"><code>ADD-CLUMP</code></a> or, more often, automatically when within
a <a href="#x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-FNN MGL-PAX:MACRO)"><code>BUILD-FNN</code></a> or <a href="#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-RNN MGL-PAX:MACRO)"><code>BUILD-RNN</code></a>. Rarely needed, <a href="#x-28MGL-BP-3AFIND-CLUMP-20FUNCTION-29" title="(MGL-BP:FIND-CLUMP FUNCTION)"><code>FIND-CLUMP</code></a> takes care of
most uses.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AFIND-CLUMP-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>FIND-CLUMP</strong> <em>NAME BPN &amp;KEY (ERRORP T)</em></p>

<p>Find the clump with <code>NAME</code> among <a href="#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN))"><code>CLUMPS</code></a> of <code>BPN</code>. As always, names are
compared with <code>EQUAL</code>. If not found, then return <code>NIL</code> or signal and
error depending on <code>ERRORP</code>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AADD-CLUMP-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>ADD-CLUMP</strong> <em>CLUMP BPN</em></p>

<p>Add <code>CLUMP</code> to <code>BPN</code>. <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a> of <code>CLUMP</code> gets set to that of <code>BPN</code>.
It is an error to add a clump with a name already used by one of the
<a href="#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN))"><code>CLUMPS</code></a> of <code>BPN</code>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MONITORING MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TRAINING MGL-PAX:SECTION)">&#8634;</a></span>10.3.1 Training</h4>

<p><a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>s are trained to minimize the loss function they compute.
Before a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> is passed to <a href="#x-28MGL-OPT-3AMINIMIZE-20FUNCTION-29" title="(MGL-OPT:MINIMIZE FUNCTION)"><code>MINIMIZE</code></a> (as its <code>GRADIENT-SOURCE</code>
argument), it must be wrapped in a <a href="#x-28MGL-BP-3ABP-LEARNER-20CLASS-29" title="(MGL-BP:BP-LEARNER CLASS)"><code>BP-LEARNER</code></a> object. <a href="#x-28MGL-BP-3ABP-LEARNER-20CLASS-29" title="(MGL-BP:BP-LEARNER CLASS)"><code>BP-LEARNER</code></a> has
[MONITORS] slot which is used for example by
<a href="#x-28MGL-OPT-3ARESET-OPTIMIZATION-MONITORS-20-28METHOD-20NIL-20-28MGL-OPT-3AITERATIVE-OPTIMIZER-20T-29-29-29" title="(MGL-OPT:RESET-OPTIMIZATION-MONITORS (METHOD NIL (MGL-OPT:ITERATIVE-OPTIMIZER T)))"><code>RESET-OPTIMIZATION-MONITORS</code></a>.</p>

<p>Without the bells an whistles, the basic shape of training is this:</p>

<pre><code><span class="code"><span class="paren1">(<span class="code">minimize optimizer <span class="paren2">(<span class="code">make-instance 'bp-learner <span class="keyword">:bpn</span> bpn</span>)</span>
          <span class="keyword">:dataset</span> dataset</span>)</span></span></code></pre>

<p><a name='x-28MGL-BP-3ABP-LEARNER-20CLASS-29'></a></p>

<ul>
<li>[class] <strong>BP-LEARNER</strong></li>
</ul>

<p><a name='x-28MGL-BP-3ABPN-20-28MGL-PAX-3AREADER-20MGL-BP-3ABP-LEARNER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>BPN</strong> <em>BP-LEARNER</em> <em>(:BPN)</em></p>

<p>The <code>BPN</code> for which this <a href="#x-28MGL-BP-3ABP-LEARNER-20CLASS-29" title="(MGL-BP:BP-LEARNER CLASS)"><code>BP-LEARNER</code></a> provides the
gradients.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3AMONITORS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABP-LEARNER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>MONITORS</strong> <em>BP-LEARNER</em> <em>(:MONITORS = NIL)</em></p>

<p>A list of <a href="#x-28MGL-CORE-3AMONITOR-20CLASS-29" title="(MGL-CORE:MONITOR CLASS)"><code>MONITOR</code></a>s.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-MONITORING-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TRAINING MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MONITORING MGL-PAX:SECTION)">&#8634;</a></span>10.3.2 Monitoring</h4>

<p><a name='x-28MGL-BP-3AMONITOR-BPN-RESULTS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MONITOR-BPN-RESULTS</strong> <em>DATASET BPN MONITORS</em></p>

<p>For every batch (of size <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20GENERIC-FUNCTION-29" title="(MGL-CORE:MAX-N-STRIPES GENERIC-FUNCTION)"><code>MAX-N-STRIPES</code></a> of <code>BPN</code>) of instances in
<code>DATASET</code>, set the batch as the next input with <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>, perform a
<a href="#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:FORWARD GENERIC-FUNCTION)"><code>FORWARD</code></a> pass and apply <code>MONITORS</code> to the <code>BPN</code> (with <a href="#x-28MGL-CORE-3AAPPLY-MONITORS-20FUNCTION-29" title="(MGL-CORE:APPLY-MONITORS FUNCTION)"><code>APPLY-MONITORS</code></a>).
Finally, return the counters of <code>MONITORS</code>. This is built on top of
<a href="#x-28MGL-CORE-3AMONITOR-MODEL-RESULTS-20FUNCTION-29" title="(MGL-CORE:MONITOR-MODEL-RESULTS FUNCTION)"><code>MONITOR-MODEL-RESULTS</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AMAKE-STEP-MONITOR-MONITORS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-STEP-MONITOR-MONITORS</strong> <em>RNN &amp;KEY (COUNTER-VALUES-FN #'COUNTER-RAW-VALUES) (MAKE-COUNTER #'MAKE-STEP-MONITOR-MONITOR-COUNTER)</em></p>

<p>Return a list of monitors, one for every monitor in <a href="#x-28MGL-BP-3ASTEP-MONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29" title="(MGL-BP:STEP-MONITORS (MGL-PAX:ACCESSOR MGL-BP:RNN))"><code>STEP-MONITORS</code></a>
of <code>RNN</code>. These monitors extract the results from their warp
counterpairs with <code>COUNTER-VALUES-FN</code> and add them to their own
counter that's created by <code>MAKE-COUNTER</code>. Wow. Ew. The idea is that
one does something like this do monitor warped prediction:</p>

<pre><code><span class="code"><span class="paren1">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren2">(<span class="code"><span class="paren3">(<span class="code"><span class="special">*warp-time*</span> t</span>)</span></span>)</span>
  <span class="paren2">(<span class="code">setf <span class="paren3">(<span class="code">step-monitors rnn</span>)</span>
        <span class="paren3">(<span class="code">make-cost-monitors rnn <span class="keyword">:attributes</span> '<span class="paren4">(<span class="code"><span class="keyword">:event</span> <span class="string">"warped pred."</span></span>)</span></span>)</span></span>)</span>
  <span class="paren2">(<span class="code">monitor-bpn-results dataset rnn
                       <span class="comment">;; Just collect and reset the warp
</span>                       <span class="comment">;; monitors after each batch of
</span>                       <span class="comment">;; instances.
</span>                       <span class="paren3">(<span class="code">make-step-monitor-monitors rnn</span>)</span></span>)</span></span>)</span></span></code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3AMAKE-STEP-MONITOR-MONITOR-COUNTER-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>MAKE-STEP-MONITOR-MONITOR-COUNTER</strong> <em>STEP-COUNTER</em></p>

<p>In an <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>, <code>STEP-COUNTER</code> aggregates results of all
the time steps during the processing of instances in the current
batch. Return a new counter into which results from <code>STEP-COUNTER</code> can
be accumulated when the processing of the batch is finished. The
default implementation creates a copy of <code>STEP-COUNTER</code>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-MONITORING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MONITORING MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN-TUTORIAL MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN MGL-PAX:SECTION)">&#8634;</a></span>10.3.3 Feed-Forward Nets</h4>

<p><a href="#x-28MGL-BP-3AFNN-20CLASS-29" title="(MGL-BP:FNN CLASS)"><code>FNN</code></a> and <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a> have a lot in common (see their common superclass, <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>).
There is very limited functionality that's specific to FNNs so let's
get them out of they way before we study a full example.</p>

<p><a name='x-28MGL-BP-3AFNN-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>FNN</strong> <em>BPN</em></p>

<p>A feed-forward neural net (as opposed to a
recurrent one, see <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>).</p></li>
</ul>

<p><a name='x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>BUILD-FNN</strong> <em>(&amp;KEY FNN (CLASS ''FNN) INITARGS MAX-N-STRIPES NAME) &amp;BODY CLUMPS</em></p>

<p>Syntactic sugar to assemble FNNs from CLUMPs. Like <code>LET*</code>, it is a
sequence of bindings (of symbols to CLUMPs). The names of the clumps
created default to the symbol of the binding. In case a clump is not
bound to a symbol (because it was created in a nested expression),
the local function <a href="#x-28MGL-BP-3ACLUMP-20CLASS-29" title="(MGL-BP:CLUMP CLASS)"><code>CLUMP</code></a> can be used to find the clump with the
given name in the fnn being built. Example:</p>

<pre><code>(build-fnn ()
  (features (-&gt;input :size n-features))
  (biases (-&gt;weight :size n-features))
  (weights (-&gt;weight :size (* n-hiddens n-features)))
  (activations0 (-&gt;v*m :weights weights :x (clump 'features)))
  (activations (-&gt;+ :args (list biases activations0)))
  (output (-&gt;sigmoid :x activations)))
</code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-FNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN-TUTORIAL MGL-PAX:SECTION)">&#8634;</a></span>FNN Tutorial</h5>

<p>Hopefully this example from <code>example/digit-fnn.lisp</code> illustrates
the concepts involved. If it's too dense despite the comments, then
read up on <a href="#x-28MGL-DATASET-3A-40MGL-DATASET-20MGL-PAX-3ASECTION-29" title="(MGL-DATASET:@MGL-DATASET MGL-PAX:SECTION)">Datasets</a>, <a href="#x-28MGL-OPT-3A-40MGL-OPT-20MGL-PAX-3ASECTION-29" title="(MGL-OPT:@MGL-OPT MGL-PAX:SECTION)">Gradient Based Optimization</a> and come back.</p>

<p><a name='x-28MGL-BP-3A-3ADIGIT-FNN-2ELISP-20-28MGL-PAX-3AINCLUDE-20-23P-22-2Fhome-2Fmega-2Fown-2Fmgl-2Fexample-2Fdigit-fnn-2Elisp-22-20-3AHEADER-NL-20-22-60-60-60commonlisp-22-20-3AFOOTER-NL-20-22-60-60-60-22-29-29'></a></p>

<pre><code><span class="code"><span class="paren1">(<span class="code"><i><span class="symbol">cl:defpackage</span></i> <span class="keyword">:mgl-example-digit-fnn</span>
  <span class="paren2">(<span class="code"><span class="keyword">:use</span> <span class="keyword">#:common-lisp</span> <span class="keyword">#:mgl</span></span>)</span></span>)</span>

<span class="paren1">(<span class="code">in-package <span class="keyword">:mgl-example-digit-fnn</span></span>)</span>

<span class="comment">;;; There are 10 possible digits used as inputs ...
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*n-inputs*</span> 10</span>)</span>
<span class="comment">;;; and we want to learn the rule that maps the input digit D to (MOD
</span><span class="comment">;;; (1+ D) 3).
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*n-outputs*</span> 3</span>)</span>

<span class="comment">;;; We define a feed-forward net to be able to specialize how inputs
</span><span class="comment">;;; are translated by adding a SET-INPUT method later.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defclass</span></i> digit-fnn <span class="paren2">(<span class="code">fnn</span>)</span>
  <span class="paren2">(<span class="code"></span>)</span></span>)</span>

<span class="comment">;;; Build a DIGIT-FNN with a single hidden layer of rectified linear
</span><span class="comment">;;; units and a softmax output.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> make-digit-fnn <span class="paren2">(<span class="code">&amp;key <span class="paren3">(<span class="code">n-hiddens 5</span>)</span></span>)</span>
  <span class="paren2">(<span class="code">build-fnn <span class="paren3">(<span class="code"><span class="keyword">:class</span> 'digit-fnn</span>)</span>
    <span class="paren3">(<span class="code">input <span class="paren4">(<span class="code">-&gt;input <span class="keyword">:size</span> <span class="special">*n-inputs*</span></span>)</span></span>)</span>
    <span class="paren3">(<span class="code">hidden-activation <span class="paren4">(<span class="code">-&gt;activation input <span class="keyword">:size</span> n-hiddens</span>)</span></span>)</span>
    <span class="paren3">(<span class="code">hidden <span class="paren4">(<span class="code">-&gt;relu hidden-activation</span>)</span></span>)</span>
    <span class="paren3">(<span class="code">output-activation <span class="paren4">(<span class="code">-&gt;activation hidden <span class="keyword">:size</span> <span class="special">*n-outputs*</span></span>)</span></span>)</span>
    <span class="paren3">(<span class="code">output <span class="paren4">(<span class="code">-&gt;softmax-xe-loss output-activation</span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; This method is called with batches of 'instances' (input digits in
</span><span class="comment">;;; this case) by MINIMIZE and also by MONITOR-BPN-RESULTS before
</span><span class="comment">;;; performing a forward pass (i.e. computing the value of the
</span><span class="comment">;;; function represented by the network). Its job is to encode the
</span><span class="comment">;;; inputs by populating rows of the NODES matrix of the INPUT clump.
</span><span class="comment">;;;
</span><span class="comment">;;; Each input is encoded as a row of zeros with a single 1 at index
</span><span class="comment">;;; determined by the input digit. This is called one-hot encoding.
</span><span class="comment">;;; The TARGET could be encoded the same way, but instead we use the
</span><span class="comment">;;; sparse option supported by TARGET of -&gt;SOFTMAX-XE-LOSS.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defmethod</span></i> set-input <span class="paren2">(<span class="code">digits <span class="paren3">(<span class="code">fnn digit-fnn</span>)</span></span>)</span>
  <span class="paren2">(<span class="code"><i><span class="symbol">let*</span></i> <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">input <span class="paren5">(<span class="code">nodes <span class="paren6">(<span class="code">find-clump 'input fnn</span>)</span></span>)</span></span>)</span>
         <span class="paren4">(<span class="code">output-lump <span class="paren5">(<span class="code">find-clump 'output fnn</span>)</span></span>)</span></span>)</span>
    <span class="paren3">(<span class="code">fill! 0 input</span>)</span>
    <span class="paren3">(<span class="code"><i><span class="symbol">loop</span></i> for i upfrom 0
          for digit in digits
          do <span class="paren4">(<span class="code">setf <span class="paren5">(<span class="code">mref input i digit</span>)</span> 1</span>)</span></span>)</span>
    <span class="paren3">(<span class="code">setf <span class="paren4">(<span class="code">target output-lump</span>)</span>
          <span class="paren4">(<span class="code">mapcar <span class="paren5">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren6">(<span class="code">digit</span>)</span>
                    <span class="paren6">(<span class="code">mod <span class="paren1">(<span class="code">1+ digit</span>)</span> <span class="special">*n-outputs*</span></span>)</span></span>)</span>
                  digits</span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Train the network by minimizing the loss (cross-entropy here) with
</span><span class="comment">;;; stochastic gradient descent.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> train-digit-fnn <span class="paren2">(<span class="code"></span>)</span>
  <span class="paren2">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">optimizer
          <span class="comment">;; First create the optimizer for MINIMIZE.
</span>          <span class="paren5">(<span class="code">make-instance 'segmented-gd-optimizer
                         <span class="keyword">:segmenter</span>
                         <span class="comment">;; We train each weight lump with the same
</span>                         <span class="comment">;; parameters and, in fact, the same
</span>                         <span class="comment">;; optimizer. But it need not be so, in
</span>                         <span class="comment">;; general.
</span>                         <span class="paren6">(<span class="code">constantly
                          <span class="paren1">(<span class="code">make-instance 'batch-gd-optimizer
                                         <span class="keyword">:learning-rate</span> 1
                                         <span class="keyword">:momentum</span> 0.9
                                         <span class="keyword">:batch-size</span> 100</span>)</span></span>)</span></span>)</span></span>)</span>
        <span class="paren4">(<span class="code">fnn <span class="paren5">(<span class="code">make-digit-fnn</span>)</span></span>)</span></span>)</span>
    <span class="comment">;; The number of instances the FNN can work with in parallel. It's
</span>    <span class="comment">;; usually equal to the batch size or is a its divisor.
</span>    <span class="paren3">(<span class="code">setf <span class="paren4">(<span class="code">max-n-stripes fnn</span>)</span> 50</span>)</span>
    <span class="comment">;; Initialize all weights randomly.
</span>    <span class="paren3">(<span class="code">map-segments <span class="paren4">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren5">(<span class="code">weights</span>)</span>
                    <span class="paren5">(<span class="code">gaussian-random! <span class="paren6">(<span class="code">nodes weights</span>)</span> <span class="keyword">:stddev</span> 0.01</span>)</span></span>)</span>
                  fnn</span>)</span>
    <span class="comment">;; Arrange for training and test error to be logged.
</span>    <span class="paren3">(<span class="code">monitor-optimization-periodically
     optimizer '<span class="paren4">(<span class="code"><span class="paren5">(<span class="code"><span class="keyword">:fn</span> log-test-error <span class="keyword">:period</span> 10000</span>)</span>
                 <span class="paren5">(<span class="code"><span class="keyword">:fn</span> reset-optimization-monitors <span class="keyword">:period</span> 1000</span>)</span></span>)</span></span>)</span>
    <span class="comment">;; Finally, start the optimization.
</span>    <span class="paren3">(<span class="code">minimize optimizer
              <span class="comment">;; Dress FNN in a BP-LEARNER and attach monitors for the
</span>              <span class="comment">;; cost to it. These monitors are going to be logged and
</span>              <span class="comment">;; reset after every 100 training instance by
</span>              <span class="comment">;; RESET-OPTIMIZATION-MONITORS above.
</span>              <span class="paren4">(<span class="code">make-instance 'bp-learner
                             <span class="keyword">:bpn</span> fnn
                             <span class="keyword">:monitors</span> <span class="paren5">(<span class="code">make-cost-monitors
                                        fnn <span class="keyword">:attributes</span> `<span class="paren6">(<span class="code"><span class="keyword">:event</span> <span class="string">"train"</span></span>)</span></span>)</span></span>)</span>
              <span class="comment">;; Training stops when the sampler runs out (after 10000
</span>              <span class="comment">;; instances).
</span>              <span class="keyword">:dataset</span> <span class="paren4">(<span class="code">make-sampler 10000</span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Return a sampler object that produces MAX-N-SAMPLES number of
</span><span class="comment">;;; random inputs (numbers between 0 and 9).
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> make-sampler <span class="paren2">(<span class="code">max-n-samples</span>)</span>
  <span class="paren2">(<span class="code">make-instance 'function-sampler <span class="keyword">:max-n-samples</span> max-n-samples
                 <span class="keyword">:generator</span> <span class="paren3">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren4">(<span class="code"></span>)</span> <span class="paren4">(<span class="code">random <span class="special">*n-inputs*</span></span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Log the test error. Also, describe the optimizer and the bpn at
</span><span class="comment">;;; the beginning of training. Called periodically during training
</span><span class="comment">;;; (see above).
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> log-test-error <span class="paren2">(<span class="code">optimizer learner</span>)</span>
  <span class="paren2">(<span class="code">when <span class="paren3">(<span class="code">zerop <span class="paren4">(<span class="code">n-instances optimizer</span>)</span></span>)</span>
    <span class="paren3">(<span class="code">describe optimizer</span>)</span>
    <span class="paren3">(<span class="code">describe <span class="paren4">(<span class="code">bpn learner</span>)</span></span>)</span></span>)</span>
  <span class="paren2">(<span class="code">log-padded
   <span class="paren3">(<span class="code">monitor-bpn-results <span class="paren4">(<span class="code">make-sampler 1000</span>)</span> <span class="paren4">(<span class="code">bpn learner</span>)</span>
                        <span class="paren4">(<span class="code">make-cost-monitors
                         <span class="paren5">(<span class="code">bpn learner</span>)</span> <span class="keyword">:attributes</span> `<span class="paren5">(<span class="code"><span class="keyword">:event</span> <span class="string">"pred."</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">#|

;;; Transcript follows:
(train-digit-fnn)
.. 2015-01-25 21:47:57: training at n-instances: 0
.. 2015-01-25 21:47:57: train cost: 0.000e+0 (0)
.. #&lt;SEGMENTED-GD-OPTIMIZER {101AF31013}&gt;
..  SEGMENTED-GD-OPTIMIZER description:
..    N-INSTANCES = 0
..    OPTIMIZERS = (#&lt;BATCH-GD-OPTIMIZER
..                    #&lt;SEGMENT-SET
..                      (#&lt;-&gt;WEIGHT # :SIZE 15 1/1 :norm 0.04560&gt;
..                       #&lt;-&gt;WEIGHT # :SIZE 3 1/1 :norm 0.00943&gt;
..                       #&lt;-&gt;WEIGHT # :SIZE 50 1/1 :norm 0.07021&gt;
..                       #&lt;-&gt;WEIGHT # :SIZE 5 1/1 :norm 0.01594&gt;)
..                      {101B2178D3}&gt;
..                    {101AE7B063}&gt;)
..    SEGMENTS = (#&lt;-&gt;WEIGHT (HIDDEN OUTPUT-ACTIVATION) :SIZE
..                  15 1/1 :norm 0.04560&gt;
..                #&lt;-&gt;WEIGHT (:BIAS OUTPUT-ACTIVATION) :SIZE
..                  3 1/1 :norm 0.00943&gt;
..                #&lt;-&gt;WEIGHT (INPUT HIDDEN-ACTIVATION) :SIZE
..                  50 1/1 :norm 0.07021&gt;
..                #&lt;-&gt;WEIGHT (:BIAS HIDDEN-ACTIVATION) :SIZE
..                  5 1/1 :norm 0.01594&gt;)
..  
.. #&lt;BATCH-GD-OPTIMIZER {101AE7B063}&gt;
..  GD-OPTIMIZER description:
..    N-INSTANCES = 0
..    SEGMENT-SET = #&lt;SEGMENT-SET
..                    (#&lt;-&gt;WEIGHT (HIDDEN OUTPUT-ACTIVATION) :SIZE
..                       15 1/1 :norm 0.04560&gt;
..                     #&lt;-&gt;WEIGHT (:BIAS OUTPUT-ACTIVATION) :SIZE
..                       3 1/1 :norm 0.00943&gt;
..                     #&lt;-&gt;WEIGHT (INPUT HIDDEN-ACTIVATION) :SIZE
..                       50 1/1 :norm 0.07021&gt;
..                     #&lt;-&gt;WEIGHT (:BIAS HIDDEN-ACTIVATION) :SIZE
..                       5 1/1 :norm 0.01594&gt;)
..                    {101B2178D3}&gt;
..    LEARNING-RATE = 1.00000e+0
..    MOMENTUM = 9.00000e-1
..    MOMENTUM-TYPE = :NORMAL
..    WEIGHT-DECAY = 0.00000e+0
..    WEIGHT-PENALTY = 0.00000e+0
..    N-AFTER-UPATE-HOOK = 0
..    BATCH-SIZE = 100
..  
..  BATCH-GD-OPTIMIZER description:
..    N-BEFORE-UPATE-HOOK = 0
..  #&lt;DIGIT-FNN {101AF33DC3}&gt;
..   BPN description:
..     CLUMPS = #(#&lt;-&gt;INPUT INPUT :SIZE 10 1/50 :norm 0.00000&gt;
..                #&lt;-&gt;ACTIVATION
..                  (HIDDEN-ACTIVATION :ACTIVATION) :STRIPES 1/50
..                  :CLUMPS 4&gt;
..                #&lt;-&gt;RELU HIDDEN :SIZE 5 1/50 :norm 0.00000&gt;
..                #&lt;-&gt;ACTIVATION
..                  (OUTPUT-ACTIVATION :ACTIVATION) :STRIPES 1/50
..                  :CLUMPS 4&gt;
..                #&lt;-&gt;SOFTMAX-XE-LOSS OUTPUT :SIZE 3 1/50 :norm 0.00000&gt;)
..     N-STRIPES = 1
..     MAX-N-STRIPES = 50
..   2015-01-25 21:47:57: pred. cost: 1.098d+0 (1000.00)
.. 2015-01-25 21:47:57: training at n-instances: 1000
.. 2015-01-25 21:47:57: train cost: 1.093d+0 (1000.00)
.. 2015-01-25 21:47:57: training at n-instances: 2000
.. 2015-01-25 21:47:57: train cost: 5.491d-1 (1000.00)
.. 2015-01-25 21:47:57: training at n-instances: 3000
.. 2015-01-25 21:47:57: train cost: 4.281d-3 (1000.00)
.. 2015-01-25 21:47:58: training at n-instances: 4000
.. 2015-01-25 21:47:58: train cost: 2.767d-4 (1000.00)
.. 2015-01-25 21:47:58: training at n-instances: 5000
.. 2015-01-25 21:47:58: train cost: 1.029d-4 (1000.00)
.. 2015-01-25 21:47:58: training at n-instances: 6000
.. 2015-01-25 21:47:58: train cost: 5.664d-5 (1000.00)
.. 2015-01-25 21:47:58: training at n-instances: 7000
.. 2015-01-25 21:47:58: train cost: 4.567d-5 (1000.00)
.. 2015-01-25 21:47:58: training at n-instances: 8000
.. 2015-01-25 21:47:58: train cost: 3.989d-5 (1000.00)
.. 2015-01-25 21:47:58: training at n-instances: 9000
.. 2015-01-25 21:47:58: train cost: 3.374d-5 (1000.00)
.. 2015-01-25 21:47:58: training at n-instances: 10000
.. 2015-01-25 21:47:58: train cost: 3.220d-5 (1000.00)
.. 2015-01-25 21:47:58: pred. cost: 3.382d-5 (1000.00)
..
==&gt; (#&lt;-&gt;WEIGHT (:BIAS HIDDEN-ACTIVATION) :SIZE 5 1/1 :norm 2.56299&gt;
--&gt;  #&lt;-&gt;WEIGHT (INPUT HIDDEN-ACTIVATION) :SIZE 50 1/1 :norm 11.03941&gt;
--&gt;  #&lt;-&gt;WEIGHT (:BIAS OUTPUT-ACTIVATION) :SIZE 3 1/1 :norm 8.04568&gt;
--&gt;  #&lt;-&gt;WEIGHT (HIDDEN OUTPUT-ACTIVATION) :SIZE 15 1/1 :norm 10.49271&gt;)

|#</span></span></code></pre>

<p><a name='x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN-TUTORIAL MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BPN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BPN MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TUTORIAL MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN MGL-PAX:SECTION)">&#8634;</a></span>10.3.4 Recurrent Neural Nets</h4>

<p><a name='x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TIME-WARP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TUTORIAL MGL-PAX:SECTION)">&#8634;</a></span>RNN Tutorial</h5>

<p>Hopefully this example from <code>example/sum-sign-fnn.lisp</code> illustrates
the concepts involved. Make sure you are comfortable with
<a href="#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN-TUTORIAL MGL-PAX:SECTION)">FNN Tutorial</a> before reading this.</p>

<p><a name='x-28MGL-BP-3A-3ASUM-SIG-RNN-2ELISP-20-28MGL-PAX-3AINCLUDE-20-23P-22-2Fhome-2Fmega-2Fown-2Fmgl-2Fexample-2Fsum-sign-rnn-2Elisp-22-20-3AHEADER-NL-20-22-60-60-60commonlisp-22-20-3AFOOTER-NL-20-22-60-60-60-22-29-29'></a></p>

<pre><code><span class="code"><span class="paren1">(<span class="code"><i><span class="symbol">cl:defpackage</span></i> <span class="keyword">:mgl-example-sum-sign-rnn</span>
  <span class="paren2">(<span class="code"><span class="keyword">:use</span> <span class="keyword">#:common-lisp</span> <span class="keyword">#:mgl</span></span>)</span></span>)</span>

<span class="paren1">(<span class="code">in-package <span class="keyword">:mgl-example-sum-sign-rnn</span></span>)</span>

<span class="comment">;;; There is a single input at each time step...
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*n-inputs*</span> 1</span>)</span>
<span class="comment">;;; and we want to learn the rule that outputs the sign of the sum of
</span><span class="comment">;;; inputs so far in the sequence.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defparameter</span></i> <span class="special">*n-outputs*</span> 3</span>)</span>

<span class="comment">;;; Generate a training example that's a sequence of random length
</span><span class="comment">;;; between 1 and LENGTH. Elements of the sequence are lists of two
</span><span class="comment">;;; elements:
</span><span class="comment">;;;
</span><span class="comment">;;; 1. The input for the network (a single random number).
</span><span class="comment">;;;
</span><span class="comment">;;; 2. The sign of the sum of inputs so far encoded as 0, 1, 2 (for
</span><span class="comment">;;;    negative, zero and positive values). To add a twist, the sum is
</span><span class="comment">;;;    reset whenever a negative input is seen.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> make-sum-sign-instance <span class="paren2">(<span class="code">&amp;key <span class="paren3">(<span class="code">length 10</span>)</span></span>)</span>
  <span class="paren2">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">length <span class="paren5">(<span class="code">max 1 <span class="paren6">(<span class="code">random length</span>)</span></span>)</span></span>)</span>
        <span class="paren4">(<span class="code">sum 0</span>)</span></span>)</span>
    <span class="paren3">(<span class="code"><i><span class="symbol">loop</span></i> for i below length
          collect <span class="paren4">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren5">(<span class="code"><span class="paren6">(<span class="code">x <span class="paren1">(<span class="code">1- <span class="paren2">(<span class="code">* 2 <span class="paren3">(<span class="code">random 2</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>
                    <span class="paren5">(<span class="code">incf sum x</span>)</span>
                    <span class="paren5">(<span class="code">when <span class="paren6">(<span class="code">&lt; x 0</span>)</span>
                      <span class="paren6">(<span class="code"><i><span class="symbol">setq</span></i> sum x</span>)</span></span>)</span>
                    <span class="paren5">(<span class="code">list x <span class="paren6">(<span class="code"><i><span class="symbol">cond</span></i> <span class="paren1">(<span class="code"><span class="paren2">(<span class="code">minusp sum</span>)</span> 0</span>)</span>
                                  <span class="paren1">(<span class="code"><span class="paren2">(<span class="code">zerop sum</span>)</span> 1</span>)</span>
                                  <span class="paren1">(<span class="code">t 2</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Build an RNN with a single lstm hidden layer and softmax output.
</span><span class="comment">;;; For each time step, a SUM-SIGN-FNN will be instantiated.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> make-sum-sign-rnn <span class="paren2">(<span class="code">&amp;key <span class="paren3">(<span class="code">n-hiddens 1</span>)</span></span>)</span>
  <span class="paren2">(<span class="code">build-rnn <span class="paren3">(<span class="code"></span>)</span>
    <span class="paren3">(<span class="code">build-fnn <span class="paren4">(<span class="code"><span class="keyword">:class</span> 'sum-sign-fnn</span>)</span>
      <span class="paren4">(<span class="code">input <span class="paren5">(<span class="code">-&gt;input <span class="keyword">:size</span> 1</span>)</span></span>)</span>
      <span class="paren4">(<span class="code">h <span class="paren5">(<span class="code">-&gt;lstm input <span class="keyword">:name</span> 'h <span class="keyword">:size</span> n-hiddens</span>)</span></span>)</span>
      <span class="paren4">(<span class="code">prediction <span class="paren5">(<span class="code">-&gt;softmax-xe-loss <span class="paren6">(<span class="code">-&gt;activation h <span class="keyword">:name</span> 'prediction
                                                   <span class="keyword">:size</span> <span class="special">*n-outputs*</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; We define this class to be able to specialize how inputs are
</span><span class="comment">;;; translated by adding a SET-INPUT method later.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defclass</span></i> sum-sign-fnn <span class="paren2">(<span class="code">fnn</span>)</span>
  <span class="paren2">(<span class="code"></span>)</span></span>)</span>

<span class="comment">;;; We have a batch of instances from MAKE-SUM-SIGN-INSTANCE for the
</span><span class="comment">;;; RNN. This function is invoked with elements of these instances
</span><span class="comment">;;; belonging to the same time step (i.e. at the same index) and sets
</span><span class="comment">;;; the input and target up.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defmethod</span></i> set-input <span class="paren2">(<span class="code">instances <span class="paren3">(<span class="code">fnn sum-sign-fnn</span>)</span></span>)</span>
  <span class="paren2">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">input-nodes <span class="paren5">(<span class="code">nodes <span class="paren6">(<span class="code">find-clump 'input fnn</span>)</span></span>)</span></span>)</span></span>)</span>
    <span class="paren3">(<span class="code">setf <span class="paren4">(<span class="code">target <span class="paren5">(<span class="code">find-clump 'prediction fnn</span>)</span></span>)</span>
          <span class="paren4">(<span class="code"><i><span class="symbol">loop</span></i> for stripe upfrom 0
                for instance in instances
                collect
                <span class="comment">;; Sequences in the batch are not of equal length. The
</span>                <span class="comment">;; RNN sends a NIL our way if a sequence has run out.
</span>                <span class="paren5">(<span class="code">when instance
                  <span class="paren6">(<span class="code">destructuring-bind <span class="paren1">(<span class="code">input target</span>)</span> instance
                    <span class="paren1">(<span class="code">setf <span class="paren2">(<span class="code">mref input-nodes stripe 0</span>)</span> input</span>)</span>
                    target</span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Train the network by minimizing the loss (cross-entropy here) with
</span><span class="comment">;;; the Adam optimizer.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> train-sum-sign-rnn <span class="paren2">(<span class="code"></span>)</span>
  <span class="paren2">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">rnn <span class="paren5">(<span class="code">make-sum-sign-rnn</span>)</span></span>)</span></span>)</span>
    <span class="paren3">(<span class="code">setf <span class="paren4">(<span class="code">max-n-stripes rnn</span>)</span> 50</span>)</span>
    <span class="comment">;; Initialize the weights in the usual sqrt(1 / fan-in) style.
</span>    <span class="paren3">(<span class="code">map-segments <span class="paren4">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren5">(<span class="code">weights</span>)</span>
                    <span class="paren5">(<span class="code"><i><span class="symbol">let*</span></i> <span class="paren6">(<span class="code"><span class="paren1">(<span class="code">fan-in <span class="paren2">(<span class="code">mat-dimension <span class="paren3">(<span class="code">nodes weights</span>)</span> 0</span>)</span></span>)</span>
                           <span class="paren1">(<span class="code">limit <span class="paren2">(<span class="code">sqrt <span class="paren3">(<span class="code">/ 6 fan-in</span>)</span></span>)</span></span>)</span></span>)</span>
                      <span class="paren6">(<span class="code">uniform-random! <span class="paren1">(<span class="code">nodes weights</span>)</span>
                                       <span class="keyword">:limit</span> <span class="paren1">(<span class="code">* 2 limit</span>)</span></span>)</span>
                      <span class="paren6">(<span class="code">.+! <span class="paren1">(<span class="code">- limit</span>)</span> <span class="paren1">(<span class="code">nodes weights</span>)</span></span>)</span></span>)</span></span>)</span>
                  rnn</span>)</span>
    <span class="paren3">(<span class="code">minimize <span class="paren4">(<span class="code">monitor-optimization-periodically
               <span class="paren5">(<span class="code">make-instance 'adam-optimizer
                              <span class="keyword">:learning-rate</span> 0.2
                              <span class="keyword">:batch-size</span> 100</span>)</span>
               '<span class="paren5">(<span class="code"><span class="paren6">(<span class="code"><span class="keyword">:fn</span> log-test-error <span class="keyword">:period</span> 30000</span>)</span>
                 <span class="paren6">(<span class="code"><span class="keyword">:fn</span> reset-optimization-monitors <span class="keyword">:period</span> 3000</span>)</span></span>)</span></span>)</span>
              <span class="paren4">(<span class="code">make-instance 'bp-learner
                             <span class="keyword">:bpn</span> rnn
                             <span class="keyword">:monitors</span> <span class="paren5">(<span class="code">make-cost-monitors rnn</span>)</span></span>)</span>
              <span class="keyword">:dataset</span> <span class="paren4">(<span class="code">make-sampler 30000</span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Return a sampler object that produces MAX-N-SAMPLES number of
</span><span class="comment">;;; random inputs.
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> make-sampler <span class="paren2">(<span class="code">max-n-samples &amp;key <span class="paren3">(<span class="code">length 10</span>)</span></span>)</span>
  <span class="paren2">(<span class="code">make-instance 'function-sampler <span class="keyword">:max-n-samples</span> max-n-samples
                 <span class="keyword">:generator</span> <span class="paren3">(<span class="code"><i><span class="symbol">lambda</span></i> <span class="paren4">(<span class="code"></span>)</span>
                              <span class="paren4">(<span class="code">make-sum-sign-instance <span class="keyword">:length</span> length</span>)</span></span>)</span></span>)</span></span>)</span>

<span class="comment">;;; Log the test error. Also, describe the optimizer and the bpn at
</span><span class="comment">;;; the beginning of training. Called periodically during training
</span><span class="comment">;;; (see above).
</span><span class="paren1">(<span class="code"><i><span class="symbol">defun</span></i> log-test-error <span class="paren2">(<span class="code">optimizer learner</span>)</span>
  <span class="paren2">(<span class="code">when <span class="paren3">(<span class="code">zerop <span class="paren4">(<span class="code">n-instances optimizer</span>)</span></span>)</span>
    <span class="paren3">(<span class="code">describe optimizer</span>)</span>
    <span class="paren3">(<span class="code">describe <span class="paren4">(<span class="code">bpn learner</span>)</span></span>)</span></span>)</span>
  <span class="paren2">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren3">(<span class="code"><span class="paren4">(<span class="code">rnn <span class="paren5">(<span class="code">bpn learner</span>)</span></span>)</span></span>)</span>
    <span class="paren3">(<span class="code">log-padded
     <span class="paren4">(<span class="code">append
      <span class="paren5">(<span class="code">monitor-bpn-results <span class="paren6">(<span class="code">make-sampler 1000</span>)</span> rnn
                           <span class="paren6">(<span class="code">make-cost-monitors
                            rnn <span class="keyword">:attributes</span> '<span class="paren1">(<span class="code"><span class="keyword">:event</span> <span class="string">"pred."</span></span>)</span></span>)</span></span>)</span>
      <span class="comment">;; Same result in a different way: monitor predictions for
</span>      <span class="comment">;; sequences up to length 20, but don't unfold the RNN
</span>      <span class="comment">;; unnecessarily to save memory.
</span>      <span class="paren5">(<span class="code"><i><span class="symbol">let</span></i> <span class="paren6">(<span class="code"><span class="paren1">(<span class="code"><span class="special">*warp-time*</span> t</span>)</span></span>)</span>
        <span class="paren6">(<span class="code">monitor-bpn-results <span class="paren1">(<span class="code">make-sampler 1000 <span class="keyword">:length</span> 20</span>)</span> rnn
                             <span class="comment">;; Just collect and reset the warp
</span>                             <span class="comment">;; monitors after each batch of
</span>                             <span class="comment">;; instances.
</span>                             <span class="paren1">(<span class="code">make-cost-monitors
                              rnn <span class="keyword">:attributes</span> '<span class="paren2">(<span class="code"><span class="keyword">:event</span> <span class="string">"warped pred."</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span></span>)</span>
    <span class="comment">;; Verify that no further unfoldings took place.
</span>    <span class="paren3">(<span class="code">assert <span class="paren4">(<span class="code">&lt;= <span class="paren5">(<span class="code">length <span class="paren6">(<span class="code">clumps rnn</span>)</span></span>)</span> 10</span>)</span></span>)</span></span>)</span>
  <span class="paren2">(<span class="code">log-mat-room</span>)</span></span>)</span>

<span class="comment">#|

;;; Transcript follows:
(let (;; Backprop nets do not need double float. Using single floats
      ;; is faster and needs less memory.
      (*default-mat-ctype* :float)
      ;; Enable moving data in and out of GPU memory so that the RNN
      ;; can work with sequences so long that the unfolded network
      ;; wouldn't otherwise fit in the GPU.
      (*cuda-window-start-time* 1))
  ;; Seed the random number generators.
  (repeatably ()
    ;; Enable CUDA if available.
    (with-cuda* ()
      (train-sum-sign-rnn))))
.. 2015-02-08 12:09:14: training at n-instances: 0
.. 2015-02-08 12:09:14: cost: 0.000e+0 (0)
.. #&lt;ADAM-OPTIMIZER {103192AEF3}&gt;
..  GD-OPTIMIZER description:
..    N-INSTANCES = 0
..    SEGMENT-SET = #&lt;SEGMENT-SET
..                    (#&lt;-&gt;WEIGHT (H #) :SIZE 1 1/1 :norm 1.73685&gt;
..                     #&lt;-&gt;WEIGHT (H #) :SIZE 1 1/1 :norm 0.31893&gt;
..                     #&lt;-&gt;WEIGHT (#1=# #2=# :PEEPHOLE) :SIZE
..                       1 1/1 :norm 1.81610&gt;
..                     #&lt;-&gt;WEIGHT (H #2#) :SIZE 1 1/1 :norm 0.21965&gt;
..                     #&lt;-&gt;WEIGHT (#1# #3=# :PEEPHOLE) :SIZE
..                       1 1/1 :norm 1.74939&gt;
..                     #&lt;-&gt;WEIGHT (H #3#) :SIZE 1 1/1 :norm 0.40377&gt;
..                     #&lt;-&gt;WEIGHT (H PREDICTION) :SIZE
..                       3 1/1 :norm 2.15898&gt;
..                     #&lt;-&gt;WEIGHT (:BIAS PREDICTION) :SIZE
..                       3 1/1 :norm 2.94470&gt;
..                     #&lt;-&gt;WEIGHT (#1# #4=# :PEEPHOLE) :SIZE
..                       1 1/1 :norm 0.97601&gt;
..                     #&lt;-&gt;WEIGHT (INPUT #4#) :SIZE 1 1/1 :norm 0.65261&gt;
..                     #&lt;-&gt;WEIGHT (:BIAS #4#) :SIZE 1 1/1 :norm 0.37653&gt;
..                     #&lt;-&gt;WEIGHT (INPUT #1#) :SIZE 1 1/1 :norm 0.92334&gt;
..                     #&lt;-&gt;WEIGHT (:BIAS #1#) :SIZE 1 1/1 :norm 0.01609&gt;
..                     #&lt;-&gt;WEIGHT (INPUT #5=#) :SIZE 1 1/1 :norm 1.09995&gt;
..                     #&lt;-&gt;WEIGHT (:BIAS #5#) :SIZE 1 1/1 :norm 1.41244&gt;
..                     #&lt;-&gt;WEIGHT (INPUT #6=#) :SIZE 1 1/1 :norm 0.40475&gt;
..                     #&lt;-&gt;WEIGHT (:BIAS #6#) :SIZE 1 1/1 :norm 1.75358&gt;)
..                    {10319D3653}&gt;
..    LEARNING-RATE = 2.00000e-1
..    MOMENTUM = NONE
..    MOMENTUM-TYPE = :NONE
..    WEIGHT-DECAY = 0.00000e+0
..    WEIGHT-PENALTY = 0.00000e+0
..    N-AFTER-UPATE-HOOK = 0
..    BATCH-SIZE = 100
..  
..  BATCH-GD-OPTIMIZER description:
..    N-BEFORE-UPATE-HOOK = 0
..  
..  ADAM-OPTIMIZER description:
..    MEAN-UPDATE-RATE = 1.00000e-1
..    VARIANCE-UPDATE-RATE = 1.00000e-3
..    VARIANCE-ADJUSTMENT = 1.00000e-8
..  #&lt;RNN {10318C6C53}&gt;
..   BPN description:
..     CLUMPS = #(#&lt;SUM-SIGN-FNN :STRIPES 1/50 :CLUMPS 4&gt;
..                #&lt;SUM-SIGN-FNN :STRIPES 1/50 :CLUMPS 4&gt;)
..     N-STRIPES = 1
..     MAX-N-STRIPES = 50
..   
..   RNN description:
..     MAX-LAG = 1
..   2015-02-08 12:09:15: pred.        cost: 1.223e+0 (4455.00)
.. 2015-02-08 12:09:15: warped pred. cost: 1.228e+0 (9476.00)
.. 2015-02-08 12:09:15: Foreign memory usage:
.. foreign arrays: 166 (used bytes: 40,400)
.. CUDA memory usage:
.. device arrays: 114 (used bytes: 220,892, pooled bytes: 19,200)
.. host arrays: 162 (used bytes: 39,600)
.. host-&gt;device copies: 6,164, device-&gt;host copies: 4,490
.. 2015-02-08 12:09:17: training at n-instances: 3000
.. 2015-02-08 12:09:17: cost: 4.986e-1 (13726.00)
.. 2015-02-08 12:09:19: training at n-instances: 6000
.. 2015-02-08 12:09:19: cost: 5.769e-2 (13890.00)
.. 2015-02-08 12:09:20: training at n-instances: 9000
.. 2015-02-08 12:09:20: cost: 2.168e-2 (13872.00)
.. 2015-02-08 12:09:22: training at n-instances: 12000
.. 2015-02-08 12:09:22: cost: 1.348e-2 (13953.00)
.. 2015-02-08 12:09:24: training at n-instances: 15000
.. 2015-02-08 12:09:24: cost: 9.696e-3 (13948.00)
.. 2015-02-08 12:09:26: training at n-instances: 18000
.. 2015-02-08 12:09:26: cost: 7.382e-3 (13849.00)
.. 2015-02-08 12:09:28: training at n-instances: 21000
.. 2015-02-08 12:09:28: cost: 5.861e-3 (13758.00)
.. 2015-02-08 12:09:30: training at n-instances: 24000
.. 2015-02-08 12:09:30: cost: 4.849e-3 (13908.00)
.. 2015-02-08 12:09:32: training at n-instances: 27000
.. 2015-02-08 12:09:32: cost: 4.013e-3 (13570.00)
.. 2015-02-08 12:09:34: training at n-instances: 30000
.. 2015-02-08 12:09:34: cost: 3.459e-3 (13721.00)
.. 2015-02-08 12:09:34: pred.        cost: 3.284e-3 (4593.00)
.. 2015-02-08 12:09:34: warped pred. cost: 3.285e-3 (9717.00)
.. 2015-02-08 12:09:34: Foreign memory usage:
.. foreign arrays: 220 (used bytes: 53,600)
.. CUDA memory usage:
.. device arrays: 148 (used bytes: 224,428, pooled bytes: 19,200)
.. host arrays: 216 (used bytes: 52,800)
.. host-&gt;device copies: 465,818, device-&gt;host copies: 371,990
..
==&gt; (#&lt;-&gt;WEIGHT (H (H :OUTPUT)) :SIZE 1 1/1 :norm 0.75226&gt;
--&gt;  #&lt;-&gt;WEIGHT (H (H :CELL)) :SIZE 1 1/1 :norm 0.04934&gt;
--&gt;  #&lt;-&gt;WEIGHT ((H :CELL) (H :FORGET) :PEEPHOLE) :SIZE 1 1/1 :norm 0.14970&gt;
--&gt;  #&lt;-&gt;WEIGHT (H (H :FORGET)) :SIZE 1 1/1 :norm 0.67698&gt;
--&gt;  #&lt;-&gt;WEIGHT ((H :CELL) (H :INPUT) :PEEPHOLE) :SIZE 1 1/1 :norm 1.40400&gt;
--&gt;  #&lt;-&gt;WEIGHT (H (H :INPUT)) :SIZE 1 1/1 :norm 0.33328&gt;
--&gt;  #&lt;-&gt;WEIGHT (H PREDICTION) :SIZE 3 1/1 :norm 21.41458&gt;
--&gt;  #&lt;-&gt;WEIGHT (:BIAS PREDICTION) :SIZE 3 1/1 :norm 4.97210&gt;
--&gt;  #&lt;-&gt;WEIGHT ((H :CELL) (H :OUTPUT) :PEEPHOLE) :SIZE 1 1/1 :norm 0.65959&gt;
--&gt;  #&lt;-&gt;WEIGHT (INPUT (H :OUTPUT)) :SIZE 1 1/1 :norm 0.77142&gt;
--&gt;  #&lt;-&gt;WEIGHT (:BIAS (H :OUTPUT)) :SIZE 1 1/1 :norm 6.28021&gt;
--&gt;  #&lt;-&gt;WEIGHT (INPUT (H :CELL)) :SIZE 1 1/1 :norm 4.96948&gt;
--&gt;  #&lt;-&gt;WEIGHT (:BIAS (H :CELL)) :SIZE 1 1/1 :norm 0.33460&gt;
--&gt;  #&lt;-&gt;WEIGHT (INPUT (H :FORGET)) :SIZE 1 1/1 :norm 3.11331&gt;
--&gt;  #&lt;-&gt;WEIGHT (:BIAS (H :FORGET)) :SIZE 1 1/1 :norm 1.13583&gt;
--&gt;  #&lt;-&gt;WEIGHT (INPUT (H :INPUT)) :SIZE 1 1/1 :norm 0.15849&gt;
--&gt;  #&lt;-&gt;WEIGHT (:BIAS (H :INPUT)) :SIZE 1 1/1 :norm 4.95984&gt;)

|#</span></span></code></pre>

<p><a name='x-28MGL-BP-3ARNN-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>RNN</strong> <em>BPN</em></p>

<p>A recurrent neural net (as opposed to a
feed-forward one. It is typically built with <a href="#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-RNN MGL-PAX:MACRO)"><code>BUILD-RNN</code></a> that's no
more than a shallow convenience macro.</p>

<p>An <code>RNN</code> takes instances as inputs that are sequences of variable
length. At each time step, the next unprocessed elements of these
sequences are set as input until all input sequences in the batch
run out. To be able to perform backpropagation, all intermediate
<a href="#x-28MGL-BP-3ALUMP-20CLASS-29" title="(MGL-BP:LUMP CLASS)"><code>LUMP</code></a>s must be kept around, so the recursive connections are
transformed out by
<a href="http://en.wikipedia.org/wiki/Backpropagation_through_time" >unfolding</a>
the network. Just how many lumps this means depends on the length of
the sequences.</p>

<p>When an <code>RNN</code> is created, <code>MAX-LAG + 1</code> BPNs are instantiated so
that all weights are present and one can start training it.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>UNFOLDER</strong> <em>RNN</em> <em>(:UNFOLDER)</em></p>

<p>The <code>UNFOLDER</code> of an <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a> is function of no arguments
that builds and returns a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>. The unfolder is allowed to create
networks with arbitrary topology even different ones for different
<a href="#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29" title="(MGL-BP:TIME-STEP FUNCTION)"><code>TIME-STEP</code></a>s with the help of <a href="#x-28MGL-BP-3ALAG-20FUNCTION-29" title="(MGL-BP:LAG FUNCTION)"><code>LAG</code></a>, or nested RNNs. Weights of
the same name are shared between the folds. That is, if a <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a>
lump were to be created and a weight lump of the same name already
exists, then the existing lump will be added to the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> created by
<code>UNFOLDER</code>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AMAX-LAG-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>MAX-LAG</strong> <em>RNN</em> <em>(:MAX-LAG = 1)</em></p>

<p>The networks built by <a href="#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN))"><code>UNFOLDER</code></a> may contain new
weights up to time step <code>MAX-LAG</code>. Beyond that point, all weight
lumps must be reappearances of weight lumps with the same name at
previous time steps. Most recurrent networks reference only the
state of lumps at the previous time step (with the function <a href="#x-28MGL-BP-3ALAG-20FUNCTION-29" title="(MGL-BP:LAG FUNCTION)"><code>LAG</code></a>),
hence the default of 1. But it is possible to have connections to
arbitrary time steps. The maximum connection lag must be specified
when creating the <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ACUDA-WINDOW-START-TIME-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>CUDA-WINDOW-START-TIME</strong> <em>RNN</em> <em>(:CUDA-WINDOW-START-TIME = *CUDA-WINDOW-START-TIME*)</em></p>

<p>Due to unfolding, the memory footprint of an <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>
is almost linear in the number of time steps (i.e. the max
sequence length). For prediction, this is addressed by
<a href="#x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TIME-WARP MGL-PAX:SECTION)">Time Warp</a>. For training, we cannot discard results of
previous time steps because they are needed for backpropagation,
but we can at least move them out of GPU memory if they are not
going to be used for a while and copy them back before they are
needed. Obviously, this is only relevant if CUDA is being used.</p>

<p>If <code>CUDA-WINDOW-START-TIME</code> is <code>NIL</code>, then this feature is turned off.
Else, during training, at <code>CUDA-WINDOW-START-TIME</code> or later time
steps, matrices belonging to non-weight lumps may be forced out of
GPU memory and later brought back as neeeded.</p>

<p>This feature is implemented in terms of
<code>MGL-MAT:WITH-SYNCING-CUDA-FACETS</code> that uses CUDA host memory (also
known as <em>page-locked</em> or <em>pinned memory</em>) to do asynchronous
copies concurrently with normal computation. The consequence of
this is that it is now main memory usage that's unbounded which
toghether with page-locking makes it a potent weapon to bring a
machine to a halt. You were warned.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-2ACUDA-WINDOW-START-TIME-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*CUDA-WINDOW-START-TIME*</strong> <em>NIL</em></p>

<p>The default for <a href="#x-28MGL-BP-3ACUDA-WINDOW-START-TIME-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29" title="(MGL-BP:CUDA-WINDOW-START-TIME (MGL-PAX:ACCESSOR MGL-BP:RNN))"><code>CUDA-WINDOW-START-TIME</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>BUILD-RNN</strong> <em>(&amp;KEY RNN (CLASS ''RNN) NAME INITARGS MAX-N-STRIPES (MAX-LAG 1)) &amp;BODY BODY</em></p>

<p>Create an <code>RNN</code> with <code>MAX-N-STRIPES</code> and <code>MAX-LAG</code> whose <a href="#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN))"><code>UNFOLDER</code></a> is <code>BODY</code>
wrapped in a lambda. Bind symbol given as the <code>RNN</code> argument to the
<code>RNN</code> object so that <code>BODY</code> can see it.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ALAG-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>LAG</strong> <em>NAME &amp;KEY (LAG 1) RNN PATH</em></p>

<p>In <code>RNN</code> or if it's <code>NIL</code> the <code>RNN</code> being extended with another
<a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> (called <em>unfolding</em>), look up the <a href="#x-28MGL-BP-3ACLUMP-20CLASS-29" title="(MGL-BP:CLUMP CLASS)"><code>CLUMP</code></a> with <code>NAME</code> in the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>
that's <code>LAG</code> number of time steps before the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> being added. If this
function is called from <a href="#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN))"><code>UNFOLDER</code></a> of an <code>RNN</code> (which is what happens
behind the scene in the body of <a href="#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-RNN MGL-PAX:MACRO)"><code>BUILD-RNN</code></a>), then it returns an
opaque object representing a lagged connection to a clump, else it
returns the <a href="#x-28MGL-BP-3ACLUMP-20CLASS-29" title="(MGL-BP:CLUMP CLASS)"><code>CLUMP</code></a> itself.</p>

<p>FIXDOC: <code>PATH</code></p></li>
</ul>

<p><a name='x-28MGL-BP-3ATIME-STEP-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>TIME-STEP</strong> <em>&amp;KEY (RNN *RNN*)</em></p>

<p>Return the time step <code>RNN</code> is currently executing or being unfolded for.
It is 0 when the <code>RNN</code> is being unfolded for the first time.</p></li>
</ul>

<p><a name='x-28MGL-CORE-3ASET-INPUT-20-28METHOD-20NIL-20-28T-20MGL-BP-3ARNN-29-29-29'></a></p>

<ul>
<li><p>[method] <strong>SET-INPUT</strong> <em>INSTANCES (RNN RNN)</em></p>

<p>RNNs operate on batches of instances just like FNNs. But the
instances here are like datasets: sequences or samplers and they are
turned into sequences of batches of instances with
<a href="#x-28MGL-DATASET-3AMAP-DATASETS-20FUNCTION-29" title="(MGL-DATASET:MAP-DATASETS FUNCTION)"><code>MAP-DATASETS</code></a> <code>:IMPUTE</code> <code>NIL</code>. The batch of instances at index 2 is
clamped onto the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> at time step 2 with <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>.</p>

<p>When the input sequences in the batch are not of the same length,
already exhausted sequences will produce <code>NIL</code> (due to <code>:IMPUTE</code> <code>NIL</code>)
above. When such a <code>NIL</code> is clamped with <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a> on a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> of the
<code>RNN</code>, <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a> must set the <a href="#x-28MGL-BP-3AIMPORTANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ELOSS-29-29" title="(MGL-BP:IMPORTANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;LOSS))"><code>IMPORTANCE</code></a> of the -&gt;ERROR lumps to 0
else training would operate on the noise left there by previous
invocations.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TUTORIAL MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TIME-WARP MGL-PAX:SECTION)">&#8634;</a></span>Time Warp</h5>

<p>The unbounded memory usage of <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>s with one <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> allocated per
time step can become a problem. For training, where the gradients
often have to be backpropagated from the last time step to the very
beginning, this is hard to solve but with <a href="#x-28MGL-BP-3ACUDA-WINDOW-START-TIME-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29" title="(MGL-BP:CUDA-WINDOW-START-TIME (MGL-PAX:ACCESSOR MGL-BP:RNN))"><code>CUDA-WINDOW-START-TIME</code></a> the
limit is no longer GPU memory.</p>

<p>For prediction on the other hand, one doesn't need to keep old steps
around indefinitely: they can be discarded when future time steps
will never reference them again.</p>

<p><a name='x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29'></a></p>

<ul>
<li><p>[variable] <strong>*WARP-TIME*</strong> <em>NIL</em></p>

<p>Controls whether warping is enabled (see <a href="#x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TIME-WARP MGL-PAX:SECTION)">Time Warp</a>). Don't
enable it for training, as it would make backprop impossible.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AWARPED-TIME-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>WARPED-TIME</strong> <em>&amp;KEY (RNN *RNN*) (TIME (TIME-STEP :RNN RNN)) (LAG 0)</em></p>

<p>Return the index of the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> in <a href="#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN))"><code>CLUMPS</code></a> of <code>RNN</code> whose task it is to
execute computation at <code>(- (TIME-STEP RNN) LAG)</code>. This is normally
the same as <a href="#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29" title="(MGL-BP:TIME-STEP FUNCTION)"><code>TIME-STEP</code></a> (disregarding <code>LAG</code>). That is, <a href="#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN))"><code>CLUMPS</code></a> can be
indexed by <a href="#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29" title="(MGL-BP:TIME-STEP FUNCTION)"><code>TIME-STEP</code></a> to get the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>. However, when <a href="#x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29" title="(MGL-BP:*WARP-TIME* VARIABLE)"><code>*WARP-TIME*</code></a> is
true, execution proceeds in a cycle as the structure of the network
allows.</p>

<p>Suppose we have a typical <code>RNN</code> that only ever references the previous
time step so its <a href="#x-28MGL-BP-3AMAX-LAG-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:MAX-LAG (MGL-PAX:READER MGL-BP:RNN))"><code>MAX-LAG</code></a> is 1. Its <a href="#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN))"><code>UNFOLDER</code></a> returns <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>s of
identical structure bar a shift in their time lagged connections
except for the very first, so <a href="#x-28MGL-BP-3AWARP-START-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:WARP-START (MGL-PAX:READER MGL-BP:RNN))"><code>WARP-START</code></a> and <a href="#x-28MGL-BP-3AWARP-LENGTH-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:WARP-LENGTH (MGL-PAX:READER MGL-BP:RNN))"><code>WARP-LENGTH</code></a> are both 1.
If <a href="#x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29" title="(MGL-BP:*WARP-TIME* VARIABLE)"><code>*WARP-TIME*</code></a> is <code>NIL</code>, then the mapping from <a href="#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29" title="(MGL-BP:TIME-STEP FUNCTION)"><code>TIME-STEP</code></a> to the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> in
<a href="#x-28MGL-BP-3ACLUMPS-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-BP:CLUMPS (MGL-PAX:READER MGL-BP:BPN))"><code>CLUMPS</code></a> is straightforward:</p>

<pre><code>time:   |  0 |  1 |  2 |  3 |  4 |  5
--------+----+----+----+----+----+----
warped: |  0 |  1 |  2 |  3 |  4 |  5
--------+----+----+----+----+----+----
bpn:    | b0 | b1 | b2 | b3 | b4 | b5
</code></pre>

<p>When <a href="#x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29" title="(MGL-BP:*WARP-TIME* VARIABLE)"><code>*WARP-TIME*</code></a> is true, we reuse the <code>B1</code> - <code>B2</code> bpns in a loop:</p>

<pre><code>time:   |  0 |  1 |  2 |  3 |  4 |  5
--------+----+----+----+----+----+----
warped: |  0 |  1 |  2 |  1 |  2 |  1
--------+----+----+----+----+----+----
bpn:    | b0 | b1 | b2 | b1*| b2 | b1*
</code></pre>

<p><code>B1*</code> is the same <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> as <code>B1</code>, but its connections created by <code>LAG</code> go
through warped time and end up referencing <code>B2</code>. This way, memory
consumption is independent of the number time steps needed to
process a sequence or make predictions.</p>

<p>To be able to pull this trick off <a href="#x-28MGL-BP-3AWARP-START-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:WARP-START (MGL-PAX:READER MGL-BP:RNN))"><code>WARP-START</code></a> and <a href="#x-28MGL-BP-3AWARP-LENGTH-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:WARP-LENGTH (MGL-PAX:READER MGL-BP:RNN))"><code>WARP-LENGTH</code></a> must be
specified when the <code>RNN</code> is instantiated. In general, with
<a href="#x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29" title="(MGL-BP:*WARP-TIME* VARIABLE)"><code>*WARP-TIME*</code></a> <code>(+ WARP-START (MAX 2 WARP-LENGTH))</code> bpns are needed.
The 2 comes from the fact that with cycle length 1 a bpn would need
to takes its input from itself which is problematic because it has
<a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> for only one set of values.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AWARP-START-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>WARP-START</strong> <em>RNN</em> <em>(:WARP-START = 1)</em></p>

<p>The <a href="#x-28MGL-BP-3ATIME-STEP-20FUNCTION-29" title="(MGL-BP:TIME-STEP FUNCTION)"><code>TIME-STEP</code></a> from which <a href="#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN))"><code>UNFOLDER</code></a> will create
<a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>s that essentially repeat every <a href="#x-28MGL-BP-3AWARP-LENGTH-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:WARP-LENGTH (MGL-PAX:READER MGL-BP:RNN))"><code>WARP-LENGTH</code></a> steps.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AWARP-LENGTH-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>WARP-LENGTH</strong> <em>RNN</em> <em>(:WARP-LENGTH = 1)</em></p>

<p>An integer such that the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> <a href="#x-28MGL-BP-3AUNFOLDER-20-28MGL-PAX-3AREADER-20MGL-BP-3ARNN-29-29" title="(MGL-BP:UNFOLDER (MGL-PAX:READER MGL-BP:RNN))"><code>UNFOLDER</code></a> creates at
time step <code>I</code> (where <code>(&lt;= WARP-START I)</code>) is identical to the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>
created at time step <code>(+ WARP-START (MOD (- I WARP-START)
WARP-LENGTH))</code> except for a shift in its time lagged
connections.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ASTEP-MONITORS-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3ARNN-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>STEP-MONITORS</strong> <em>RNN</em> <em>(:STEP-MONITORS = NIL)</em></p>

<p>During training, unfolded <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>s corresponding to
previous time steps may be expensive to get at because they are no
longer in GPU memory. This consideration also applies to making
prediction with the additional caveat that with <a href="#x-28MGL-BP-3A-2AWARP-TIME-2A-20VARIABLE-29" title="(MGL-BP:*WARP-TIME* VARIABLE)"><code>*WARP-TIME*</code></a> true,
previous states are discarded so it's not possible to gather
statistics after <a href="#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:FORWARD GENERIC-FUNCTION)"><code>FORWARD</code></a> finished.</p>

<p>Add monitor objects to this slot and they will be automatically
applied to the <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a> after each step when <a href="#x-28MGL-BP-3AFORWARD-20GENERIC-FUNCTION-29" title="(MGL-BP:FORWARD GENERIC-FUNCTION)"><code>FORWARD</code></a>ing the <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>
during training or prediction. To be able to easily switch between
sets of monitors, in addition to a list of monitors this can be a
symbol or a function, too. If it's a symbol, then its a designator
for its <code>SYMBOL-VALUE</code>. If it's a function, then it must have no
arguments and it's a designator for its return value.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-RNN-TIME-WARP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TIME-WARP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8634;</a></span>10.4 Lumps</h3>

<p><a name='x-28MGL-BP-3A-40MGL-BP-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUTS MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMP MGL-PAX:SECTION)">&#8634;</a></span>10.4.1 Lump Base Class</h4>

<p><a name='x-28MGL-BP-3ALUMP-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>LUMP</strong> <em>CLUMP</em></p>

<p>A <code>LUMP</code> is a simple, layerlike component of a neural
network. There are many kinds of lumps, each of which performs a
specific operation or just stores inputs and weights. By convention,
the names of lumps start with the prefix <code>-&gt;</code>. Defined as classes,
they also have a function of the same name as the class to create
them easily. These maker functions typically have keyword arguments
corresponding to initargs of the class, with some (mainly the input
lumps) turned into normal positional arguments. So instead of having
to do</p>

<pre><code>(make-instance '-&gt;tanh :x some-input :name 'my-tanh)
</code></pre>

<p>one can simply write</p>

<pre><code>(-&gt;tanh some-input :name 'my-tanh)
</code></pre>

<p>Lumps instantiated in any way within a <a href="#x-28MGL-BP-3ABUILD-FNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-FNN MGL-PAX:MACRO)"><code>BUILD-FNN</code></a> or <a href="#x-28MGL-BP-3ABUILD-RNN-20MGL-PAX-3AMACRO-29" title="(MGL-BP:BUILD-RNN MGL-PAX:MACRO)"><code>BUILD-RNN</code></a> are
automatically added to the network being built.</p>

<p>A lump has its own <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> and <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> matrices allocated for it
in which the results of the forward and backward passes are stored.
This is in contrast to a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> whose <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> and <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a>
are those of its last constituent <a href="#x-28MGL-BP-3ACLUMP-20CLASS-29" title="(MGL-BP:CLUMP CLASS)"><code>CLUMP</code></a>.</p>

<p>Since lumps almost always live within a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a>, their
<a href="#x-28MGL-CORE-3AN-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-CORE:N-STRIPES (MGL-PAX:READER MGL-BP:BPN))"><code>N-STRIPES</code></a> and <a href="#x-28MGL-CORE-3AMAX-N-STRIPES-20-28MGL-PAX-3AREADER-20MGL-BP-3ABPN-29-29" title="(MGL-CORE:MAX-N-STRIPES (MGL-PAX:READER MGL-BP:BPN))"><code>MAX-N-STRIPES</code></a> are
handled automagically behind the scenes.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29'></a></p>

<ul>
<li><p>[reader] <strong>SIZE</strong> <em>LUMP</em> <em>(:SIZE)</em></p>

<p>The number of values in a single stripe.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ADEFAULT-VALUE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29'></a></p>

<ul>
<li><p>[reader] <strong>DEFAULT-VALUE</strong> <em>LUMP</em> <em>(:DEFAULT-VALUE = 0)</em></p>

<p>Upon creation or resize the lump's nodes get
filled with this value.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ADEFAULT-SIZE-20GENERIC-FUNCTION-29'></a></p>

<ul>
<li><p>[generic-function] <strong>DEFAULT-SIZE</strong> <em>LUMP</em></p>

<p>Return a default for the <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>SIZE</code></a> of
<code>LUMP</code> if one is not supplied at instantiation. The value is often
computed based on the sizes of the inputs. This function is for
implementing new lump types.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ANODES-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29'></a></p>

<ul>
<li><p>[reader] <strong>NODES</strong> <em>LUMP</em> <em>(= NIL)</em></p>

<p>The values computed by the lump in the forward
pass are stored here. It is an <code>N-STRIPES * SIZE</code> matrix that has
storage allocated for <code>MAX-N-STRIPES * SIZE</code> elements for
non-weight lumps. <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a> lumps have no stripes nor restrictions
on their shape.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ADERIVATIVES-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29'></a></p>

<ul>
<li><p>[reader] <strong>DERIVATIVES</strong> <em>LUMP</em></p>

<p>The derivatives computed in the backward pass are
stored here. This matrix is very much like <a href="#x-28MGL-COMMON-3ANODES-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:NODES (MGL-PAX:READER MGL-BP:LUMP))"><code>NODES</code></a>
in shape and size.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUT-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUTS MGL-PAX:SECTION)">&#8634;</a></span>10.4.2 Inputs</h4>

<p><a name='x-28MGL-BP-3A-40MGL-BP-INPUT-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUTS MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUTS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-EMBEDDING-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EMBEDDING-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUT-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Input Lump</h5>

<p><a name='x-28MGL-BP-3A--3EINPUT-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;INPUT</strong> <em>-&gt;DROPOUT</em></p>

<p>A lump that has no input lumps, does not change its
values in the forward pass (except when <a href="#x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EINPUT-29-29" title="(MGL-BP:DROPOUT (MGL-PAX:ACCESSOR MGL-BP:-&gt;INPUT))"><code>DROPOUT</code></a> is non-zero), and does not compute derivatives. <em>Clamp</em>
inputs on <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> of input lumps in <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>.</p>

<p>For convenience, <code>-&gt;INPUT</code> can perform dropout itself although it
defaults to no dropout.</p>

<pre><code>(->input :size 10 :name 'some-input)
==> #<->INPUT SOME-INPUT :SIZE 10 1/1 :norm 0.00000>
</code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EINPUT-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>DROPOUT</strong> <em>-&gt;INPUT</em> <em>(= NIL)</em></p>

<p>See <a href="#x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EDROPOUT-29-29" title="(MGL-BP:DROPOUT (MGL-PAX:ACCESSOR MGL-BP:-&gt;DROPOUT))"><code>DROPOUT</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-EMBEDDING-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUT-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-INPUTS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-INPUTS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-WEIGHT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-WEIGHT-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-EMBEDDING-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EMBEDDING-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Embedding Lump</h5>

<p>This lump is like an input and a simple activation molded together
in the name of efficiency.</p>

<p><a name='x-28MGL-BP-3A--3EEMBEDDING-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;EMBEDDING</strong> <em>LUMP</em></p>

<p>Select rows of <code>WEIGHTS</code>(<a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>0</code></a> <a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>1</code></a>), one row for each index in
<a href="#x-28MGL-BP-3AINPUT-ROW-INDICES-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-BP:INPUT-ROW-INDICES (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>INPUT-ROW-INDICES</code></a>. This lump is equivalent to adding an <a href="#x-28MGL-BP-3A--3EINPUT-20CLASS-29" title="(MGL-BP:-&gt;INPUT CLASS)"><code>-&gt;INPUT</code></a> lump
with a one hot encoding scheme and a <a href="#x-28MGL-BP-3A--3EV-2AM-20CLASS-29" title="(MGL-BP:-&gt;V*M CLASS)"><code>-&gt;V*M</code></a> lump on top of it, but it
is more efficient in execution and in memory usage, because it works
with a sparse representation of the input.</p>

<p>The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is the number of columns of <code>WEIGHTS</code>(<a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>0</code></a> <a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>1</code></a>) which is
determined automatically.</p>

<pre><code>(->embedding :weights (->weight :name 'embedding-weights
                                :dimensions '(3 5))
             :name 'embeddings)
==> #<->EMBEDDING EMBEDDINGS :SIZE 5 1/1 :norm 0.00000>
</code></pre></li>
</ul>

<p><a name='x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29'></a></p>

<ul>
<li><p>[reader] <strong>WEIGHTS</strong> <em>-&gt;EMBEDDING</em> <em>(:WEIGHTS)</em></p>

<p>A weight lump whose rows indexed by
<a href="#x-28MGL-BP-3AINPUT-ROW-INDICES-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-BP:INPUT-ROW-INDICES (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>INPUT-ROW-INDICES</code></a> are copied to the output of this lump.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AINPUT-ROW-INDICES-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29'></a></p>

<ul>
<li><p>[reader] <strong>INPUT-ROW-INDICES</strong> <em>-&gt;EMBEDDING</em> <em>(:INPUT-ROW-INDICES)</em></p>

<p>A sequence of batch size length of row indices. To
be set in <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-WEIGHT-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-EMBEDDING-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EMBEDDING-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-SUBNET-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-SUBNET MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-WEIGHT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-WEIGHT-LUMP MGL-PAX:SECTION)">&#8634;</a></span>10.4.3 Weight Lump</h4>

<p><a name='x-28MGL-BP-3A--3EWEIGHT-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;WEIGHT</strong> <em>LUMP</em></p>

<p>A set of optimizable parameters of some kind. When
a <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> is is trained (see <a href="#x-28MGL-BP-3A-40MGL-BP-TRAINING-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TRAINING MGL-PAX:SECTION)">Training</a>) the <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> of weight lumps
will be changed. Weight lumps perform no computation.</p>

<p>Weights can be created by specifying the total size or the
dimensions:</p>

<pre><code>(dimensions (->weight :size 10 :name 'w))
=> (1 10)
(dimensions (->weight :dimensions '(5 10) :name 'w))
=> (5 10)
</code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3ADIMENSIONS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EWEIGHT-29-29'></a></p>

<ul>
<li><p>[reader] <strong>DIMENSIONS</strong> <em>-&gt;WEIGHT</em> <em>(:DIMENSIONS)</em></p>

<p><a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a> and <a href="#x-28MGL-BP-3ADERIVATIVES-20GENERIC-FUNCTION-29" title="(MGL-BP:DERIVATIVES GENERIC-FUNCTION)"><code>DERIVATIVES</code></a> of this lump will be
allocated with these dimensions.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AWITH-WEIGHTS-COPIED-20MGL-PAX-3AMACRO-29'></a></p>

<ul>
<li><p>[macro] <strong>WITH-WEIGHTS-COPIED</strong> <em>(FROM-BPN) &amp;BODY BODY</em></p>

<p>In <code>BODY</code> <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a> will first look up if a weight lump of the same
name exists in <code>FROM-BPN</code> and return that, or else create a weight
lump normally. If <code>FROM-BPN</code> is <code>NIL</code>, then no weights are copied.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-ACTIVATION-SUBNET-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-WEIGHT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-WEIGHT-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-SUBNET-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-SUBNET MGL-PAX:SECTION)">&#8634;</a></span>10.4.4 Activation Subnet</h4>

<p>So we have some inputs. Usually the next step is to multiply the
input vector with a weight matrix and add biases. This can be done
directly with <a href="#x-28MGL-BP-3A--3E-2B-20CLASS-29" title="(MGL-BP:-&gt;+ CLASS)"><code>-&gt;+</code></a>, <a href="#x-28MGL-BP-3A--3EV-2AM-20CLASS-29" title="(MGL-BP:-&gt;V*M CLASS)"><code>-&gt;V*M</code></a> and <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a>, but it's more convenient to
use activation subnets to reduce the clutter.</p>

<p><a name='x-28MGL-BP-3A--3EACTIVATION-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;ACTIVATION</strong> <em>BPN</em></p>

<p>Activation subnetworks are built by the function
<code>-&gt;ACTIVATION</code> and they have a number of lumps hidden inside them.
Ultimately, this subnetwork computes a sum like <code>sum_i x_i * W_i +
sum_j y_j .* V_j + biases</code> where <code>x_i</code> are input lumps, <code>W_i</code> are
dense matrices representing connections, while <code>V_j</code> are peephole
connection vectors that are mulitplied in an elementwise manner with
their corresponding input <code>y_j</code>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A--3EACTIVATION-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>-&gt;ACTIVATION</strong> <em>INPUTS &amp;KEY (NAME (GENSYM)) SIZE PEEPHOLES (ADD-BIAS-P T)</em></p>

<p>Create a subnetwork of class <a href="#x-28MGL-BP-3A--3EACTIVATION-20CLASS-29" title="(MGL-BP:-&gt;ACTIVATION CLASS)"><code>-&gt;ACTIVATION</code></a> that computes the over
activation from dense connection from lumps in <code>INPUTS</code>, and
elementwise connection from lumps in <code>PEEPHOLES</code>. Create new <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a>
lumps as necessary. <code>INPUTS</code> and <code>PEEPHOLES</code> can be a single lump or a
list of lumps. Finally, if <code>ADD-BIAS-P</code>, then add an elementwise bias
too. <code>SIZE</code> must be specified explicitly, because it is not possible
to determine it unless there are peephole connections.</p>

<pre><code>(->activation (->input :size 10 :name 'input) :name 'h1 :size 4)
==> #<->ACTIVATION (H1 :ACTIVATION) :STRIPES 1/1 :CLUMPS 4>
</code></pre>

<p>This is the basic workhorse of neural networks which takes care of
the linear transformation whose results and then fed to some
non-linearity (<a href="#x-28MGL-BP-3A--3ESIGMOID-20CLASS-29" title="(MGL-BP:-&gt;SIGMOID CLASS)"><code>-&gt;SIGMOID</code></a>, <a href="#x-28MGL-BP-3A--3ETANH-20CLASS-29" title="(MGL-BP:-&gt;TANH CLASS)"><code>-&gt;TANH</code></a>, etc).</p>

<p>The name of the subnetwork clump is <code>(,NAME :ACTIVATION)</code>. The bias
weight lump (if any) is named <code>(:BIAS ,NAME)</code>. Dense connection
weight lumps are named are named after the input and <code>NAME</code>: <code>(,(NAME
INPUT) ,NAME)</code>, while peepholes weight lumps are named <code>(,(NAME
INPUT) ,NAME :PEEPHOLE)</code>. This is useful to know if, for example,
they are to be initialized differently.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-SUBNET-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-SUBNET MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SIGMOID-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SIGMOID-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8634;</a></span>10.4.5 Activation Functions</h4>

<p>Now we are moving on to the most important non-linearities to which
activations are fed.</p>

<p><a name='x-28MGL-BP-3A-40MGL-BP-SIGMOID-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-TANH-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TANH-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SIGMOID-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SIGMOID-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Sigmoid Lump</h5>

<p><a name='x-28MGL-BP-3A--3ESIGMOID-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;SIGMOID</strong> <em>-&gt;DROPOUT LUMP</em></p>

<p>Applies the <code>1/(1 + e^{-x})</code> function elementwise
to its inputs. This is one of the classic non-linearities for neural
networks.</p>

<p>For convenience, <code>-&gt;SIGMOID</code> can perform dropout itself although it
defaults to no dropout.</p>

<pre><code>(->sigmoid (->activation (->input :size 10) :size 5) :name 'this)
==> #<->SIGMOID THIS :SIZE 5 1/1 :norm 0.00000>
</code></pre>

<p>The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is the size of its input which is determined
automatically.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESIGMOID-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>DROPOUT</strong> <em>-&gt;SIGMOID</em> <em>(= NIL)</em></p>

<p>See <a href="#x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EDROPOUT-29-29" title="(MGL-BP:DROPOUT (MGL-PAX:ACCESSOR MGL-BP:-&gt;DROPOUT))"><code>DROPOUT</code></a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-TANH-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-SIGMOID-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SIGMOID-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SCALED-TANH-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SCALED-TANH-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-TANH-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TANH-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Tanh Lump</h5>

<p><a name='x-28MGL-BP-3A--3ETANH-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;TANH</strong> <em>LUMP</em></p>

<p>Applies the <code>TANH</code> function to its input in an
elementwise manner. The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is the size of its input
which is determined automatically.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-SCALED-TANH-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-TANH-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-TANH-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-RELU-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RELU-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SCALED-TANH-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SCALED-TANH-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Scaled Tanh Lump</h5>

<p><a name='x-28MGL-BP-3A--3ESCALED-TANH-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;SCALED-TANH</strong> <em>LUMP</em></p>

<p>Pretty much like <code>TANH</code> but its input and output is
scaled in such a way that the variance of its output is close to 1
if the variance of its input is close to 1 which is a nice property
to combat vanishing gradients. The actual function is <code>1.7159 *
tanh(2/3 * x)</code>. The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is the size of its input which
is determined automatically.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-RELU-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-SCALED-TANH-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SCALED-TANH-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MAX-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MAX-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-RELU-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RELU-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Relu Lump</h5>

<p>We are somewhere around year 2007 by now.</p>

<p><a name='x-28MGL-BP-3A--3ERELU-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;RELU</strong> <em>LUMP</em></p>

<p><code>max(0,x)</code> activation function. Be careful, relu
units can get stuck in the off state: if they move to far to
negative territory it can be very difficult to get out of it. The
<code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is the size of its input which is determined
automatically.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-MAX-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-RELU-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RELU-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MIN-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MIN-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MAX-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MAX-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Max Lump</h5>

<p>We are in about year 2011.</p>

<p><a name='x-28MGL-BP-3A--3EMAX-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;MAX</strong> <em>LUMP</em></p>

<p>This is basically maxout without dropout (see
http://arxiv.org/abs/1302.4389). It groups its inputs by
<a href="#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-29-29" title="(MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;MAX))"><code>GROUP-SIZE</code></a>, and outputs the maximum of each group.
The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of the output is automatically calculated, it is the size
of the input divided by <a href="#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-29-29" title="(MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;MAX))"><code>GROUP-SIZE</code></a>.</p>

<pre><code>(->max (->input :size 120) :group-size 3 :name 'my-max)
==> #<->MAX MY-MAX :SIZE 40 1/1 :norm 0.00000>
</code></pre>

<p>The advantage of <code>-&gt;MAX</code> over <a href="#x-28MGL-BP-3A--3ERELU-20CLASS-29" title="(MGL-BP:-&gt;RELU CLASS)"><code>-&gt;RELU</code></a> is that flow gradient is never
stopped so there is no problem of units getting stuck in off
state.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-29-29'></a></p>

<ul>
<li><p>[reader] <strong>GROUP-SIZE</strong> <em>-&gt;MAX</em> <em>(:GROUP-SIZE)</em></p>

<p>The number of inputs in each group.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-MIN-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-MAX-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MAX-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MAX-CHANNEL-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MAX-CHANNEL-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MIN-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MIN-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Min Lump</h5>

<p><a name='x-28MGL-BP-3A--3EMIN-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;MIN</strong> <em>LUMP</em></p>

<p>Same as <a href="#x-28MGL-BP-3A--3EMAX-20CLASS-29" title="(MGL-BP:-&gt;MAX CLASS)"><code>-&gt;MAX</code></a>, but it computes the <code>MIN</code> of groups.
Rarely useful.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMIN-29-29'></a></p>

<ul>
<li><p>[reader] <strong>GROUP-SIZE</strong> <em>-&gt;MIN</em> <em>(:GROUP-SIZE)</em></p>

<p>The number of inputs in each group.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-MAX-CHANNEL-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-MIN-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MIN-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ACTIVATION-FUNCTIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ACTIVATION-FUNCTIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSSES MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-MAX-CHANNEL-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MAX-CHANNEL-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Max-Channel Lump</h5>

<p><a name='x-28MGL-BP-3A--3EMAX-CHANNEL-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;MAX-CHANNEL</strong> <em>LUMP</em></p>

<p>Called LWTA (Local Winner Take All) or
Channel-Out (see http://arxiv.org/abs/1312.1909) in the literature
it is basically <a href="#x-28MGL-BP-3A--3EMAX-20CLASS-29" title="(MGL-BP:-&gt;MAX CLASS)"><code>-&gt;MAX</code></a>, but instead of producing one output per
group, it just produces zeros for all unit but the one with the
maximum value in the group. This allows the next layer to get some
information about the path along which information flowed. The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>)
of this lump is the size of its input which is determined
automatically.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EMAX-CHANNEL-29-29'></a></p>

<ul>
<li><p>[reader] <strong>GROUP-SIZE</strong> <em>-&gt;MAX-CHANNEL</em> <em>(:GROUP-SIZE)</em></p>

<p>The number of inputs in each group.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-MAX-CHANNEL-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-MAX-CHANNEL-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSS-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSSES MGL-PAX:SECTION)">&#8634;</a></span>10.4.6 Losses</h4>

<p>Ultimately, we need to tell the network what to learn which means
that the loss function to be minimized needs to be constructed as
part of the network.</p>

<p><a name='x-28MGL-BP-3A-40MGL-BP-LOSS-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSSES MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSSES MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SQUARED-DIFFERENCE-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SQUARED-DIFFERENCE-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSS-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Loss Lump</h5>

<p><a name='x-28MGL-BP-3A--3ELOSS-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;LOSS</strong> <em>-&gt;SUM</em></p>

<p>Calculate the loss for the instances in the batch.
The main purpose of this lump is to provide a training signal.</p>

<p>An error lump is usually a leaf in the graph of lumps (i.e. there
are no other lumps whose input is this one). The special thing about
error lumps is that 1 (but see <a href="#x-28MGL-BP-3AIMPORTANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ELOSS-29-29" title="(MGL-BP:IMPORTANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;LOSS))"><code>IMPORTANCE</code></a>) is added automatically to
their derivatives. Error lumps have exactly one node (per stripe)
whose value is computed as the sum of nodes in their input lump.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AIMPORTANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ELOSS-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>IMPORTANCE</strong> <em>-&gt;LOSS</em> <em>(:IMPORTANCE = NIL)</em></p>

<p>This is to support weighted instances. That is
when not all training instances are equally important. If non-NIL,
a 1d <code>MAT</code> with the importances of stripes of the batch. When
<code>IMPORTANCE</code> is given (typically in <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>), then instead of
adding 1 to the derivatives of all stripes, <code>IMPORTANCE</code> is added
elemtwise.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-SQUARED-DIFFERENCE-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSS-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSSES MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SOFTMAX-XE-LOSS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SOFTMAX-XE-LOSS-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SQUARED-DIFFERENCE-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SQUARED-DIFFERENCE-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Squared Difference Lump</h5>

<p>In regression, the squared error loss is most common. The squared
error loss can be constructed by combining <a href="#x-28MGL-BP-3A--3ESQUARED-DIFFERENCE-20CLASS-29" title="(MGL-BP:-&gt;SQUARED-DIFFERENCE CLASS)"><code>-&gt;SQUARED-DIFFERENCE</code></a> with
a <a href="#x-28MGL-BP-3A--3ELOSS-20CLASS-29" title="(MGL-BP:-&gt;LOSS CLASS)"><code>-&gt;LOSS</code></a>.</p>

<p><a name='x-28MGL-BP-3A--3ESQUARED-DIFFERENCE-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;SQUARED-DIFFERENCE</strong> <em>LUMP</em></p>

<p>This lump takes two input lumps and calculates
their squared difference <code>(x - y)^2</code> in an elementwise manner. The
<code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is automatically determined from the size of its
inputs. This lump is often fed into <a href="#x-28MGL-BP-3A--3ELOSS-20CLASS-29" title="(MGL-BP:-&gt;LOSS CLASS)"><code>-&gt;LOSS</code></a> that sums the squared
differences and makes it part of the function to be minimized.</p>

<pre><code>(->loss (->squared-difference (->activation (->input :size 100)
                                            :size 10)
                              (->input :name 'target :size 10))
        :name 'squared-error)
==> #<->LOSS SQUARED-ERROR :SIZE 1 1/1 :norm 0.00000>
</code></pre>

<p>Currently this lump is not CUDAized, but it will copy data from the
GPU if it needs to.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-SOFTMAX-XE-LOSS-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-SQUARED-DIFFERENCE-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SQUARED-DIFFERENCE-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LOSSES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LOSSES MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-STOCHASTICITY MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SOFTMAX-XE-LOSS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SOFTMAX-XE-LOSS-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Softmax Cross-Entropy Loss Lump</h5>

<p><a name='x-28MGL-BP-3A--3ESOFTMAX-XE-LOSS-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;SOFTMAX-XE-LOSS</strong> <em>LUMP</em></p>

<p>A specialized lump that computes the softmax of its
input in the forward pass and backpropagates a cross-entropy loss.
The advantage of doing these together is numerical stability. The
total cross-entropy is the sum of cross-entropies per group of
<a href="#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29" title="(MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS))"><code>GROUP-SIZE</code></a> elements:</p>

<pre><code>XE(x) = - sum_{i=1,g} t_i * ln(s_i)
</code></pre>

<p>where <code>g</code> is the number of classes (<a href="#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29" title="(MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS))"><code>GROUP-SIZE</code></a>), <code>t_i</code> are the targets (i.e. the true
probabilities of the class, often all zero but one), <code>s_i</code> is the
output of softmax calculated from input <code>X</code>:</p>

<pre><code>s_i = softmax{x_1, x_2, ..., x_g} = e^x_i / (sum_{j=1,g} e^x_j)
</code></pre>

<p>In other words, in the forward phase this lump takes input <code>X</code>,
computes its elementwise <code>EXP</code>, normalizes each group of
<a href="#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29" title="(MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS))"><code>GROUP-SIZE</code></a> elements to sum to 1 to get
the softmax which is the result that goes into <a href="#x-28MGL-COMMON-3ANODES-20GENERIC-FUNCTION-29" title="(MGL-COMMON:NODES GENERIC-FUNCTION)"><code>NODES</code></a>. In the
backward phase, there are two sources of gradients: the lumps that
use the output of this lump as their input (currently not
implemented and would result in an error) and an implicit
cross-entropy loss.</p>

<p>One can get the cross-entropy calculated in the most recent forward
pass by calling <a href="#x-28MGL-COMMON-3ACOST-20GENERIC-FUNCTION-29" title="(MGL-COMMON:COST GENERIC-FUNCTION)"><code>COST</code></a> on this lump.</p>

<p>This is the most common loss function for classification. In fact,
it is nearly ubiquitous. See the <a href="#x-28MGL-BP-3A-40MGL-FNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-FNN-TUTORIAL MGL-PAX:SECTION)">FNN Tutorial</a> and the
<a href="#x-28MGL-BP-3A-40MGL-RNN-TUTORIAL-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-RNN-TUTORIAL MGL-PAX:SECTION)">RNN Tutorial</a> for how this loss and <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a> work together.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29'></a></p>

<ul>
<li><p>[reader] <strong>GROUP-SIZE</strong> <em>-&gt;SOFTMAX-XE-LOSS</em> <em>(:GROUP-SIZE)</em></p>

<p>The number of elements in a softmax group. This is
the number of classes for classification. Often <code>GROUP-SIZE</code> is
equal to <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) (it is the default), but in general the only
constraint is that <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) is a multiple of <code>GROUP-SIZE</code>.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3ATARGET-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>TARGET</strong> <em>-&gt;SOFTMAX-XE-LOSS</em> <em>(:TARGET = NIL)</em></p>

<p>Set in <a href="#x-28MGL-CORE-3ASET-INPUT-20GENERIC-FUNCTION-29" title="(MGL-CORE:SET-INPUT GENERIC-FUNCTION)"><code>SET-INPUT</code></a>, this is either a <code>MAT</code> of the same
size as the input lump <code>X</code> or if the target is very sparse, this
can also be a sequence of batch size length that contains the
index value pairs of non-zero entries:</p>

<pre><code>(;; first instance in batch has to non-zero targets
 (;; class 10 has 30% expected probability
  (10 . 0.3)
  ;; class 2 has 70% expected probability
  (2 .  0.7))
 ;; second instance in batch puts 100% on class 7
 7
 ;; more instance in the batch follow
 ...)
</code></pre>

<p>Actually, in the rare case where <a href="#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29" title="(MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS))"><code>GROUP-SIZE</code></a> is not <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) (i.e. there are several softmax
normalization groups for every example), the length of the above
target sequence is <code>BATCH-SIZE</code>(<a href="#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-CG-3ACG-OPTIMIZER-29-29" title="(MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-CG:CG-OPTIMIZER))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ABATCH-SIZE-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-COMMON:BATCH-SIZE (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER))"><code>1</code></a>) * N-GROUPS. Indices are always
relative to the start of the group.</p>

<p>If <a href="#x-28MGL-COMMON-3AGROUP-SIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29" title="(MGL-COMMON:GROUP-SIZE (MGL-PAX:READER MGL-BP:-&gt;SOFTMAX-XE-LOSS))"><code>GROUP-SIZE</code></a> is large (for example,
in neural language models with a huge number of words), using
sparse targets can make things go much faster, because calculation
of the derivative is no longer quadratic.</p>

<p>Giving different weights to training instances is implicitly
supported. While target values in a group should sum to 1,
multiplying all target values with a weight <code>W</code> is equivalent to
training that <code>W</code> times on the same example.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AENSURE-SOFTMAX-TARGET-MATRIX-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>ENSURE-SOFTMAX-TARGET-MATRIX</strong> <em>SOFTMAX-XE-LOSS N</em></p>

<p>Set <a href="#x-28MGL-COMMON-3ATARGET-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESOFTMAX-XE-LOSS-29-29" title="(MGL-COMMON:TARGET (MGL-PAX:ACCESSOR MGL-BP:-&gt;SOFTMAX-XE-LOSS))"><code>TARGET</code></a> of <code>SOFTMAX-XE-LOSS</code> to a <code>MAT</code> capable of holding the dense
target values for <code>N</code> stripes.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-SOFTMAX-XE-LOSS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SOFTMAX-XE-LOSS-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-DROPOUT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-DROPOUT-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-STOCHASTICITY MGL-PAX:SECTION)">&#8634;</a></span>10.4.7 Stochasticity</h4>

<p><a name='x-28MGL-BP-3A-40MGL-BP-DROPOUT-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-STOCHASTICITY MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-STOCHASTICITY MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-GAUSSIAN-RANDOM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-GAUSSIAN-RANDOM-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-DROPOUT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-DROPOUT-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Dropout Lump</h5>

<p><a name='x-28MGL-BP-3A--3EDROPOUT-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;DROPOUT</strong> <em>LUMP</em></p>

<p>The output of this lump is identical to its input,
except it randomly zeroes out some of them during training which act
as a very strong regularizer. See Geoffrey Hinton's 'Improving
neural networks by preventing co-adaptation of feature
detectors'.</p>

<p>The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is the size of its input which is determined
automatically.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ADROPOUT-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EDROPOUT-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>DROPOUT</strong> <em>-&gt;DROPOUT</em> <em>(:DROPOUT = 0.5)</em></p>

<p>If non-NIL, then in the forward pass zeroes out
each node in this chunk with <code>DROPOUT</code> probability.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-GAUSSIAN-RANDOM-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-DROPOUT-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-DROPOUT-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-STOCHASTICITY MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SAMPLE-BINARY-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SAMPLE-BINARY-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-GAUSSIAN-RANDOM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-GAUSSIAN-RANDOM-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Gaussian Random Lump</h5>

<p><a name='x-28MGL-BP-3A--3EGAUSSIAN-RANDOM-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;GAUSSIAN-RANDOM</strong> <em>LUMP</em></p>

<p>This lump has no input, it produces normally
distributed independent random numbers with <a href="#x-28MGL-BP-3AMEAN-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29" title="(MGL-BP:MEAN (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM))"><code>MEAN</code></a> and <a href="#x-28MGL-BP-3AVARIANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29" title="(MGL-BP:VARIANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM))"><code>VARIANCE</code></a> (or
<a href="#x-28MGL-BP-3AVARIANCE-FOR-PREDICTION-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29" title="(MGL-BP:VARIANCE-FOR-PREDICTION (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM))"><code>VARIANCE-FOR-PREDICTION</code></a>). This is useful building block for noise
based regularization methods.</p>

<pre><code>(->gaussian-random :size 10 :name 'normal :mean 1 :variance 2)
==> #<->GAUSSIAN-RANDOM NORMAL :SIZE 10 1/1 :norm 0.00000>
</code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3AMEAN-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>MEAN</strong> <em>-&gt;GAUSSIAN-RANDOM</em> <em>(:MEAN = 0)</em></p>

<p>The mean of the normal distribution.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AVARIANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>VARIANCE</strong> <em>-&gt;GAUSSIAN-RANDOM</em> <em>(:VARIANCE = 1)</em></p>

<p>The variance of the normal distribution.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AVARIANCE-FOR-PREDICTION-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>VARIANCE-FOR-PREDICTION</strong> <em>-&gt;GAUSSIAN-RANDOM</em> <em>(:VARIANCE-FOR-PREDICTION = 0)</em></p>

<p>If not <code>NIL</code>, then this value overrides <a href="#x-28MGL-BP-3AVARIANCE-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3EGAUSSIAN-RANDOM-29-29" title="(MGL-BP:VARIANCE (MGL-PAX:ACCESSOR MGL-BP:-&gt;GAUSSIAN-RANDOM))"><code>VARIANCE</code></a>
when not in training (i.e. when making predictions).</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-SAMPLE-BINARY-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-GAUSSIAN-RANDOM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-GAUSSIAN-RANDOM-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-STOCHASTICITY-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-STOCHASTICITY MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SAMPLE-BINARY-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SAMPLE-BINARY-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Binary Sampling Lump</h5>

<p><a name='x-28MGL-BP-3A--3ESAMPLE-BINARY-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;SAMPLE-BINARY</strong> <em>LUMP</em></p>

<p>Treating values of its input as probabilities,
sample independent binomials. Turn true into 1 and false into 0. The
<code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is determined automatically from the size of its
input.</p>

<pre><code>(->sample-binary (->input :size 10) :name 'binarized-input)
==> #<->SAMPLE-BINARY BINARIZED-INPUT :SIZE 10 1/1 :norm 0.00000>
</code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-SAMPLE-BINARY-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SAMPLE-BINARY-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SUM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SUM-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8634;</a></span>10.4.8 Arithmetic</h4>

<p><a name='x-28MGL-BP-3A-40MGL-BP-SUM-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-V-2AM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-V*M-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SUM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SUM-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Sum Lump</h5>

<p><a name='x-28MGL-BP-3A--3ESUM-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;SUM</strong> <em>LUMP</em></p>

<p>Computes the sum of all nodes of its input per
stripe. This <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is always 1.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-V-2AM-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-SUM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SUM-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP--2B-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-+-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-V-2AM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-V*M-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Vector-Matrix Multiplication Lump</h5>

<p><a name='x-28MGL-BP-3A--3EV-2AM-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;V*M</strong> <em>LUMP</em></p>

<p>Perform <code>X * WEIGHTS</code> where <code>X</code> (the input) is of
size <code>M</code> and <code>WEIGHTS</code>(<a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>0</code></a> <a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>1</code></a>) is a <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a> whose single stripe is taken to
be of dimensions <code>M x N</code> stored in row major order. <code>N</code> is the size
of this lump. If <a href="#x-28MGL-BP-3ATRANSPOSE-WEIGHTS-P-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-BP:TRANSPOSE-WEIGHTS-P (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>TRANSPOSE-WEIGHTS-P</code></a> then <code>WEIGHTS</code>(<a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>0</code></a> <a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>1</code></a>) is <code>N x M</code> and <code>X
* WEIGHTS'</code> is computed.</p></li>
</ul>

<p><a name='x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29'></a></p>

<ul>
<li><p>[reader] <strong>WEIGHTS</strong> <em>-&gt;V*M</em> <em>(:WEIGHTS)</em></p>

<p>A <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a> lump.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ATRANSPOSE-WEIGHTS-P-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29'></a></p>

<ul>
<li><p>[reader] <strong>TRANSPOSE-WEIGHTS-P</strong> <em>-&gt;V*M</em> <em>(:TRANSPOSE-WEIGHTS-P = NIL)</em></p>

<p>Determines whether the input is multiplied by
<code>WEIGHTS</code>(<a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EV-2AM-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;V*M))"><code>0</code></a> <a href="#x-28MGL-COMMON-3AWEIGHTS-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3EEMBEDDING-29-29" title="(MGL-COMMON:WEIGHTS (MGL-PAX:READER MGL-BP:-&gt;EMBEDDING))"><code>1</code></a>) or its transpose.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP--2B-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-V-2AM-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-V*M-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP--2A-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-*-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP--2B-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-+-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Elementwise Addition Lump</h5>

<p><a name='x-28MGL-BP-3A--3E-2B-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;+</strong> <em>LUMP</em></p>

<p>Performs elementwise addition on its input lumps.
The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is automatically determined from the size of
its inputs if there is at least one. If one of the inputs is a
<a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a> lump, then it is added to every stripe.</p>

<pre><code>(->+ (list (->input :size 10) (->weight :size 10 :name 'bias))
     :name 'plus)
==> #<->+ PLUS :SIZE 10 1/1 :norm 0.00000>
</code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP--2A-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP--2B-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-+-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ABS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ABS-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP--2A-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-*-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Elementwise Multiplication Lump</h5>

<p><a name='x-28MGL-BP-3A--3E-2A-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;*</strong> <em>LUMP</em></p>

<p>Performs elementwise multiplication on its two
input lumps. The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is automatically determined from
the size of its inputs. Either input can be a <a href="#x-28MGL-BP-3A--3EWEIGHT-20CLASS-29" title="(MGL-BP:-&gt;WEIGHT CLASS)"><code>-&gt;WEIGHT</code></a> lump.</p>

<pre><code>(->* (->input :size 10) (->weight :size 10 :name 'scale)
     :name 'mult)
==> #<->* MULT :SIZE 10 1/1 :norm 0.00000>
</code></pre></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-ABS-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP--2A-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-*-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-EXP-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EXP-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ABS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ABS-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Abs Lump</h5>

<p><a name='x-28MGL-BP-3A--3EABS-20CLASS-29'></a></p>

<ul>
<li>[class] <strong>-&gt;ABS</strong> <em>LUMP</em></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-EXP-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-ABS-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ABS-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-NORMALIZED-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-NORMALIZED-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-EXP-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EXP-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Exp Lump</h5>

<p><a name='x-28MGL-BP-3A--3EEXP-20CLASS-29'></a></p>

<ul>
<li>[class] <strong>-&gt;EXP</strong> <em>LUMP</em></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-NORMALIZED-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-EXP-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-EXP-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-ARITHMETIC-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-ARITHMETIC MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RNN-OPERATIONS MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-NORMALIZED-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-NORMALIZED-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Normalized Lump</h5>

<p><a name='x-28MGL-BP-3A--3ENORMALIZED-20CLASS-29'></a></p>

<ul>
<li>[class] <strong>-&gt;NORMALIZED</strong> <em>LUMP</em></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29'></a></p>

<h4><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-NORMALIZED-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-NORMALIZED-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LUMPS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LUMPS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LSTM-SUBNET-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LSTM-SUBNET MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RNN-OPERATIONS MGL-PAX:SECTION)">&#8634;</a></span>10.4.9 Operations for RNNs</h4>

<p><a name='x-28MGL-BP-3A-40MGL-BP-LSTM-SUBNET-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RNN-OPERATIONS MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RNN-OPERATIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SEQ-BARRIER-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SEQ-BARRIER-LUMP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-LSTM-SUBNET-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LSTM-SUBNET MGL-PAX:SECTION)">&#8634;</a></span>LSTM Subnet</h5>

<p><a name='x-28MGL-BP-3A--3ELSTM-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;LSTM</strong> <em>BPN</em></p>

<p>Long-Short Term Memory subnetworks are built by the
function <code>-&gt;LSTM</code> and they have many lumps hidden inside them. These
lumps are packaged into a subnetwork to reduce clutter.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A--3ELSTM-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>-&gt;LSTM</strong> <em>INPUTS &amp;KEY NAME CELL-INIT OUTPUT-INIT SIZE (GATE-FN '-&gt;SIGMOID) (INPUT-FN '-&gt;TANH) (OUTPUT-FN '-&gt;TANH) (PEEPHOLES T)</em></p>

<p>Create an LSTM layer consisting of input, forget, output gates with
which input, cell state and output are scaled. Lots of lumps are
created, the final one representing to output of the LSTM has <code>NAME</code>.
The rest of the lumps are named automatically based on <code>NAME</code>. This
function returns only the output lump (<code>m</code>), but all created lumps
are added automatically to the <a href="#x-28MGL-BP-3ABPN-20CLASS-29" title="(MGL-BP:BPN CLASS)"><code>BPN</code></a> being built.</p>

<p>There are many papers and tutorials on LSTMs. This version is well
described in &quot;Long Short-Term Memory Recurrent Neural Network
Architectures for Large Scale Acoustic Modeling&quot; (2014, Hasim Sak,
Andrew Senior, Francoise Beaufays). Using the notation from that
paper:</p>

<pre><code>i_t = s(W_ix * x_t + W_im * m_{t_1} + W_ic .* c_{t-1} + b_i)
f_t = s(W_fx * x_t + W_fm * m_{t_1} + W_fc .* c_{t-1} + b_f)
c_t = f_t .* c_{t-1} + i_t .* g(W_cx * x_t + W_cm  * m_{t-1} + b_c)
o_t = s(W_ox * x_t + W_om * m_{t-1} + W_oc .* c_t + b_o)
m_t = o_t .* h(c_t)
</code></pre>

<p>... where <code>i</code>, <code>f</code>, and <code>o</code> are the input, forget and output gates.
<code>c</code> is the cell state and <code>m</code> is the actual output.</p>

<p>Weight matrices for connections from <code>c</code> (<code>W_ic</code>, <code>W_fc</code> and <code>W_oc</code>)
diagonal and are represented by just the vector of diagonal values.
These connections are only added if <code>PEEPHOLES</code> is true.</p>

<p>A notable difference from the paper is that in addition to being a
single lump, <code>x_t</code> (<code>INPUTS</code>) can also be a list of lumps. Whenever
some activation is to be calculated based on <code>x_t</code>, it is going to
be the sum of individual activations. For example, <code>W_ix * x_t</code> is
really <code>sum_j W_ijx * inputs_j</code>.</p>

<p>If <code>CELL-INIT</code> is non-NIL, then it must be a <a href="#x-28MGL-BP-3ACLUMP-20CLASS-29" title="(MGL-BP:CLUMP CLASS)"><code>CLUMP</code></a> of <code>SIZE</code> form which
stands for the initial state of the value cell (<code>c_{-1}</code>). <code>CELL-INIT</code>
being <code>NIL</code> is equivalent to the state of all zeros.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-SEQ-BARRIER-LUMP-20MGL-PAX-3ASECTION-29'></a></p>

<h5><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-LSTM-SUBNET-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-LSTM-SUBNET MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-RNN-OPERATIONS-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-RNN-OPERATIONS MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-UTILITIES MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-SEQ-BARRIER-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SEQ-BARRIER-LUMP MGL-PAX:SECTION)">&#8634;</a></span>Sequence Barrier Lump</h5>

<p><a name='x-28MGL-BP-3A--3ESEQ-BARRIER-20CLASS-29'></a></p>

<ul>
<li><p>[class] <strong>-&gt;SEQ-BARRIER</strong> <em>LUMP</em></p>

<p>In an <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a>, processing of stripes (instances in the
batch) may require different number of time step so the final state
for stripe 0 is in stripe 0 of some lump L at time step 7, while for
stripe 1 it is in stripe 1 of sump lump L at time step 42.</p>

<p>This lump copies the per-stripe states from different lumps into a
single lump so that further processing can take place (typically
when the <a href="#x-28MGL-BP-3ARNN-20CLASS-29" title="(MGL-BP:RNN CLASS)"><code>RNN</code></a> is embedded in another network).</p>

<p>The <code>SIZE</code>(<a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-BP-3ALUMP-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-BP:LUMP))"><code>0</code></a> <a href="#x-28MGL-COMMON-3ASIZE-20-28MGL-PAX-3AREADER-20MGL-OPT-3ASEGMENT-SET-29-29" title="(MGL-COMMON:SIZE (MGL-PAX:READER MGL-OPT:SEGMENT-SET))"><code>1</code></a>) of this lump is automatically set to the size of the lump
returned by <code>(FUNCALL SEQ-ELT-FN 0)</code>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ASEQ-ELT-FN-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESEQ-BARRIER-29-29'></a></p>

<ul>
<li><p>[reader] <strong>SEQ-ELT-FN</strong> <em>-&gt;SEQ-BARRIER</em> <em>(:SEQ-ELT-FN)</em></p>

<p>A function of an [INDEX] argument that
returns the lump with that index in some sequence.</p></li>
</ul>

<p><a name='x-28MGL-BP-3ASEQ-INDICES-20-28MGL-PAX-3AACCESSOR-20MGL-BP-3A--3ESEQ-BARRIER-29-29'></a></p>

<ul>
<li><p>[accessor] <strong>SEQ-INDICES</strong> <em>-&gt;SEQ-BARRIER</em></p>

<p>A sequence of length batch size of indices. The
element at index <code>I</code> is the index to be passed to <a href="#x-28MGL-BP-3ASEQ-ELT-FN-20-28MGL-PAX-3AREADER-20MGL-BP-3A--3ESEQ-BARRIER-29-29" title="(MGL-BP:SEQ-ELT-FN (MGL-PAX:READER MGL-BP:-&gt;SEQ-BARRIER))"><code>SEQ-ELT-FN</code></a> to
find the lump whose stripe <code>I</code> is copied to stripe <code>I</code> of this
this lump.</p></li>
</ul>

<p><a name='x-28MGL-BP-3A-40MGL-BP-UTILITIES-20MGL-PAX-3ASECTION-29'></a></p>

<h3><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-SEQ-BARRIER-LUMP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-SEQ-BARRIER-LUMP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-3A-40MGL-BM-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-BM MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-BP-3A-40MGL-BP-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-UTILITIES MGL-PAX:SECTION)">&#8634;</a></span>10.5 Utilities</h3>

<p><a name='x-28MGL-BP-3ARENORMALIZE-ACTIVATIONS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>RENORMALIZE-ACTIVATIONS</strong> <em>-&gt;V*M-LUMPS L2-UPPER-BOUND</em></p>

<p>If the l2 norm of the incoming weight vector of the a unit is
larger than <code>L2-UPPER-BOUND</code> then renormalize it to <code>L2-UPPER-BOUND</code>.
The list of <code>-&gt;V*M-LUMPS</code> is assumed to be eventually fed to the same
lump.</p>

<p>To use it, group the activation clumps into the same GD-OPTIMIZER
and hang this function on <a href="#x-28MGL-GD-3AAFTER-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-GD:AFTER-UPDATE-HOOK (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER))"><code>AFTER-UPDATE-HOOK</code></a>, that latter of which is
done for you <a href="#x-28MGL-BP-3AARRANGE-FOR-RENORMALIZING-ACTIVATIONS-20FUNCTION-29" title="(MGL-BP:ARRANGE-FOR-RENORMALIZING-ACTIVATIONS FUNCTION)"><code>ARRANGE-FOR-RENORMALIZING-ACTIVATIONS</code></a>.</p>

<p>See &quot;Improving neural networks by preventing co-adaptation of
feature detectors (Hinton, 2012)&quot;,
<a href="http://arxiv.org/pdf/1207.0580.pdf">http://arxiv.org/pdf/1207.0580.pdf</a>.</p></li>
</ul>

<p><a name='x-28MGL-BP-3AARRANGE-FOR-RENORMALIZING-ACTIVATIONS-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>ARRANGE-FOR-RENORMALIZING-ACTIVATIONS</strong> <em>BPN OPTIMIZER L2-UPPER-BOUND</em></p>

<p>By pushing a lambda to <a href="#x-28MGL-GD-3AAFTER-UPDATE-HOOK-20-28MGL-PAX-3AACCESSOR-20MGL-GD-3A-3AGD-OPTIMIZER-29-29" title="(MGL-GD:AFTER-UPDATE-HOOK (MGL-PAX:ACCESSOR MGL-GD::GD-OPTIMIZER))"><code>AFTER-UPDATE-HOOK</code></a> of <code>OPTIMIZER</code> arrange for
all weights beings trained by <code>OPTIMIZER</code> to be renormalized (as in
<a href="#x-28MGL-BP-3ARENORMALIZE-ACTIVATIONS-20FUNCTION-29" title="(MGL-BP:RENORMALIZE-ACTIVATIONS FUNCTION)"><code>RENORMALIZE-ACTIVATIONS</code></a> with <code>L2-UPPER-BOUND</code>).</p>

<p>It is assumed that if the weights either belong to an activation
lump or are simply added to the activations (i.e. they are biases).</p></li>
</ul>

<p><a name='x-28MGL-3A-40MGL-BM-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-BP-3A-40MGL-BP-UTILITIES-20MGL-PAX-3ASECTION-29" title="(MGL-BP:@MGL-BP-UTILITIES MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-3A-40MGL-GP-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-3A-40MGL-BM-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-BM MGL-PAX:SECTION)">&#8634;</a></span>11 Boltzmann Machines</h2>

<p><a name='x-28MGL-3A-40MGL-GP-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-3A-40MGL-BM-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-BM MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-NLP-3A-40MGL-NLP-20MGL-PAX-3ASECTION-29" title="(MGL-NLP:@MGL-NLP MGL-PAX:SECTION)">&#8594;</a> <a href="#x-28MGL-3A-40MGL-GP-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GP MGL-PAX:SECTION)">&#8634;</a></span>12 Gaussian Processes</h2>

<p><a name='x-28MGL-NLP-3A-40MGL-NLP-20MGL-PAX-3ASECTION-29'></a></p>

<h2><span class="navigation"> <a href="#x-28MGL-3A-40MGL-GP-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-GP MGL-PAX:SECTION)">&#8592;</a> <a href="#x-28MGL-3A-40MGL-MANUAL-20MGL-PAX-3ASECTION-29" title="(MGL:@MGL-MANUAL MGL-PAX:SECTION)">&#8593;</a> <a href="#x-28MGL-NLP-3A-40MGL-NLP-20MGL-PAX-3ASECTION-29" title="(MGL-NLP:@MGL-NLP MGL-PAX:SECTION)">&#8634;</a></span>13 Natural Language Processing</h2>

<h6>[in package MGL-NLP]</h6>

<p>This in nothing more then a couple of utilities for now which may
grow into a more serious toolset for NLP eventually.</p>

<p><a name='x-28MGL-NLP-3AMAKE-N-GRAM-MAPPEE-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>MAKE-N-GRAM-MAPPEE</strong> <em>FUNCTION N</em></p>

<p>Make a function of a single argument that's suitable as the
function argument to a mapper function. It calls <code>FUNCTION</code> with every
<code>N</code> element.</p>

<pre><code>(map nil (make-n-gram-mappee #'print 3) '(a b c d e))
..
.. (A B C) 
.. (B C D) 
.. (C D E) 
</code></pre></li>
</ul>

<p><a name='x-28MGL-NLP-3ABLEU-20FUNCTION-29'></a></p>

<ul>
<li><p>[function] <strong>BLEU</strong> <em>CANDIDATES REFERENCES &amp;KEY CANDIDATE-KEY REFERENCE-KEY (N 4)</em></p>

<p>Compute the <a href="http://en.wikipedia.org/wiki/BLEU" >BLEU score</a> for
bilingual CORPUS. <a href="#x-28MGL-NLP-3ABLEU-20FUNCTION-29" title="(MGL-NLP:BLEU FUNCTION)"><code>BLEU</code></a> measures how good a translation is compared
to human reference translations.</p>

<p><code>CANDIDATES</code> (keyed by <code>CANDIDATE-KEY</code>) and <code>REFERENCES</code> (keyed by
<code>REFERENCE-KEY</code>) are sequences of sentences. A sentence is a sequence
of words. Words are compared with <code>EQUAL</code>, and may be any kind of
object (not necessarily strings).</p>

<p>Currently there is no support for multiple reference translations. <code>N</code>
determines the largest n-grams to consider.</p>

<p>The first return value is the <a href="#x-28MGL-NLP-3ABLEU-20FUNCTION-29" title="(MGL-NLP:BLEU FUNCTION)"><code>BLEU</code></a> score (between 0 and 1, not as a
percentage), the second value is the brevity penalty and the third
is a list n-gram precisions (also between 0 and 1 or <code>NIL</code>), one for
each element in [1..N][].</p>

<p>This is basically a reimplementation of
<a href="https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl" >multi-bleu.perl</a>.</p>

<pre><code>(bleu '((1 2 3 4) (a b))
      '((1 2 3 4) (1 2)))
=> 0.8408964
=> 1.0
=> (;; 1-gram precision: 4/6
    2/3
    ;; 2-gram precision: 3/4
    3/4
    ;; 3-gram precision: 2/2
    1
    ;; 4-gram precision: 1/1
    1)
</code></pre></li>
</ul>
<hr/><h6>[generated by
          <a href="https://github.com/melisgl/mgl-pax">MGL-PAX</a>]
          </h6>
          </body>
</html>
